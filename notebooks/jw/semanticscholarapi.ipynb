{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakwisn/.cache/pypoetry/virtualenvs/mars-48yr609M-py3.7/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import semanticscholar\n",
    "from mars.utils import extract_text_from_pdf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scripts.parse_jobin2019 import *\n",
    "from mars.utils import get_inteligent_first_search_results, get_duckduckgo_first_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../../../../Downloads/1906.11668.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23185/2473920416.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_topics_from_jobin_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jakwi/github/AI-strategies-papers-regulations-monitoring/scripts/parse_jobin2019.py\u001b[0m in \u001b[0;36mextract_topics_from_jobin_citations\u001b[0;34m(path_to_jobin_file)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_topics_from_jobin_citations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_jobin_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;34m\"\"\"Extracts topics for each relevant citation in jobin2019 preprint version\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0mcitations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_citations_from_jobin2019\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_jobin_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mall_citations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jakwi/github/AI-strategies-papers-regulations-monitoring/scripts/parse_jobin2019.py\u001b[0m in \u001b[0;36mextract_citations_from_jobin2019\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mrelevant_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_on_pages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# pop empty one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/jakwi/github/AI-strategies-papers-regulations-monitoring/mars/utils.py\u001b[0m in \u001b[0;36msplit_on_words\u001b[0;34m(text, split_words)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mthreads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlier_thread\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = extract_topics_from_jobin_citations(file_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = extract_references_from_jobin2019(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_references = list(np.array(references)[data.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: 1906.11668\n",
      "84\n",
      "BS google is down\n",
      "Selenium Google is down\n"
     ]
    }
   ],
   "source": [
    "actual_link = match_references_with_url(actual_references,'1906.11668')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ac in actual_link.items():\n",
    "    if type(ac) == str: \n",
    "        actual_link[key] = (ac, 'semantic_scholar_api') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title'] = [ar for ar in actual_references]\n",
    "data['link'] = [ac[0] for ac in actual_link.values()]\n",
    "data['source'] = [ac[1] for ac in actual_link.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../data/jobin2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: dvc: command not found\n"
     ]
    }
   ],
   "source": [
    "! dvc add jobin2019.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: 1408.2083\n"
     ]
    }
   ],
   "source": [
    "paper = fetch_paper_information('1408.2083')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 'With a jocund air, we present an observation on the first 24 coefficients of the modular invariant and of the modular discriminant. The observation is purely for the sake of entertainment and could be of some diversion to a mathematical audience.',\n",
       " 'arxivId': '1408.2083',\n",
       " 'authors': [{'authorId': '2022419',\n",
       "   'name': 'Y. He',\n",
       "   'url': 'https://www.semanticscholar.org/author/2022419'},\n",
       "  {'authorId': '144974619',\n",
       "   'name': 'J. McKay',\n",
       "   'url': 'https://www.semanticscholar.org/author/144974619'}],\n",
       " 'citationVelocity': 0,\n",
       " 'citations': [{'arxivId': '2106.01162',\n",
       "   'authors': [{'authorId': '144974619', 'name': 'J. McKay'},\n",
       "    {'authorId': None, 'name': 'Yang-Hui He'}],\n",
       "   'doi': None,\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '62666269f5dc32898ea1436a43b7a86af794eb27',\n",
       "   'title': 'Kashiwa Lectures on\"New Approaches to the Monster\"',\n",
       "   'url': 'https://www.semanticscholar.org/paper/62666269f5dc32898ea1436a43b7a86af794eb27',\n",
       "   'venue': '',\n",
       "   'year': 2021},\n",
       "  {'arxivId': '1903.09851',\n",
       "   'authors': [{'authorId': '1882073', 'name': 'A. Kleshchev'},\n",
       "    {'authorId': '3104218', 'name': 'Lucia Morotti'},\n",
       "    {'authorId': '2841976', 'name': 'P. Tiep'}],\n",
       "   'doi': '10.1090/ert/538',\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '7822a029341d6401143a56ae9e1377d91cf28586',\n",
       "   'title': 'Irreducible restrictions of representations of alternating groups in small characteristics: Reduction theorems',\n",
       "   'url': 'https://www.semanticscholar.org/paper/7822a029341d6401143a56ae9e1377d91cf28586',\n",
       "   'venue': '',\n",
       "   'year': 2020},\n",
       "  {'arxivId': '1503.02677',\n",
       "   'authors': [{'authorId': '1913450', 'name': 'M. Planat'}],\n",
       "   'doi': '10.3390/math3030746',\n",
       "   'intent': ['background'],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '151299c13331be15713e8989a7bf6d13c7422f45',\n",
       "   'title': 'A moonshine dialogue in mathematical physics',\n",
       "   'url': 'https://www.semanticscholar.org/paper/151299c13331be15713e8989a7bf6d13c7422f45',\n",
       "   'venue': '',\n",
       "   'year': 2015},\n",
       "  {'arxivId': '1505.06742',\n",
       "   'authors': [{'authorId': '2022419', 'name': 'Y. He'},\n",
       "    {'authorId': '144974619', 'name': 'J. McKay'}],\n",
       "   'doi': None,\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': 'f1b9d264a676f8f8d1588f26f90ffe3e580c0059',\n",
       "   'title': 'Sporadic and Exceptional',\n",
       "   'url': 'https://www.semanticscholar.org/paper/f1b9d264a676f8f8d1588f26f90ffe3e580c0059',\n",
       "   'venue': '',\n",
       "   'year': 2015}],\n",
       " 'corpusId': 119156163,\n",
       " 'doi': '10.1090/CONM/694',\n",
       " 'fieldsOfStudy': ['Mathematics', 'Physics'],\n",
       " 'influentialCitationCount': 0,\n",
       " 'isOpenAccess': False,\n",
       " 'isPublisherLicensed': True,\n",
       " 'is_open_access': False,\n",
       " 'is_publisher_licensed': True,\n",
       " 'numCitedBy': 4,\n",
       " 'numCiting': 7,\n",
       " 'paperId': '66554b927c1a5fee787045b8b1bfe3ce2dc35f02',\n",
       " 'references': [{'arxivId': None,\n",
       "   'authors': [{'authorId': None, 'name': 'G. N. Watson'}],\n",
       "   'doi': None,\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '',\n",
       "   'title': 'The problem of the square pyramid,',\n",
       "   'url': '',\n",
       "   'venue': 'Messenger of Mathematics,',\n",
       "   'year': 1918},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '143607031', 'name': 'Jean-Pierre Serre'}],\n",
       "   'doi': '10.1007/978-1-4684-9884-4',\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '43490ebdf44e78d7346ca511cc8b0e952ef20ee1',\n",
       "   'title': 'A Course in Arithmetic',\n",
       "   'url': 'https://www.semanticscholar.org/paper/43490ebdf44e78d7346ca511cc8b0e952ef20ee1',\n",
       "   'venue': '',\n",
       "   'year': 1973},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '32685270', 'name': 'J. Conway'}],\n",
       "   'doi': '10.1016/0021-8693(83)90025-X',\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': 'a961c522c7a198e32e88fe065bdf929bbef6588b',\n",
       "   'title': 'The automorphism group of the 26-dimensional even unimodular Lorentzian lattice',\n",
       "   'url': 'https://www.semanticscholar.org/paper/a961c522c7a198e32e88fe065bdf929bbef6588b',\n",
       "   'venue': '',\n",
       "   'year': 1983},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '12147079', 'name': 'R. Borcherds'}],\n",
       "   'doi': '10.1073/PNAS.83.10.3068',\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': 'a3bb2d2772ccc0c1582f0216f9ab87c1b8a11eb6',\n",
       "   'title': 'Vertex algebras, Kac-Moody algebras, and the Monster.',\n",
       "   'url': 'https://www.semanticscholar.org/paper/a3bb2d2772ccc0c1582f0216f9ab87c1b8a11eb6',\n",
       "   'venue': 'Proceedings of the National Academy of Sciences of the United States of America',\n",
       "   'year': 1986},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '144696179', 'name': 'D. Adams'},\n",
       "    {'authorId': '143716820', 'name': 'D. Maggs'}],\n",
       "   'doi': None,\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '79a993e9cd062c981e0b9cd62e7065d018fd8c9e',\n",
       "   'title': \"The hitchhiker's guide to the galaxy : radio scripts\",\n",
       "   'url': 'https://www.semanticscholar.org/paper/79a993e9cd062c981e0b9cd62e7065d018fd8c9e',\n",
       "   'venue': '',\n",
       "   'year': 2005},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '2533582', 'name': 'T. Gannon'}],\n",
       "   'doi': None,\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': 'a7dd67f98677b8ceff9009e52b04d1fdd6a58b56',\n",
       "   'title': 'Moonshine beyond the Monster: The Bridge Connecting Algebra, Modular Forms and Physics',\n",
       "   'url': 'https://www.semanticscholar.org/paper/a7dd67f98677b8ceff9009e52b04d1fdd6a58b56',\n",
       "   'venue': '',\n",
       "   'year': 2006},\n",
       "  {'arxivId': None,\n",
       "   'authors': [{'authorId': '104280639', 'name': 'Ozlem Umdu'}],\n",
       "   'doi': '10.1090/mbk/121/80',\n",
       "   'intent': [],\n",
       "   'isInfluential': False,\n",
       "   'paperId': '2726d5ae3330a0eb0eff43a3483d5772cdb63b03',\n",
       "   'title': 'The Monstrous Moonshine',\n",
       "   'url': 'https://www.semanticscholar.org/paper/2726d5ae3330a0eb0eff43a3483d5772cdb63b03',\n",
       "   'venue': '',\n",
       "   'year': 2012}],\n",
       " 'title': 'Moonshine and the Meaning of Life',\n",
       " 'topics': [{'topic': 'Deep Thought (chess computer)',\n",
       "   'topicId': '866187',\n",
       "   'url': 'https://www.semanticscholar.org/topic/866187'},\n",
       "  {'topic': 'moonshine',\n",
       "   'topicId': '316845',\n",
       "   'url': 'https://www.semanticscholar.org/topic/316845'},\n",
       "  {'topic': 'transcriptional intermediary factor 1gamma, zebrafish',\n",
       "   'topicId': '10701888',\n",
       "   'url': 'https://www.semanticscholar.org/topic/10701888'},\n",
       "  {'topic': 'Quantum field theory',\n",
       "   'topicId': '22570',\n",
       "   'url': 'https://www.semanticscholar.org/topic/22570'},\n",
       "  {'topic': 'Published Comment',\n",
       "   'topicId': '838',\n",
       "   'url': 'https://www.semanticscholar.org/topic/838'}],\n",
       " 'url': 'https://www.semanticscholar.org/paper/66554b927c1a5fee787045b8b1bfe3ce2dc35f02',\n",
       " 'venue': '',\n",
       " 'year': 2017}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19923/1037567472.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpaper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arxivId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "paper['arxivId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' \\n',\n",
       "  '1 \\n',\n",
       "  'Artificial Intelligence: the global landscape of ethics guidelines \\n \\n \\n \\nAnna Jobin a, Marcello Ienca a, Effy Vayena a* \\n \\n \\n \\na Health Ethics & Policy Lab, ETH Zurich, 8092 Zurich, Switzerland \\n \\n* Corresponding author: effy.vayena@hest.ethz.ch \\n \\n \\n \\nPreprint version \\n \\n© The authors 2019 \\n \\n \\n \\n \\n \\n \\nABSTRACT \\nIn  the  last  five  years,  private  companies,  research  institutions  as  well  as  public  sector \\norganisations have issued principles and guidelines for ethical AI, yet there is debate about \\nboth what constitutes “ethical AI” and which ethical requirements, technical standards and \\nbest practices are needed for its realization. To investigate whether a global agreement on \\nthese questions is emerging, we mapped and analyzed the current corpus of principles and \\nguidelines on ethical AI. Our results reveal a global convergence emerging around five \\nethical principles (transparency, justice and fairness, non-maleficence, responsibility and \\nprivacy), with substantive divergence in relation to how these principles are interpreted; \\nwhy they are deemed important; what issue, domain or actors they pertain to; and how they \\nshould be implemented. Our findings highlight the importance of integrating guideline-\\ndevelopment  efforts  with  substantive  ethical  analysis  and  adequate  implementation \\nstrategies.\\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '2 \\n',\n",
       "  'MAIN ARTICLE \\nIntroduction \\nArtificial Intelligence (AI), or the theory and development of computer systems able to \\nperform tasks normally requiring human intelligence, is widely heralded as an ongoing \\n“revolution” transforming science and society altogether1,2. While approaches to AI such as \\nmachine learning, deep learning and artificial neural networks are reshaping data processing \\nand analysis3, autonomous and semi-autonomous systems are being increasingly used in a \\nvariety of sectors including healthcare, transportation and the production chain4. In light of \\nits powerful transformative force and profound impact across various societal domains, AI \\nhas sparked ample debate about the principles and values that should guide its development \\nand  use5,6.  Fears  that  AI  might  jeopardize  jobs  for  human  workers7,  be  misused  by \\nmalevolent  actors8,  elude  accountability  or  inadvertently  disseminate  bias  and  thereby \\nundermine fairness9 have been at the forefront of the recent scientific literature and media \\ncoverage.  Several  studies  have  discussed  the  topic  of  ethical  AI10–13,  notably  in  meta-\\nassessments14–16 or in relation to systemic risks17,18 and unintended negative consequences \\nlike algorithmic bias or discrimination19–21. \\n \\nNational  and  international  organisations  have  responded  to  these  societal  fears  by \\ndeveloping ad hoc expert committees on AI, often commissioned with the drafting of policy \\ndocuments. These include the High-Level Expert Group on Artificial Intelligence appointed \\nby the European Commission, the expert group on AI in Society of the Organisation for \\nEconomic Co-operation and Development (OECD), the Advisory Council on the Ethical \\nUse of Artificial Intelligence and Data in Singapore, and the select committee on Artificial \\nIntelligence of the United Kingdom (UK) House of Lords. As part of their institutional \\nappointments, these committees have produced or are reportedly producing reports and \\nguidance documents on AI. Similar efforts are taking place in the private sector, especially \\namong corporations who rely on AI for their business. In 2018 alone, companies such as \\nGoogle and SAP have publicly released AI guidelines and principles. Declarations and \\nrecommendations  have  also  been  issued  by  professional  associations  and  non-profit \\norganisations such as the Association of Computing Machinery (ACM), Access Now and \\nAmnesty International. The intense efforts of such a diverse set of stakeholders in issuing \\nAI principles and policies demonstrate not only the need for ethical guidance, but also the \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '3 \\n',\n",
       "  'strong  interest  of  these  stakeholders  to  shape  the  ethics  of  AI  in  ways  that  meet  their \\nrespective priorities16. Notably, the private sector’s involvement in the AI-ethics arena has \\nbeen called into question for potentially using such high-level soft-policy as a portmanteau \\nto either render a social problem technical16 or to eschew regulation altogether22. Beyond \\nthe composition of the groups that have produced ethical guidance on AI, the content of this \\nguidance itself is of interest. Are these various groups converging on what ethical AI should \\nbe, and the ethical principles that will determine the development of AI? If they diverge, \\nwhat are these differences and can they be reconciled? \\n \\nTo  answer  these  questions,  we  conducted  a  scoping  review  of  the  existing  corpus  of \\nguidelines on ethical AI. Our analysis aims at mapping the global landscape of existing \\nprinciples  and  guidelines  for  ethical  AI  and  thereby  determining  whether  a  global \\nconvergence is emerging regarding both the principles for ethical AI and the requirements \\nfor  its  realization.  This  analysis  will  inform  scientists,  research  institutions,  funding \\nagencies,  governmental  and \\ninter-governmental  organisations  and  other  relevant \\nstakeholders involved in the advancement of ethically responsible innovation in AI.  \\n \\nResults \\nOur search identified 84 documents containing ethical principles or guidelines for AI (cf. \\nTable 1). Data reveal a significant increase over time in the number of publications, with \\n88%  having  been  released  after  2016  (cf.  SI  Table  S1).  Data  breakdown  by  type  and \\ngeographic location of issuing organisation (cf. SI Table S1) shows that most documents \\nwere  produced  by  private  companies  (n=19;  22.6%)  and  governmental  agencies \\nrespectively (n=18; 21.4%), followed by academic and research institutions (n=9; 10.7%), \\ninter-governmental or supra-national organisations (n=8; 9.5%), non-profit organisations \\nand  professional  associations/scientific  societies  (n=7  each;  8.3%  each),  private  sector \\nalliances (n=4; 4.8%), research alliances (n=1; 1.2%), science foundations (n=1; 1.2%), \\nfederations of worker unions (n=1; 1.2%) and political parties (n=1; 1.2%). Four documents \\nwere issued by initiatives belonging to more than one of the above categories and four more \\ncould not be classified at all (4.8% each). \\n \\n \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  'Table 1- Ethical guidelines for AI by country of issuer \\n',\n",
       "  'Name of Document/Website \\n',\n",
       "  'Issuer \\n',\n",
       "  \"Artificial Intelligence. Australia's Ethics Framework. A \\ndiscussion Paper \\nMontréal Declaration: Responsible AI \\nWork in the age of artificial intelligence. Four perspectives on the \\neconomy, employment, skills and ethics \\nTieto’s AI ethics guidelines \\nCommitments and principles \\nHow can humans keep the upper hand? Report on the ethical \\nmatters raised by AI algorithms \\nFor a meaningful Artificial Intelligence. Towards a French and \\nEuropean strategy \\nEthique de la recherche en robotique \\nAI Guidelines \\nSAP’s guiding principles for artificial intelligence \\nAutomated and Connected Driving: Report \\n\",\n",
       "  \"Ethics Policy \\nDiscussion Paper: National Strategy for Artificial Intelligence \\nL'intelligenzia artificiale al servizio del cittadino \\nThe Japanese Society for Artificial Intelligence Ethical \\nGuidelines \\nReport on Artificial Intelligence and Human Society (Unofficial \\ntranslation) \\n\",\n",
       "  'Draft AI R&D Guidelines for International Discussions \\n',\n",
       "  'Sony Group AI Ethics Guidelines \\nHuman Rights in the Robot Age Report \\nDutch Artificial Intelligence Manifesto \\n',\n",
       "  'Artificial intelligence and privacy \\nDiscussion Paper on Artificial Intelligence (AI) and Personal \\nData - Fostering Responsible Development and Adoption of AI \\nMid- to Long-Term Master Plan in Preparation for the Intelligent \\nInformation Society \\nAI Principles of Telefónica \\nAI Principles & Ethics \\nPrinciples of robotics \\nThe Ethics of Code: Developing AI for Business with Five Core \\nPrinciples \\nBig data, artificial intelligence, machine learning and data \\nprotection \\nDeepMind Ethics & Society Principles \\nBusiness Ethics and Artificial Intelligence \\nAI in the UK: ready, willing and able? \\nArtificial Intelligence (AI) in Health \\nInitial code of conduct for data-driven health and care technology \\nEthics Framework - Responsible AI \\nThe responsible AI framework \\nResponsible AI and robotics. An ethical framework. \\nMachine learning: the power and promise of computers that learn \\nby example \\nEthical, social, and political challenges of Artificial Intelligence \\nin Health \\nUnified Ethical Frame for Big Data Analysis. IAF Big Data \\nEthics Initiative, Part A \\nThe AI Now Report. The Social and Economic Implications of \\nArtificial Intelligence Technologies in the Near-Term \\nStatement on Algorithmic Transparency and Accountability \\nAI Principles \\nAI - Our approach \\nArtificial Intelligence. The Public Policy Opportunity \\nIBM’s Principles for Trust and Transparency \\nOpenAI Charter \\nOur principles \\nPolicy Recommendations on Augmented Intelligence in Health \\nCare H-480.940 \\nEveryday Ethics for Artificial Intelligence. A practical guide for \\ndesigners & developers \\nGoverning Artificial Intelligence. Upholding Human Rights & \\nDignity \\nIntel’s AI Privacy Policy White Paper. Protecting individuals’ \\nprivacy and data in the artificial intelligence world \\nIntroducing Unity’s Guiding Principles for Ethical AI – Unity \\nBlog \\nDigital Decisions \\nScience, Law and Society (SLS) Initiative \\nAI Now 2018 Report \\nResponsible bots: 10 guidelines for developers of conversational \\nAI \\nPreparing for the future of Artificial Intelligence \\n',\n",
       "  'The National Artificial Intelligence Research and Development \\nStrategic Plan \\n',\n",
       "  ' \\n',\n",
       "  'Department of Industry Innovation and Science \\n',\n",
       "  'Université de Montréal \\nMinistry of Economic Affairs and Employment \\n',\n",
       "  'Tieto \\nOP Group \\nFrench Data Protection Authority (CNIL)  \\n',\n",
       "  'Mission Villani \\n',\n",
       "  \"CERNA (Allistene) \\nDeutsche Telekom \\nSAP \\nFederal Ministry of Transport and Digital Infrastructure, Ethics \\nCommission \\nIcelandic Institute for Intelligent Machines (IIIM) \\nNational Institution for Transforming India (Niti Aayog) \\nAgenzia per l'Italia Digitale (AGID) \\nJapanese Society for Artificial Intelligence \\n\",\n",
       "  'Advisory Board on Artificial Intelligence and Human Society \\n(initiative of the Minister of State for Science and Technology \\nPolicy) \\nInstitute for Information and Communications Policy (IICP), The \\nConference toward AI Network Society \\nSONY \\nThe Rathenau Institute \\nSpecial Interest Group on Artificial Intelligence (SIGAI), ICT \\nPlatform Netherlands (IPN) \\nThe Norwegian Data Protection Authority \\nPersonal Data Protection Commission Singapore \\n',\n",
       "  'Government of the Republic of Korea \\n',\n",
       "  'Telefonica \\nSmart Dubai \\nEngineering and Physical Sciences Research Council UK (EPSRC) \\nSage \\n',\n",
       "  \"Information Commissioner's Office \\n\",\n",
       "  'DeepMind Ethics & Society \\nInstitute of Business Ethics \\nUK House of Lords, Select Committee on Artificial Intelligence \\nRoyal College of Physicians \\nUK Department of Health & Social Care \\nMachine Intelligence Garage Ethics Committee \\nPriceWaterhouseCoopers UK \\nAccenture UK \\nThe Royal Society \\n',\n",
       "  'Future Advocacy \\n',\n",
       "  'The Information Accountability Foundation \\n',\n",
       "  'AI Now Institute \\n',\n",
       "  'Association for Computing Machinery (ACM) \\nFuture of Life Institute \\nMicrosoft \\nIntel Corporation \\nIBM \\nOpenAI \\nGoogle \\nAmerican Medical Association (AMA) \\n',\n",
       "  'IBM \\n',\n",
       "  'Data & Society \\n',\n",
       "  'Intel Corporation \\n',\n",
       "  'Unity Technologies \\n',\n",
       "  'Center for Democracy & Technology \\nThe Future Society \\nAI Now Institute \\nMicrosoft \\n',\n",
       "  'Executive Office of the President; National Science and Technology \\nCouncil; Committee on Technology \\nNational Science and Technology Council; Networking and \\nInformation Technology Research and Development Subcommittee \\n',\n",
       "  ' \\n',\n",
       "  '4 \\n',\n",
       "  'Country of \\nissuer \\nAustralia \\n',\n",
       "  'Canada \\nFinland \\n',\n",
       "  'Finland \\nFinland \\nFrance \\n',\n",
       "  'France \\n',\n",
       "  'France \\nGermany \\nGermany \\nGermany \\n',\n",
       "  'Iceland \\nIndia \\nItaly \\nJapan \\n',\n",
       "  'Japan \\n',\n",
       "  'Japan \\n',\n",
       "  'Japan \\nNetherlands \\nNetherlands \\n',\n",
       "  'Norway \\nSingapore \\n',\n",
       "  'South Korea \\n',\n",
       "  'Spain \\nUAE \\nUK \\nUK \\n',\n",
       "  'UK \\n',\n",
       "  'UK \\nUK \\nUK \\nUK \\nUK \\nUK \\nUK \\nUK \\nUK \\n',\n",
       "  'UK \\n',\n",
       "  'UK \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\nUSA \\nUSA \\nUSA \\nUSA \\nUSA \\nUSA \\nUSA \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\nUSA \\nUSA \\nUSA \\n',\n",
       "  'USA \\n',\n",
       "  'USA \\n'],\n",
       " ['AI Now Institute \\nThe Greens (Green Working Group Robots) \\nEuropean Parliament \\n',\n",
       "  'High-Level Expert Group on Artificial Intelligence \\nAI4People \\n',\n",
       "  'Concil of Europe: European Commission for the efficiency of \\nJustice (CEPEJ) \\nEuropean Commission, European Group on Ethics in Science and \\nNew Technologies \\nInternet Society \\nCOMEST/UNESCO \\nSoftware & Information Industry Association (SIIA), Public Policy \\nDivision \\nInformation Technology Industry Council (ITI) \\nInstitute of Electrical and Electronics Engineers (IEEE), The IEEE \\nGlobal Initiative on Ethics of Autonomous and Intelligent Systems \\nUNI Global Union \\nFuture of Humanity Institute; University of Oxford; Centre for the \\nStudy of Existential Risk; University of Cambridge; Center for a \\nNew American Security; Electronic Frontier Foundation; OpenAI \\nWEF, Global Future Council on Human Rights 2016-2018 \\n',\n",
       "  'Privacy International & Article 19 \\n',\n",
       "  'Access Now ; Amnesty International \\n',\n",
       "  'Leaders of the G7 \\n',\n",
       "  'W20 \\nICDPPC \\nThe Public Voice \\nAmerican College of Radiology; European Society of Radiology; \\nRadiology Society of North America; Society for Imaging \\nInformatics in Medicine; European Society of Medical Imaging \\nInformatics; Canadian Association of Radiologists; American \\nAssociation of Physicists in Medicine \\nInstitute of Electrical and Electronics Engineers (IEEE), The IEEE \\nGlobal Initiative on Ethics of Autonomous and Intelligent Systems \\n',\n",
       "  'Partnership on AI \\nFairness, Accountability, and Transparency in Machine Learning \\n(FATML) \\nWomen leading in AI \\n',\n",
       "  ' \\n',\n",
       "  '5 \\n',\n",
       "  'USA \\nEU \\nEU \\n',\n",
       "  'EU \\nEU \\n',\n",
       "  'EU \\n',\n",
       "  'EU \\n',\n",
       "  'international \\ninternational \\ninternational \\n',\n",
       "  'international \\ninternational \\n',\n",
       "  'international \\ninternational \\n',\n",
       "  'international \\n',\n",
       "  'international \\n',\n",
       "  'international \\n',\n",
       "  'international \\n',\n",
       "  'international \\ninternational \\ninternational \\ninternational \\n',\n",
       "  'international \\n',\n",
       "  'n.a. \\nn.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  ' \\nIn  terms  of  geographic  distribution,  data  show  a  significant  representation  of  more \\neconomically  developed  countries  (MEDC),  with  the  USA  (n=20;  23.8%)  and  the  UK \\n(n=14;  16.7%)  together  accounting  for  more  than  a  third  of  all  ethical  AI  principles, \\nfollowed by Japan (n=4; 4.8%), Germany, France, and Finland (each n=3; 3.6% each). The \\ncumulative number of sources from the European Union, comprising both documents issued \\nby EU institutions (n=6) and documents issued within each member state (13 in total), \\naccounts  for  19  documents  overall.  African  and  South-American  countries  are  not \\nrepresented independently from international or supra-national organisations (cf. Figure 1). \\n \\n',\n",
       "  ' \\n',\n",
       "  \"AI Now 2017 Report \\nPosition on Robotics and Artificial Intelligence \\nReport with recommendations to the Commission on Civil Law \\nRules on Robotics \\nEthics Guidelines for Trustworthy AI \\nAI4People—An Ethical Framework for a Good AI Society: \\nOpportunities, Risks, Principles, and Recommendations \\nEuropean ethical Charter on the use of Artificial Intelligence in \\njudicial systems and their environment \\nStatement on Artificial Intelligence, Robotics and 'Autonomous' \\nSystems \\nArtificial Intelligence and Machine Learning: Policy Paper \\nReport of COMEST on Robotics Ethics \\nEthical Principles for Artificial Intelligence and Data Analytics \\n\",\n",
       "  'ITI AI Policy Principles \\nEthically Aligned Design. A Vision for Prioritizing Human Well-\\nbeing with Autonomous and Intelligent Systems, version 2 \\nTop 10 Principles for Ethical Artificial Intelligence \\nThe Malicious Use of Artificial Intelligence: Forecasting, \\nPrevention, and Mitigation \\n',\n",
       "  'White Paper: How to Prevent Discriminatory Outcomes in \\nMachine Learning \\nPrivacy and Freedom of Expression In the Age of Artificial \\nIntelligence \\nThe Toronto Declaration: Protecting the right to equality and non-\\ndiscrimination in machine learning systems \\nCharlevoix Common Vision for the Future of Artificial \\nIntelligence \\nArtificial Intelligence: open questions about gender inclusion \\nDeclaration on ethics and data protection in Artificial Intelligence \\nUniversal Guidelines for Artificial Intelligence \\nEthics of AI in Radiology: European and North American \\nMultisociety Statement \\n',\n",
       "  'Ethically Aligned Design: A Vision for Prioritizing Human Well-\\nbeing with Autonomous and Intelligent Systems, First Edition \\n(EAD1e) \\nTenets \\nPrinciples for Accountable Algorithms and a Social Impact \\nStatement for Algorithms \\n10 Principles of responsible AI \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '6 \\n',\n",
       "  'Figure 1- Geographic distribution of issuers of ethical AI guidelines by number of documents released \\n',\n",
       "  ' \\n',\n",
       "  'Figure  1:  Geographic  distribution  of  issuers  of  ethical  AI  guidelines  by  number  of \\ndocuments released. Most ethics guidelines are released in the United States (n=20) and \\nwithin  the  European  Union  (19),  followed  by  the  United  Kingdom  (14)  and  Japan  (4). \\nCanada,  Iceland,  Norway,  the  United  Arab  Emirates,  India,  Singapore,  South  Korea, \\nAustralia are represented with 1 document each. Having endorsed a distinct G7 statement, \\nmember  states  of  the  G7  countries  are  highlighted  separately.  Map  created  using \\nmapchart.net. \\n \\nData  breakdown  by  target  audience  indicates  that  most  principles  and  guidelines  are \\naddressed to multiple stakeholder groups (n=27; 32.1%). Another significant portion of the \\ndocuments is self-directed, as they are addressed to a category of stakeholders within the \\nsphere of activity of the issuer such as the members of the issuing organisation or the issuing \\ncompany’s employees (n=24; 28.6%). Finally, some documents target the public sector \\n(n=10;  11.9%),  the  private  sector  (n=5;  6.0%),  or  other  specific  stakeholders  beyond \\nmembers  of  the  issuing  organisation,  namely  developers  or  designers  (n=3;  3.6%), \\n‘organisations’ (n=1; 1.2%) and researchers (n=1; 1.2%). 13 sources (15.5%) do not specify \\ntheir target audience (cf. SI Table S1).  \\n \\nEleven overarching ethical values and principles have emerged from our content analysis. \\nThese are, by frequency of the number of sources in which they were featured: transparency, \\njustice and  fairness,  non-maleficence, responsibility, privacy, beneficence, freedom and \\nautonomy, trust, dignity, sustainability, and solidarity (cf. Table 2). \\n \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '7 \\n',\n",
       "  'Table 2 – Ethical principles identified in existing AI guidelines \\n',\n",
       "  'Ethical principle \\n',\n",
       "  'Transparency \\n',\n",
       "  'Number of \\ndocuments \\n',\n",
       "  '73/84 \\n',\n",
       "  'Justice & fairness \\n',\n",
       "  '68/84 \\n',\n",
       "  'Non-maleficence \\n',\n",
       "  '60/84 \\n',\n",
       "  'Responsibility \\nPrivacy \\nBeneficence \\nFreedom & \\nautonomy \\nTrust \\nSustainability \\nDignity \\nSolidarity \\n',\n",
       "  '60/84 \\n47/84 \\n41/84 \\n34/84 \\n',\n",
       "  '28/84 \\n14/84 \\n13/84 \\n6/84 \\n',\n",
       "  'Included codes \\n',\n",
       "  'Transparency, explainability, explicability, understandability, \\ninterpretability, communication, disclosure, showing \\nJustice, fairness, consistency, inclusion, equality, equity, (non-)bias, \\n(non-)discrimination, diversity, plurality, accessibility, reversibility, \\nremedy, redress, challenge, access and distribution \\nNon-maleficence, security, safety, harm, protection, precaution, \\nprevention, integrity (bodily or mental), non-subversion \\nResponsibility, accountability, liability, acting with integrity \\nPrivacy, personal or private information \\nBenefits, beneficence, well-being, peace, social good, common good \\nFreedom, autonomy, consent, choice, self-determination, liberty, \\nempowerment \\nTrust \\nSustainability, environment (nature), energy, resources (energy) \\nDignity \\nSolidarity, social security, cohesion \\n',\n",
       "  ' \\nNo  single  ethical principle  appeared to be common to the entire corpus of documents, \\nalthough there is an emerging convergence around the following principles: transparency, \\njustice  and  fairness,  non-maleficence,  responsibility,  and  privacy.  These  principles  are \\nreferenced  in  more  than  half  of  all  the  sources.  Nonetheless,  further  thematic  analysis \\nreveals significant semantic and conceptual divergences in both how the eleven ethical \\nprinciples are interpreted and the specific recommendations or areas of concern derived \\nfrom each. A detailed thematic evaluation is presented in the following. \\n \\nTransparency \\nFeatured  in  73/84  sources,  transparency  is  the  most  prevalent  principle  in  the  current \\nliterature. Thematic analysis reveals significant variation in relation to the interpretation, \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '8 \\n',\n",
       "  'its  benefit  for \\n',\n",
       "  'auditable  by  humans37,60 \\n',\n",
       "  'though  some  sources  underline \\n',\n",
       "  'justification, domain of application, and mode of achievement. References to transparency \\ncomprise efforts to increase explainability, interpretability or other acts of communication \\nand disclosure (cf. Table 2). Principal domains of application include data use23–26, human-\\nAI interaction23,27–35, automated decisions26,36–46, and the purpose of data use or application \\nof AI systems24,27,47–51. Primarily, transparency is presented as a way to minimize harm and \\nimprove  AI36–38,44,45,49,52–55, \\nlegal \\nreasons37,45,46,49,50,52  or  to  foster  trust23,24,29,33,36,37,48,51,52,56–58.  A  few  sources  also  link \\ntransparency to dialogue, participation, and the principles of democracy30,41,49,50,52,59. \\n \\nTo achieve greater transparency, many sources suggest increased disclosure of information \\nby  those  developing  or  deploying  AI  systems36,51,60,61,  although  specifications  regarding \\nwhat should be communicated vary greatly: use of AI45, source code31,52,62, data use35,47,50,58, \\nevidence  base  for  AI  use57,  limitations25,33,47,51,58,60,63,  laws62,64,  responsibility  for  AI40, \\ninvestments in AI44,65 and possible impact66. The provision of explanations ‘in non-technical \\nterms’26  or \\nand \\nauditability28,39,44,45,50,59,61,62,67,68 are mainly proposed by data protection offices and NPOs, \\nit  is  mostly  the  private  sector  that  suggests  technical  solutions27,30,52,59,69,70.  Alternative \\nmeasures focus on oversight45,47,48,55,62, interaction and mediation with stakeholders and the \\npublic24,32,36,51,61,71 and the facilitation of whistleblowing36,60. \\n \\nJustice, fairness, and equity \\nJustice is mainly expressed in terms of fairness23,25,27–29,48,50,58,60,66,72–77, and of prevention, \\nmonitoring \\nand \\ndiscrimination28,33,36,38,44,45,50,55,56,60,68,81–84, the latter being significantly less referenced than \\nthe first two by the private sector. Whereas some sources focus on justice as respect for \\ndiversity31,38,56,59,65,66,70,72,78,80,85,86, inclusion31,45,47,51,72,80 and equality41,45,51,59,60,72,78, others \\ncall  for  a  possibility  to  appeal  or  challenge  decisions28,35–37,74,79,  or  the  right  to \\nredress33,42,45,46,50,68,85 and remedy45,48. Sources also emphasize the importance of fair access \\nto AI59,70,87, to data33,37,44,67,83,88–90, and to the benefits of AI37,38,80,91. Issuers from the public \\nsector place particular emphasis on AI’s impact on the labor market37,38,55,84,92, and the need \\nto address democratic33,38,59,73 or societal31,48,55,65 issues. Sources focusing on the risk of \\nbiases  within  datasets  underline  the  importance  of  acquiring  and  processing  accurate, \\ncomplete and diverse data23,28,52,70,93, especially training data27,33,35,38,52,58. \\n',\n",
       "  'unwanted  bias23,28,33,40,47,52,54,58,64,69,73,74,78–80 \\n',\n",
       "  'is \\n',\n",
       "  'encouraged.  Whereas \\n',\n",
       "  'audits \\n',\n",
       "  'or  mitigation \\n',\n",
       "  'of \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '9 \\n',\n",
       "  'society  or  other \\n',\n",
       "  'relevant \\n',\n",
       "  'increased  attention \\n',\n",
       "  'stakeholders \\nto \\n',\n",
       "  ' \\nIf specified, the preservation and promotion of justice are proposed to be pursued through: \\n(a) technical solutions such as standards50,68,89 or explicit normative encoding28,37,43,67; (b) \\ntransparency54,62, notably by providing information36,38,79 and raising public awareness of \\nexisting rights and regulation28,59; (c) testing52,58,67,69, monitoring54,56 and auditing39,46,50,67, \\nthe preferred solution of notably data protection offices; (d) developing or strengthening the \\nrule of law and the right to appeal, recourse, redress, or remedy37,38,42,45,46,48,68,74,79; (e) via \\nsystemic  changes  and  processes  such  as  governmental  action42,45,87,92  and  oversight94,  a \\nmore interdisciplinary47,65,85,93 or otherwise diverse58,59,70,85,87,95 workforce, as well as better \\ninclusion  of  civil \\ninteractive \\nin  an \\nmanner28,33,41,46,55,57,58,65,68,69,79,80,86  and \\nthe  distribution  of \\nbenefits25,33,38,48,63,76. \\n \\nNon-maleficence \\nReferences  to  non-maleficence  outweigh  those  to  beneficence  by  a  factor  of  1.5  and \\nencompass general calls for safety and security80,90,96,97 or state that AI should never cause \\nforeseeable  or  unintentional  harm23,30,33,56,60,79.  More  granular  considerations  entail  the \\navoidance of specific risks or potential harms, e.g. intentional misuse via cyberwarfare and \\nmalicious hacking51,53,54,78,81,89, and suggest risk-management strategies. Harm is primarily \\ninterpreted  as discrimination38,44,47,48,50,95,98, violation of privacy23,35,44,64,78,98,99, or bodily \\nharm25,30,31,33,56,92,96,100. Less frequent characterizations include loss of trust30 or skills44, \\n‘radical  individualism’38,  the  risk  that  technological  progress  might  outpace  regulatory \\nmeasures57, negative impacts on long-term social well-being44, on infrastructure44, or on \\npsychological35,56, emotional56 or economic aspects44,56. \\n \\nHarm-prevention  guidelines  focus  primarily  on  technical  measures  and  governance \\nstrategies,  ranging  from \\nlevel  of  AI  research27,47,64,79,85,101, \\ndesign23,25,27,32,39,56,58, technology development and/or deployment54 to lateral and continuous \\napproaches33,55,63.  Technical  solutions  include  in-built  data  quality  evaluations25  or \\nsecurity23  and  privacy  by  design23,27,39,  though  notable  exceptions  also  advocate  for \\nestablishing  industry  standards30,64,102.  Proposed  governance  strategies  include  active \\ncooperation across disciplines and stakeholders33,47,53,62, compliance with existing or new \\nlegislation27,31,35,81,95,99, and the need to establish oversight processes and practices, notably \\n',\n",
       "  'interventions  at \\n',\n",
       "  'the \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '10 \\n',\n",
       "  'tests36,38,47,74,79, monitoring36,58, audits and assessments by internal units, customers, users, \\nindependent third parties, or governmental entities40,48,51,58,81,94,95,98, often geared towards \\nstandards for AI implementation and outcome assessment. Most sources explicitly mention \\npotential ‘dual-use’8,32,33,38,60,79 or imply that damages may be unavoidable, in which case \\nrisks  should  be  assessed40,48,51,  reduced40,69,72–74,  and  mitigated34,35,38,53,63,68,  and  the \\nattribution of liability should be clearly defined31,37,38,44,82. \\n \\nResponsibility and accountability \\nDespite widespread references to ‘responsible AI’43,51,78,83, responsibility and accountability \\nare  rarely  defined.  Nonetheless,  specific  recommendations \\ninclude  acting  with \\n‘integrity’47,52,60 and clarifying the attribution of responsibility and legal liability23,58,78,103, \\nif possible upfront36, in contracts52 or, alternatively, by centering on remedy26. In contrast, \\nother sources suggest focusing on the underlying reasons and processes that may lead to \\npotential  harm74,83. Yet others  underline the responsibility of whistleblowing in case of \\npotential harm36,55,60, and aim at promoting diversity49,92 or introducing ethics into STEM \\neducation59. Very different actors are named as being responsible and accountable for AI’s \\nactions  and  decisions:  AI  developers58,60,73,96,  designers36,44, \\n‘institutions’40,42  or \\n‘industry’69. Further disagreement emerged on whether AI should be held accountable in a \\nhuman-like  manner70  or  whether  humans  should  always  be  the  only  actors  who  are \\nultimately responsible for technological artifacts31,32,35,37,52,92. \\n \\nPrivacy \\nEthical  AI  sees  privacy  both  as  a  value  to  uphold44,64,75,99  and  as  a  right  to  be \\nprotected27,28,37,38,53. While often undefined, privacy is often presented in relation to data \\nprotection23,27,36,53,58,66,71,79,83,98 and data security27,35,64,66,88,98. A few sources link privacy to \\nfreedom38,53  or  trust74,92.  Suggested  modes  of  achievement  fall  into  three  categories: \\ntechnical solutions64,80 such as differential privacy74,89, privacy by design25,27,28,79,98, data \\nminimization36,58, and access control36,58, calls for more research47,64,74,98 and awareness64,74, \\nand  regulatory  approaches25,52,71,  with  sources  referring  to  legal  compliance  more \\nbroadly27,32,36,58,60,81, or suggesting certificates104 or the creation or adaptation of laws and \\nregulations to accommodate the specificities of AI64,74,88,105. \\n \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '11 \\n',\n",
       "  'Beneficence \\nWhile promoting good (beneficence in ethical terms) is often mentioned, it is rarely defined, \\nthough notable exceptions mention the augmentation of human senses86, the promotion of \\nhuman  well-being  and  flourishing34,90,  peace  and  happiness60,  the  creation  of  socio-\\neconomic opportunities36, and economic prosperity37,53. Similar uncertainty concerns the \\nactors that should benefit from AI: private sector issuers tend to highlight the benefit of AI \\nfor  customers23,48,  though  many  sources  require  AI  to  be  shared49,52,76  and  to  benefit \\n‘everyone’36,59,65,84, ‘humanity’27,37,44,60,100,102, both of the above48,66, ‘society’34,87, ‘as many \\npeople as possible’37,53,99, ‘all sentient creatures’83, the ‘planet’37,72 and the environment38,90. \\nStrategies for the promotion of good include aligning AI with human values34,44, advancing \\n‘scientific  understanding  of  the  world’100,  minimizing  power  concentration102  or, \\nconversely, using power ‘for the benefit of human rights’82; working more closely with \\n‘affected’  people65,  minimizing  conflicts  of  interests102;  proving  beneficence  through \\ncustomer  demand48  and feedback58,  and developing new metrics and measurements for \\nhuman well-being44,90. \\n \\nFreedom and autonomy \\nWhereas  some  sources  specifically  refer  to  the  freedom  of  expression28,73,82,105  or \\ninformational  self-determination28,90  and  ‘privacy-protecting  user  controls’58,  others \\ngenerally  promote  freedom31,69,72,  empowerment28,52,99  or  autonomy31,33,62,77,81,96.  Some \\ndocuments refer to autonomy as a positive freedom, specifically the freedom to flourish36, \\nto  self-determination  through  democratic  means38,  the  right  to  establish  and  develop \\nrelationships  with  other  human  beings38,92,  the  freedom  to  withdraw  consent67,  or  the \\nfreedom to use a preferred platform or technology73,80. Other documents focus on negative \\nfreedom,  for  example  freedom  from  technological  experimentation82,  manipulation33  or \\nsurveillance38. Freedom and autonomy are believed to be promoted through transparency \\nand predictable AI38, by not ‘reducing options for and knowledge of citizens’38, by actively \\nincreasing people’s knowledge about AI36,52,62, giving notice and consent79 or, conversely, \\nby  actively  refraining  from  collecting  and  spreading  data  in  absence  of  informed \\nconsent30,38,44,55,74. \\n \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '12 \\n',\n",
       "  'trust \\n',\n",
       "  'in \\n',\n",
       "  'to  be \\n',\n",
       "  'require  AI \\n',\n",
       "  'Trust \\nReferences  to  trust  include  calls  for  trustworthy  AI  research  and  technology50,97,99, \\ntrustworthy  AI  developers  and  organisations51,60,66,  trustworthy  ‘design  principles’91,  or \\nunderline  the  importance  of  customers’  trust23,52,58,66,74,80.  Calls  for  trust  are  proposed \\nbecause  a  culture  of  trust  among  scientists  and  engineers  is  believed  to  support  the \\nachievement  of  other  organisational  goals99,  or  because  overall \\nthe \\nrecommendations, judgments and uses of AI is indispensable for AI to ‘fulfill its world \\nchanging potential’24. This last point is contradicted by one guideline explicitly warning \\nagainst  excessive  trust  in  AI81.  Suggestions  for  building  or  sustaining  trust  include \\neducation33, reliability50,51, accountability56, processes to monitor and evaluate the integrity \\nof AI systems over time51 and tools and techniques ensuring compliance with norms and \\nstandards43,63.  Whereas  some  guidelines \\ntransparent37,43,57,58, \\nunderstandable36,37, or explainable52 in order to build trust, another one explicitly suggests \\nthat, instead of demanding understandability, it should be ensured that AI fulfills public \\nexpectations50.  Other  reported  facilitators  of  trust  include  ‘a  Certificate  of  Fairness’104, \\nmulti-stakeholder  dialogue64,  awareness  about  the  value  of  using  personal  data74,  and \\navoiding harm30,56. \\n \\nSustainability \\nTo the extent that is referenced, sustainability calls for development and deployment of AI \\nto  consider  protecting  the  environment33,38,46,  improving  the  planet’s  ecosystem  and \\nbiodiversity37,  contributing  to  fairer  and  more  equal  societies65  and  promoting  peace66. \\nIdeally,  AI  creates  sustainable  systems44,76,90  that  process  data  sustainably43  and  whose \\ninsights remain valid over time48. To achieve this aim, AI should be designed, deployed and \\nmanaged with care38 to increase its energy efficiency and minimize its ecological footprint31. \\nTo make future developments sustainable, corporations are asked to create policies ensuring \\naccountability in the domain of potential job losses37 and to use challenges as an opportunity \\nfor innovation38. \\n \\nDignity \\nWhile dignity remains undefined in existing guidelines, safe the specification that it is a \\nprerogative of humans but not robots92, there is frequent reference to what it entails: dignity \\nis  intertwined  with  human  rights101  or  otherwise  means  avoiding  harm31,  forced \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '13 \\n',\n",
       "  'acceptance31, automated classification38, and unknown human-AI interaction38. It is argued \\nthat AI should not diminish33 or destroy80 but respect82, preserve69 or even increase human \\ndignity36,37. Dignity is believed to be preserved if it is respected by AI developers in the first \\nplace96 and promoted through new legislation38, through governance initiatives36, or through \\ngovernment-issued technical and methodological guidelines82. \\n \\nSolidarity \\nSolidarity is mostly referenced in relation to the implications of AI for the labor market104. \\nSources call for a strong social safety net37,84. They underline the need for redistributing the \\nbenefits of AI in order not to threaten social cohesion49 and respecting potentially vulnerable \\npersons and groups33. Lastly, there is a warning of data collection and practices focused on \\nindividuals which may undermine solidarity in favour of ‘radical individualism’38. \\n \\nDiscussion \\nWe found a rapid increase in the number and variety of guidance documents for ethical AI, \\ndemonstrating  the  increasing  active  involvement  of  the  international  community. \\nOrganisations publishing AI guidelines come from a wide range of sectors. In particular the \\nnearly equivalent proportion of documents issued by the public sector (i.e. governmental \\nand inter-governmental organisations) and the private sector (companies and private sector \\nalliances) indicate that the ethical challenges of AI concern both public entities and private \\nenterprises. However, there is significant divergence in the solutions proposed to meet the \\nethical challenges of AI. Further, the relative underrepresentation of geographic areas such \\nas Africa, South  and Central America  and Central Asia indicates that the international \\ndebate over ethical AI may not be happening globally in equal measures. MEDC countries \\nare  shaping  this  debate more than others, which raises concerns about neglecting local \\nknowledge, cultural pluralism and global fairness. \\n \\nThe proliferation of soft-law efforts can be interpreted as a governance response to advanced \\nresearch into AI, whose research output and market size have drastically increased106 in \\nrecent  years.  Our  analysis  shows  the  emergence  of  an  apparent  cross-stakeholder \\nconvergence on promoting the ethical principles of transparency, justice, non-maleficence, \\nresponsibility,  and  privacy.  Nonetheless,  our  thematic  analysis  reveals  substantive \\ndivergences in relation to four major factors: (i) how ethical principles are interpreted, (ii) \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '14 \\n',\n",
       "  'why they are deemed important, (iii) what issue, domain or actors they pertain to, and (iv) \\nhow  they  should  be  implemented.  Furthermore,  unclarity  remains  as  to  which  ethical \\nprinciples should be prioritized, how conflicts between ethical principles should be resolved, \\nwho should enforce ethical oversight on AI and how researchers and institutions can comply \\nwith the resulting guidelines. These findings suggest the existence of a gap at the cross-\\nsection of principles formulation and their implementation into practice which can hardly \\nbe solved through technical expertise or top-down approaches. \\n \\nAlthough  no  single  ethical  principle  is  explicitly  endorsed  by  all  existing  guidelines, \\ntransparency,  justice  and fairness, non-maleficence, responsibility and privacy are each \\nreferenced in more than half of all guidelines. This focus could be indicating a developing \\nconvergence  on  ethical  AI  around  these  principles  in  the  global  policy  landscape.  In \\nparticular, the prevalence of calls for transparency, justice and fairness points to an emerging \\nmoral priority to require transparent processes throughout the entire AI continuum (from \\ntransparency in the development and design of algorithms to transparent practices for AI \\nuse), and to caution the global community against the risk that AI might increase inequality \\nif justice and fairness considerations are not adequately addressed. Both these themes appear \\nto be intertwined with the theme of responsibility, as the promotion of both transparency \\nand justice seems to postulate increased responsibility and accountability on the side of AI \\nmakers and deployers. \\n \\nIt has been argued that transparency is not an ethical principle per se, but rather “a proethical \\ncondition for enabling or impairing other ethical practices or principles”107. The proethical \\nnature of transparency might partly explain its higher prevalence compared to other ethical \\nprinciples. It is notable that current guidelines place significant value in the promotion of \\nresponsibility and accountability, yet few of them emphasize the duty of all stakeholders \\ninvolved in the development and deployment of AI to act with integrity. This mismatch is \\nprobably associated with the observation that existing guidelines fail to establish  a  full \\ncorrespondence  between principles and actionable requirements, with several principles \\nremaining  uncharacterized  or  disconnected  from  the  requirements  necessary  for  their \\nrealization.  \\n \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '15 \\n',\n",
       "  'As codes related to non-maleficence outnumber those related to beneficence, it appears that, \\nfor the current AI community, the moral obligation to preventing harm takes precedence \\nover the promotion of good. This fact can be partly interpreted as an instance of the so-\\ncalled  negativity  bias,  i.e.  a  general  cognitive  bias to  give  greater  weight  to  negative \\nentities108,109. This negative characterization of ethical values is further emphasized by the \\nfact that existing guidelines focus primarily on how to preserve privacy, dignity, autonomy \\nand individual freedom in spite of advances in AI, while largely neglecting whether these \\nprinciples could be promoted through responsible innovation in AI110. \\n \\nThe issue of trust in AI, while being addressed by less than one third of all sources, tackles \\na critical ethical dilemma in AI governance: determining whether it is morally desirable to \\nfoster public trust in AI. While several sources, especially those produced within the private \\nsector, highlight the importance of fostering trust in AI through educational and awareness-\\nraising activities, a smaller number of sources contend that trust in AI may actually diminish \\nscrutiny and undermine some societal obligations of AI producers111. This possibility would \\nchallenge the dominant view in AI ethics that building public trust in AI is a fundamental \\nrequirement for ethical governance112.  \\n \\nThe relative thematic underrepresentation of sustainability and solidarity suggests that these \\ntopics might be currently flying under the radar of the mainstream ethical discourse on AI. \\nThe underrepresentation of sustainability-related principles is particularly problematic in \\nlight of the fact that the deployment of AI requires massive computational resources which, \\nin turn, require high energy consumption. The environmental impact of AI, however, does \\nnot only involve the negative effects of high-footprint digital infrastructures, but also the \\npossibility of harnessing AI for the benefit of ecosystems and the entire biosphere. This \\nlatter point, highlighted in a report by the World Economic Forum113 though not in the AI \\nguidelines by the same institution, requires wider endorsement to become entrenched in the \\nethical AI narrative. The ethical principle of solidarity is sparsely referenced, typically in \\nassociation with the development of inclusive strategies for the prevention of job losses and \\nunfair sharing of burdens. Little attention is devoted to promoting solidarity through the \\nemerging possibility of using AI expertise for solving humanitarian challenges, a mission \\nthat is currently being pursued, among others, by intergovernmental organisations such as \\nthe  United  Nations  Office  for  Project  Services  (UNOPS)114  or  the  World  Health \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '16 \\n',\n",
       "  'Organization (WHO) and private companies such as Microsoft115. As the humanitarian cost \\nof anthropogenic climate change is rapidly increasing116, the principles of sustainability and \\nsolidarity  appear  strictly  intertwined  though  poorly  represented  compared  to  other \\nprinciples. \\n \\nWhile numerical data indicate an emerging convergence around the promotion of some \\nethical principles, in-depth thematic analysis paints a more complicated picture, as there are \\ncritical differences in how these principles are interpreted as well as what requirements are \\nconsidered  to  be  necessary  for  their  realization.  Results  show  that  different  and  often \\nconflicting measures are proposed for the practical achievement of ethical AI. For example, \\nthe need for ever larger, more diverse datasets to “unbias” AI appears difficult to conciliate \\nwith the requirement to give individuals increased control over their data and its use in order \\nto respect their privacy and autonomy. Similar contrasts emerge between the requirement \\nof avoiding harm at all costs and that of balancing risks and benefits. Furthermore, it should \\nbe noted that risk-benefit evaluations will lead to different results depending on whose well-\\nbeing it will be optimized for by which actors. If not resolved, such divergences and tensions \\nmay undermine attempts to develop a global agenda for ethical AI.  \\n \\nDespite  a  general  agreement  that  AI  should  be  ethical,  significant  divergences  emerge \\nwithin and between guidelines for ethical AI. Furthermore, uncertainty remains regarding \\nhow  ethical  principles  and  guidelines  should  be  implemented.  These  challenges  have \\nimplications for science policy, technology governance and research ethics. At the policy \\nlevel,  they  urge  increased  cooperative  efforts  among  governmental  organisations  to \\nharmonize and prioritize their AI agendas, an effort that can be mediated and facilitated by \\ninter-governmental organisations. While harmonization is desirable, however, it should not \\ncome  at  the  costs  of  obliterating  cultural  and  moral  pluralism  over  AI.  Therefore,  a \\nfundamental challenge for developing a global agenda for AI is balancing the need for cross-\\nnational harmonization over the respect for cultural diversity and moral pluralism. This \\nchallenge  will  require  the  development  of  deliberative  mechanisms  to  adjudicate \\ndisagreement  concerning  the  values  and  implications  of  AI  advances  among  different \\nstakeholders  from  different  global  regions.  At  the  level  of  technology  governance, \\nharmonization is typically implemented in terms of standardizations. Efforts in this direction \\nhave been made, among others, by the Institute of Electrical and Electronics Engineers \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '17 \\n',\n",
       "  '(IEEE) through the “Ethically Aligned Designed”  initiative117. Finally, soft governance \\nmechanisms such as Independent Review Boards (IRBs) will be increasingly required to \\nassess the ethical validity of AI applications in scientific research, especially those in the \\nacademic domain. However, AI applications by governments or private corporations will \\nunlikely fall under their oversight, unless significant expansions to the IRBs’ purview are \\nmade. \\n \\nThe international community seems to converge on the importance of transparency, non-\\nmaleficence, responsibility, and privacy for the development and deployment of ethical AI. \\nHowever, enriching the current ethical AI discourse through a better appraisal of critical yet \\nunderrepresented ethical principles such as human dignity, solidarity and sustainability is \\nlikely  to  result  into  a  better  articulated  ethical  landscape  for  artificial  intelligence. \\nFurthermore, shifting the focus from principle-formulation to translation into practice must \\nbe the next step. A global agenda for ethical AI should balance the need for cross-national \\nand cross-domain harmonization over the respect for cultural diversity and moral pluralism. \\nOverall, our review provides a useful starting point for understanding the inherent diversity \\nof current principles and guidelines for ethical AI and outlines the challenges ahead for the \\nglobal community. \\n \\nLimitations \\nThis study has several limitations. First, guidelines and soft-law documents are an instance \\nof gray literature, hence not indexed in conventional scholarly databases. Therefore, their \\nretrieval is inevitably less replicable and unbiased compared to systematic database search \\nof  peer-reviewed  literature.  Following  best  practices  for  gray  literature  review,  this \\nlimitation has been mitigated by developing a discovery and eligibility protocol which was \\npilot-tested  prior  to  data  collection.  Although  search  results  from  search  engines  are \\npersonalized, the risk of personalization influencing discovery has been mitigated through \\nthe broadness of both the keyword search and the inclusion of results. A language bias may \\nhave skewed our corpus towards English results. Our content analysis presents the typical \\nlimitations of qualitative analytic methods. Following best practices for content analysis, \\nthis limitation has been mitigated by developing an inductive coding strategy which was \\nconducted independently by two reviewers to minimize subjective bias. Finally, given the \\nrapid pace of publication of AI guidance documents, there is a possibility that new policy \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '18 \\n',\n",
       "  'documents  were  published  after  our  search  was  completed.  To  minimize  this  risk, \\ncontinuous monitoring of the literature was conducted in parallel with the data analysis and \\nuntil April 23, 2019.  \\n \\nMethods \\nWe conducted a scoping review of the gray literature reporting principles and guidelines for \\nethical AI. A scoping review is a method aimed at synthesizing and mapping the existing \\nliterature118, which is considered particularly suitable for complex or heterogeneous areas \\nof research118,119. Given the absence of a unified database for AI-specific ethics guidelines, \\nwe developed a protocol for discovery and eligibility, adapted from the Preferred Reporting \\nItems for Systematic Reviews and Meta-Analyses (PRISMA) framework120. The protocol \\nwas pilot-tested and calibrated prior to data collection. Following best practices for gray \\nliterature retrieval, a multi-stage screening strategy involving both inductive screening via \\nsearch engine and deductive identification of relevant entities with associated websites and \\nonline  collections  was  conducted.  To  achieve  comprehensiveness  and  systematicity, \\nrelevant  documents  were  retrieved  by  relying  on  three  sequential  search  strategies  (cf. \\nFigure  2):  First,  a  manual  search  of  four  link  hub  webpages  (“linkhubs”)121–124  was \\nperformed. 68 sources were retrieved, out of which 30 were eligible (27 after removing \\nduplicates). Second, a keyword-based web search of the Google.com search engine was \\nperformed in private browsing modus, after log-out from personal accounts and erasure of \\nall web cookies and history.125,126 Search was performed using the following keywords: [AI \\nprinciples],  [artificial  intelligence  principles],  [AI  guidelines],  [artificial  intelligence \\nguidelines], [ethical AI] and [ethical artificial intelligence]. Every link in the first thirty \\nsearch results was followed and screened (i) for AI principles, resulting in 10 more sources \\nafter  removing duplicates, and (ii) for articles mentioning AI principles, leading to the \\nidentification of 3 additional non-duplicate sources. The remaining Google results up to the \\n200th listings for each Google search were followed and screened for AI principles only. \\nWithin these additional 1020 link listings we identified 15 non-duplicate documents. After \\nidentifying relevant documents through the two processes above, we used citation-chaining \\nto manually screen the full-texts and, if applicable, reference lists of all eligible sources in \\norder  to  identify  other  relevant  documents.  17  additional  sources  were  identified.  We \\ncontinued to monitor the literature in parallel with the data analysis and until April 23, 2019, \\nto retrieve eligible documents that were released after our search was completed. Twelve \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '19 \\n',\n",
       "  'new  sources  were  included  within  this  extended  time  frame.  To  ensure  theoretical \\nsaturation,  we  exhausted  the  citation  chaining  within  all  identified  sources  until  no \\nadditional relevant document could be identified. \\n \\nFigure 2- PRISMA-based flowchart of retrieval process \\n',\n",
       "  ' \\n',\n",
       "  'Flowchart  of  our  retrieval  process  based  on  the  PRISMA  template  for  systematic \\nreviews127.  We  relied  on  three  search  strategies  (linkhubs,  web  search  and  citation \\nchaining) and added the most recent records manually, identifying a total of 84 eligible, \\nnon-duplicate documents containing ethical principles for AI. \\n \\nBased  on  our  inclusion/exclusion  criteria,  policy  documents  (including  principles, \\nguidelines  and  institutional  reports)  included  in  the  final  synthesis  were  (i)  written  in \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  ' \\n',\n",
       "  '20 \\n',\n",
       "  'English, German, French, Italian, Greek; (ii) issued by institutional entities from both the \\npublic  and  the  public  sectors;  (iii)  referred  explicitly  in  their  title/description  to  AI  or \\nancillary notions, (iv) expressed a normative ethical stance defined as a moral preference \\nfor a defined course of action (cf. SI Table S2). Following full-text screening, 84 sources or \\nparts thereof were included in the final synthesis (cf. SI Table S1). \\n \\nContent analysis of the 84 sources was independently conducted by two researchers in two \\ncycles of manual coding and one cycle of code mapping within the qualitative data analysis \\nsoftware Nvivo for Mac v.11.4. During the first cycle of coding, one researcher exhaustively \\ntagged all relevant text through inductive coding128 attributing a total of 3457 codes, out of \\nwhich 1180 were subsequently discovered to pertain to ethical principles. Subsequently, \\ntwo researchers conducted the code mapping process in order to reduce subjective bias. The \\nprocess  of  code  mapping,  a  method  for  qualitative  metasynthesis129,  consisted  of  two \\niterations  of  themeing128,  whereby  categories  were  first  attributed  to  each  code,  then \\ncategorized  in  turn  (cf.  SI  Table  S3).  For  the  theming  of  ethical  principles,  we  relied \\ndeductively on normative ethical literature. Ethical categories were inspected and assessed \\nfor  consistency  by  two  researchers  with  primary  expertise  in  ethics.  Thirteen  ethical \\ncategories emerging from code mapping, two of which were merged with others due to \\nindependently assessed semantic and thematic proximity. Finally, we extracted significance \\nand frequency by applying focused coding, a second cycle coding methodology used for \\ninterpretive analysis128, to the data categorized in ethical categories. Consistency check was \\nperformed both by reference to the relevant ethical literature and a process of deliberative \\nmutual adjustment among the general principles and the particular judgments contained in \\nthe policy documents, an analytic strategy known as ‘reflective equilibrium’130. \\n \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '1 \\n',\n",
       "  'REFERENCES \\n \\n1.  Harari, Y. N. Reboot for the AI revolution. Nat. News 550, 324 (2017). \\n',\n",
       "  '2.  Appenzeller, T. The AI revolution in science. Science (2017). \\n',\n",
       "  'doi:10.1126/science.aan7064 \\n',\n",
       "  '3. \\n',\n",
       "  'Jordan, M. I. & Mitchell, T. M. Machine learning: Trends, perspectives, and prospects. \\n',\n",
       "  'Science 349, 255–260 (2015). \\n',\n",
       "  '4.  Stead, W. W. Clinical Implications and Challenges of Artificial Intelligence and Deep \\n',\n",
       "  'Learning. JAMA 320, 1107–1108 (2018). \\n',\n",
       "  '5.  Vayena, E., Blasimme, A. & Cohen, I. G. Machine learning in medicine: Addressing \\n',\n",
       "  'ethical challenges. PLOS Med. 15, e1002689 (2018). \\n',\n",
       "  '6.  Awad, E. et al. The Moral Machine experiment. Nature 563, 59 (2018). \\n',\n",
       "  '7.  Science must examine the future of work. Nat. News 550, 301 (2017). \\n',\n",
       "  '8.  Brundage, M. et al. The Malicious Use of Artificial Intelligence: Forecasting, \\n',\n",
       "  'Prevention, and Mitigation. (Future of Humanity Institute; University of Oxford; \\n',\n",
       "  'Centre for the Study of Existential Risk; University of Cambridge; Center for a New \\n',\n",
       "  'American Security; Electronic Frontier Foundation; OpenAI, 2018). \\n',\n",
       "  '9.  Zou, J. & Schiebinger, L. AI can be sexist and racist — it’s time to make it fair. \\n',\n",
       "  'Nature 559, 324 (2018). \\n',\n",
       "  '10.  Boddington, P. Towards a Code of Ethics for Artificial Intelligence. (Springer \\n',\n",
       "  'International Publishing, 2017). \\n',\n",
       "  '11.  Bostrom, N. & Yudkowsky, E. The ethics of artificial intelligence. in The Cambridge \\n',\n",
       "  'Handbook of Artificial Intelligence (eds. Frankish, K. & Ramsey, W. M.) 316–334 \\n',\n",
       "  '(Cambridge University Press, 2014). doi:10.1017/CBO9781139046855.020 \\n',\n",
       "  '12.  Etzioni, A. & Etzioni, O. AI Assisted Ethics. Ethics Inf. Technol. 18, 149–156 (2016). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '2 \\n',\n",
       "  '13.  Yuste, R. et al. Four ethical priorities for neurotechnologies and AI. Nat. News 551, \\n',\n",
       "  '159 (2017). \\n',\n",
       "  '14.  Cath, C., Wachter, S., Mittelstadt, B., Taddeo, M. & Floridi, L. Artificial Intelligence \\n',\n",
       "  'and the ‘Good Society’: the US, EU, and UK approach. Sci. Eng. Ethics 24, 505–528 \\n',\n",
       "  '(2018). \\n',\n",
       "  '15.  Zeng, Y., Lu, E. & Huangfu, C. Linking Artificial Intelligence Principles. \\n',\n",
       "  'ArXiv181204814 Cs (2018). \\n',\n",
       "  '16.  Greene, D., Hoffmann, A. L. & Stark, L. Better, Nicer, Clearer, Fairer: A Critical \\n',\n",
       "  'Assessment of the Movement for Ethical Artificial Intelligence and Machine \\n',\n",
       "  'Learning. in (2019). \\n',\n",
       "  '17.  Crawford, K. & Calo, R. There is a blind spot in AI research. Nat. News 538, 311 \\n',\n",
       "  '(2016). \\n',\n",
       "  '18.  Altman, M., Wood, A. & Vayena, E. A Harm-Reduction Framework for Algorithmic \\n',\n",
       "  'Fairness. IEEE Secur. Priv. 16, 34–45 (2018). \\n',\n",
       "  '19.  Bolukbasi, T., Chang, K.-W., Zou, J., Saligrama, V. & Kalai, A. Man is to Computer \\n',\n",
       "  'Programmer as Woman is to Homemaker? Debiasing Word Embeddings. \\n',\n",
       "  'ArXiv160706520 Cs Stat (2016). \\n',\n",
       "  '20.  O’Neil, C. Weapons of Math Destruction: How Big Data Increases Inequality and \\n',\n",
       "  'Threatens Democracy. (Crown, 2016). \\n',\n",
       "  '21.  Veale, M. & Binns, R. Fairer machine learning in the real world: Mitigating \\n',\n",
       "  'discrimination without collecting sensitive data. Big Data Soc. 4, 205395171774353 \\n',\n",
       "  '(2017). \\n',\n",
       "  '22.  Wagner, B. Ethics as an escape from regulation. From “ethics-washing” to ethics-\\n',\n",
       "  'shopping? in Being profiled: cogitas ergo sum\\u2009: 10 years of ‘profiling the European \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '3 \\n',\n",
       "  'citizen’ (eds. Bayamlioglu, E., Baraliuc, I., Janssens, L. A. W. & Hildebrandt, M.) 84–\\n',\n",
       "  '89 (Amsterdam University Press, 2018). \\n',\n",
       "  '23.  Deutsche Telekom. Deutsche Telekom’s guidelines for artificial intelligence. (2018). \\n',\n",
       "  '24.  IBM. Transparency and Trust in the Cognitive Era. IBM (2017). Available at: \\n',\n",
       "  'https://www.ibm.com/blogs/think/2017/01/ibm-cognitive-principles/. (Accessed: 21st \\n',\n",
       "  'February 2019) \\n',\n",
       "  '25.  Initial code of conduct for data-driven health and care technology. GOV.UK Available \\n',\n",
       "  'at: https://www.gov.uk/government/publications/code-of-conduct-for-data-driven-\\n',\n",
       "  'health-and-care-technology/initial-code-of-conduct-for-data-driven-health-and-care-\\n',\n",
       "  'technology. (Accessed: 1st November 2018) \\n',\n",
       "  '26.  Diakopoulos, N. et al. Principles for Accountable Algorithms. FATML | Principles for \\n',\n",
       "  'Accountable Algorithms and a Social Impact Statement for Algorithms (2016). \\n',\n",
       "  'Available at: http://www.fatml.org/resources/principles-for-accountable-algorithms. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '27.  Telefónica. Our Artificial Intelligence Principles. (2018). \\n',\n",
       "  '28.  Commission Nationale de l’Informatique et des Libertés (CNIL), European Data \\n',\n",
       "  'Protection Supervisor (EDPS) & Garante per la protezione dei dati personali. \\n',\n",
       "  'Declaration on Ethics and Data Protection in Artificial Intelligence. (2018). \\n',\n",
       "  '29.  IBM. Everyday Ethics for Artificial Intelligence. A practical guide for designers & \\n',\n",
       "  'developers. (2018). \\n',\n",
       "  '30.  Federal Ministry of Transport and Digital Infrastructure, Ethics Commission. BMVI - \\n',\n",
       "  'Ethics Commission’s complete report on automated and connected driving. (2017). \\n',\n",
       "  '31.  Green Digital Working Group. Position on Robotics and Artificial Intelligence. \\n',\n",
       "  '(2016). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '4 \\n',\n",
       "  '32.  EPSRC. Principles of robotics. Engineering and Physical Sciences Research Council \\n',\n",
       "  'UK (EPSRC) (2011). Available at: \\n',\n",
       "  'https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofr\\n',\n",
       "  'obotics/. (Accessed: 21st February 2019) \\n',\n",
       "  '33.  High-Level Expert Group on Artificial Intelligence. Ethics Guidelines for Trustworthy \\n',\n",
       "  'AI. (2019). \\n',\n",
       "  '34.  Dubai. AI Principles & Ethics. Smart Dubai (2019). Available at: \\n',\n",
       "  'http://www.smartdubai.ae/initiatives/ai-principles-ethics. (Accessed: 8th April 2019) \\n',\n",
       "  '35.  Dawson, D. et al. Artificial Intelligence: Australia’s Ethics Framework. (2019). \\n',\n",
       "  '36.  Internet Society. Artificial Intelligence & Machine Learning: Policy Paper. Internet \\n',\n",
       "  'Society (2017). Available at: \\n',\n",
       "  'https://www.internetsociety.org/resources/doc/2017/artificial-intelligence-and-\\n',\n",
       "  'machine-learning-policy-paper/. (Accessed: 21st February 2019) \\n',\n",
       "  '37.  UNI Global. 10 Principles for Ethical AI. (2017). \\n',\n",
       "  '38.  European Group on Ethics in Science and New Technologies. Statement on Artificial \\n',\n",
       "  'Intelligence, Robotics and ‘Autonomous’ Systems. (2018). \\n',\n",
       "  '39.  Information Commissioner’s Office UK. Big data, artificial intelligence, machine \\n',\n",
       "  'learning and data protection. (2017). \\n',\n",
       "  '40.  The Public Voice. Universal Guidelines for Artificial Intelligence. The Public Voice \\n',\n",
       "  '(2018). Available at: https://thepublicvoice.org/ai-universal-guidelines/. (Accessed: \\n',\n",
       "  '21st February 2019) \\n',\n",
       "  '41.  The Future Society. Science, Law and Society (SLS) Initiative. The Future Society \\n',\n",
       "  '(2018). Available at: \\n',\n",
       "  'https://web.archive.org/web/20180621203843/http://thefuturesociety.org/science-law-\\n',\n",
       "  'society-sls-initiative/. (Accessed: 25th February 2019) \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '5 \\n',\n",
       "  '42.  Association for Computing Machinery (ACM). Statement on Algorithmic \\n',\n",
       "  'Transparency and Accountability. (2017). \\n',\n",
       "  '43.  Special Interest Group on Artificial Intelligence. Dutch Artificial Intelligence \\n',\n",
       "  'Manifesto. (2018). \\n',\n",
       "  '44.  Ethically Aligned Design. A Vision for Prioritizing Human Well-being with \\n',\n",
       "  'Autonomous and Intelligent Systems. Ethically Aligned Design. A Vision for \\n',\n",
       "  'Prioritizing Human Well-being with Autonomous and Intelligent Systems V.2. \\n',\n",
       "  '(2017). \\n',\n",
       "  '45.  Access Now. The Toronto Declaration: Protecting the right to equality and non-\\n',\n",
       "  'discrimination in machine learning systems. (2018). \\n',\n",
       "  '46.  Floridi, L. et al. AI4People—An Ethical Framework for a Good AI Society: \\n',\n",
       "  'Opportunities, Risks, Principles, and Recommendations. (AI4People). \\n',\n",
       "  '47.  SAP. SAP’s guiding principles for artificial intelligence (AI). SAP (2018). Available \\n',\n",
       "  'at: https://www.sap.com/products/leonardo/machine-learning/ai-ethics.html#guiding-\\n',\n",
       "  'principles. (Accessed: 19th February 2019) \\n',\n",
       "  '48.  Software & Information Industry Association (SIIA), Public Policy Division. Ethical \\n',\n",
       "  'Principles for Artificial Intelligence and Data Analytics. (2017). \\n',\n",
       "  '49.  Koski, O. & Husso, K. Work in the age of artificial intelligence. (2018). \\n',\n",
       "  '50.  Center for Democracy & Technology. Digital Decisions. Center for Democracy & \\n',\n",
       "  'Technology Available at: https://cdt.org/issue/privacy-data/digital-decisions/. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '51.  MI Garage. Ethics Framework - Responsible AI. MI Garage Available at: \\n',\n",
       "  'https://www.migarage.ai/ethics-framework/. (Accessed: 22nd February 2019) \\n',\n",
       "  '52.  Institute of Business Ethics. Business Ethics and Artificial Intelligence. (2018). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '6 \\n',\n",
       "  '53.  Asilomar AI Principles. Future of Life Institute (2017). Available at: \\n',\n",
       "  'https://futureoflife.org/ai-principles/. (Accessed: 1st November 2018) \\n',\n",
       "  '54.  PricewaterhouseCoopers. The responsible AI framework. PwC Available at: \\n',\n",
       "  'https://www.pwc.co.uk/services/audit-assurance/risk-assurance/services/technology-\\n',\n",
       "  'risk/technology-risk-insights/accelerating-innovation-through-responsible-\\n',\n",
       "  'ai/responsible-ai-framework.html. (Accessed: 22nd February 2019) \\n',\n",
       "  '55.  Whittaker, M. et al. AI Now Report 2018. (2018). \\n',\n",
       "  '56.  Personal Data Protection Commission Singapore. Discussion Paper on AI and \\n',\n",
       "  'Personal Data -- Fostering Responsible Development and Adoption of AI. (2018). \\n',\n",
       "  '57.  Royal College of Physicians. Artificial Intelligence (AI) in Health. RCP London \\n',\n",
       "  '(2018). Available at: https://www.rcplondon.ac.uk/projects/outputs/artificial-\\n',\n",
       "  'intelligence-ai-health.  \\n',\n",
       "  '58.  Microsoft. Responsible bots: 10 guidelines for developers of conversational AI. \\n',\n",
       "  '(2018). \\n',\n",
       "  '59.  Villani, C. For a meaningful Artificial Intelligence. Towards a French and European \\n',\n",
       "  'strategy. (Mission assigned by the Prime Minister Édouard Philippe, 2018). \\n',\n",
       "  '60.  The Japanese Society for Artificial Intelligence. The Japanese Society for Artificial \\n',\n",
       "  'Intelligence Ethical Guidelines. (2017). \\n',\n",
       "  '61.  Demiaux, V. How can humans keep the upper hand? The ethical matters raised by \\n',\n",
       "  'algorithms and artificial intelligence. (2017). \\n',\n",
       "  '62.  Council of Europe: CEPEJ. European ethical Charter on the use of Artificial \\n',\n",
       "  'Intelligence in judicial systems and their environment. (2019). \\n',\n",
       "  '63.  American College of Radiology et al. Ethics of AI in Radiology: European and North \\n',\n",
       "  'American Multisociety Statement. (2019). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '7 \\n',\n",
       "  '64.  Leaders of the G7. Charlevoix Common Vision for the Future of Artificial \\n',\n",
       "  'Intelligence. (2018). \\n',\n",
       "  '65.  DeepMind Ethics&Society. DeepMind Ethics & Society Principles. DeepMind (2017). \\n',\n",
       "  'Available at: https://deepmind.com/applied/deepmind-ethics-society/principles/. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '66.  Sony. Sony Group AI Ethics Guidelines. (2018). \\n',\n",
       "  '67.  Datatilsynet. Artificial intelligence and privacy. (The Norwegian Data Protection \\n',\n",
       "  'Authority, 2018). \\n',\n",
       "  '68.  WEF. White Paper: How to Prevent Discriminatory Outcomes in Machine Learnig. \\n',\n",
       "  '(2018). \\n',\n",
       "  '69.  Information Technology Industry Council (ITI). ITI AI Policy Principles. (2017). \\n',\n",
       "  '70.  Sage. The Ethics of Code: Developing AI for Business with Five Core Principles. \\n',\n",
       "  '(2017). \\n',\n",
       "  '71.  OP Group. Commitments and principles. OP Available at: https://www.op.fi/op-\\n',\n",
       "  'financial-group/corporate-social-responsibility/commitments-and-principles. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '72.  Tieto. Tieto’s AI ethics guidelines. (2018). \\n',\n",
       "  '73.  Unity. Introducing Unity’s Guiding Principles for Ethical AI – Unity Blog. Unity \\n',\n",
       "  'Technologies Blog (2018). \\n',\n",
       "  '74.  National Institution for Transforming India (Niti Aayog). Discussion Paper: National \\n',\n",
       "  'Strategy for Artificial Intelligence. (2018). \\n',\n",
       "  '75.  House of Lords. AI in the UK: ready, willing and able. 183 (2018). \\n',\n",
       "  '76.  The Information Accountability Foundation. Unified Ethical Frame for Big Data \\n',\n",
       "  'Analysis IAF Big Data Ethics Initiative, Part A. (2015). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '8 \\n',\n",
       "  '77.  Fenech, M., Nika Strukelj & Olly Buston. Ethical, social, and political challenges of \\n',\n",
       "  'Artificial Intelligence in Health. (Future Advocacy, 2019). \\n',\n",
       "  '78.  Accenture UK. Responsible AI and robotics. An ethical framework. Available at: \\n',\n",
       "  'https://www.accenture.com/gb-en/company-responsible-ai-robotics. (Accessed: 22nd \\n',\n",
       "  'February 2019) \\n',\n",
       "  '79.  Google. Our Principles. Google AI (2018). Available at: https://ai.google/principles/. \\n',\n",
       "  '(Accessed: 19th February 2019) \\n',\n",
       "  '80.  Microsoft. Microsoft AI principles. Our approach (2017). Available at: \\n',\n",
       "  'https://www.microsoft.com/en-us/ai/our-approach-to-ai. (Accessed: 1st November \\n',\n",
       "  '2018) \\n',\n",
       "  '81.  CERNA Commission de réflexion sur l’Éthique de la Rechercheen sciences et \\n',\n",
       "  'technologies du Numérique d’Allistene. Éthique de la rechercheen robotique. \\n',\n",
       "  '(Allistene, 2014). \\n',\n",
       "  '82.  Est, R. van & Gerritsen, J. Human rights in the robot age: Challenges arising from the \\n',\n",
       "  'use of robotics, artificial intelligence, and virtual and augmented reality. (The \\n',\n",
       "  'Rathenau Institute, 2017). \\n',\n",
       "  '83.  Université de Montréal. Montreal Declaration. The Declaration - Montreal \\n',\n",
       "  'Responsible AI (2017). Available at: https://www.montrealdeclaration-\\n',\n",
       "  'responsibleai.com/the-declaration. (Accessed: 21st February 2019) \\n',\n",
       "  '84.  Government of the Republic of Korea. Mid- to Long-Term Master Plan in Preparation \\n',\n",
       "  'for the Intelligent Information Society. Managing the Fourth Industrial Revolution. \\n',\n",
       "  '(2017). \\n',\n",
       "  '85.  Crawford, K. et al. The AI Now Report. The Social and Economic Implications of \\n',\n",
       "  'Artificial Intelligence Technologies in the Near-Term. (2016). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '9 \\n',\n",
       "  '86.  Advisory Board on Artificial Intelligence and Human Society. Report on Artificial \\n',\n",
       "  'Intelligence and Human Society Unofficial translation. (Ministry of State for Science \\n',\n",
       "  'and Technology Policy, 2017). \\n',\n",
       "  '87.  Executive Office of the President; National Science and Technology Council; \\n',\n",
       "  'Committee on Technology. Preparing for the future of Artificial Intelligence. (2016). \\n',\n",
       "  '88.  Intel. Artificial intelligence. The public policy opportunity. (2017). \\n',\n",
       "  '89.  Royal Society. Machine learning: the power and promise of computers that learn by \\n',\n",
       "  'example. (Royal Society (Great Britain), 2017). \\n',\n",
       "  '90.  IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. Ethically \\n',\n",
       "  'Aligned Design: A Vision for Prioritizing Human Well-being with Autonomous and \\n',\n",
       "  'Intelligent Systems, First Edition (EAD1e). (2019). \\n',\n",
       "  '91.  European Parliament. Report with recommendations to the Commission on Civil Law \\n',\n",
       "  'Rules on Robotics. (2017). \\n',\n",
       "  '92.  COMEST/UNESCO. Report of COMEST on robotics ethics. UNESDOC Digital \\n',\n",
       "  'Library (2017). Available at: https://unesdoc.unesco.org/ark:/48223/pf0000253952. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '93.  Campolo, A., Madelyn Sanfilippo, Meredith Whittaker & Kate Crawford. AI Now \\n',\n",
       "  '2017 Report. (2017). \\n',\n",
       "  '94.  American Medical Association (AMA). Policy Recommendations on Augmented \\n',\n",
       "  'Intelligence in Health Care H-480.940. (2018). Available at: https://policysearch.ama-\\n',\n",
       "  'assn.org/policyfinder/detail/AI?uri=%2FAMADoc%2FHOD.xml-H-480.940.xml. \\n',\n",
       "  '(Accessed: 21st February 2019) \\n',\n",
       "  '95.  Avila, R., Ana Brandusescu, Juan Ortiz Freuler & Dhanaraj Thakur. Artificial \\n',\n",
       "  'Intelligence: open questions about gender inclusion. (2018). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '10 \\n',\n",
       "  '96.  The Conference toward AI Network Society. Draft AI R&D Guidelines for \\n',\n",
       "  'International Discussions. (2017). Available at: \\n',\n",
       "  'http://www.soumu.go.jp/main_content/000507517.pdf. (Accessed: 21st February \\n',\n",
       "  '2019) \\n',\n",
       "  '97.  National Science and Technology Council; Networking and Information Technology \\n',\n",
       "  'Research and Development Subcommittee. The National Artificial Intelligence \\n',\n",
       "  'Research and Development Strategic Plan. (2016). \\n',\n",
       "  '98.  Hoffmann, D. & Masucci, R. Intel’s AI Privacy Policy White Paper. Protecting \\n',\n",
       "  'individuals’ privacy and data in the artificial intelligence world. (2018). \\n',\n",
       "  '99.  Partnership on AI. Tenets. The Partnership on AI (2016). Available at: \\n',\n",
       "  'https://www.partnershiponai.org/tenets/. (Accessed: 21st February 2019) \\n',\n",
       "  '100. Icelandic Institute for Intelligent Machines (IIIM). Ethics Policy. IIIM (2015). \\n',\n",
       "  'Available at: http://www.iiim.is/2015/08/ethics-policy/. (Accessed: 21st February \\n',\n",
       "  '2019) \\n',\n",
       "  '101. Latonero, M. Governing Artificial Intelligence. Upholding Human Rights & Dignity. \\n',\n",
       "  '(Data & Society, 2018). \\n',\n",
       "  '102. OpenAI. OpenAI Charter. OpenAI (2018). Available at: \\n',\n",
       "  'https://blog.openai.com/openai-charter/. (Accessed: 21st February 2019) \\n',\n",
       "  '103. Agenzia per l’Italia Digitale (AGID). L’intelligenzia artificiale al servizio del \\n',\n",
       "  'cittadino. (2018). \\n',\n",
       "  '104. Women Leading in AI. 10 Principles of responsible AI. (2019). \\n',\n",
       "  '105. Privacy International & Article 19. Privacy and Freedom of Expression In the Age of \\n',\n",
       "  'Artificial Intelligence. (2018). \\n',\n",
       "  '106. Shoham, Y. et al. The AI Index 2018 Annual Report. (AI Index Steering Committee, \\n',\n",
       "  'Human-Centered AI Initiative, Stanford University, 2018). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '11 \\n',\n",
       "  '107. Turilli, M. & Floridi, L. The ethics of information transparency. Ethics Inf. Technol. \\n',\n",
       "  '11, 105–112 (2009). \\n',\n",
       "  '108. Rozin, P. & Royzman, E. B. Negativity Bias, Negativity Dominance, and Contagion: \\n',\n",
       "  'Personal. Soc. Psychol. Rev. (2016). doi:10.1207/S15327957PSPR0504_2 \\n',\n",
       "  '109. Bentley, P. J., Brundage, M., Häggström, O. & Metzinger, T. Should we fear artificial \\n',\n",
       "  'intelligence?: in-depth analysis. (European Parliamentary Research Service: \\n',\n",
       "  'Scientific Foresight Unit (STOA), 2018). \\n',\n",
       "  '110. Taddeo, M. & Floridi, L. How AI can be a force for good. Science 361, 751–752 \\n',\n",
       "  '(2018). \\n',\n",
       "  '111. Bryson, J. AI & Global Governance: No One Should Trust AI - Centre for Policy \\n',\n",
       "  'Research at United Nations University. United Nations University. Centre for Policy \\n',\n",
       "  'Research (2018). Available at: https://cpr.unu.edu/ai-global-governance-no-one-\\n',\n",
       "  'should-trust-ai.html. (Accessed: 21st March 2019) \\n',\n",
       "  '112. Winfield, A. F. T. & Marina, J. Ethical governance is essential to building trust in \\n',\n",
       "  'robotics and artificial intelligence systems. Philos. Trans. R. Soc. Math. Phys. Eng. \\n',\n",
       "  'Sci. 376, 20180085 (2018). \\n',\n",
       "  '113. WEF. Harnessing Artificial Intelligence for the Earth. (WEF, 2018). \\n',\n",
       "  '114. Lancaster, C. Can artificial intelligence improve humanitarian responses? UNOPS \\n',\n",
       "  '(2018). Available at: https://www.unops.org/news-and-stories/insights/can-artificial-\\n',\n",
       "  'intelligence-improve-humanitarian-responses. (Accessed: 22nd March 2019) \\n',\n",
       "  '115. Microsoft. AI for Humanitarian Action. Microsoft | AI Available at: \\n',\n",
       "  'https://www.microsoft.com/en-us/ai/ai-for-humanitarian-action. (Accessed: 22nd \\n',\n",
       "  'March 2019) \\n',\n",
       "  '116. Scheffran, J., Brzoska, M., Kominek, J., Link, P. M. & Schilling, J. Climate change \\n',\n",
       "  'and violent conflict. Science 336, 869–871 (2012). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '12 \\n',\n",
       "  '117. IEEE. The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems. \\n',\n",
       "  'IEEE Standards Association Available at: https://standards.ieee.org/industry-\\n',\n",
       "  'connections/ec/autonomous-systems.html. (Accessed: 22nd March 2019) \\n',\n",
       "  '118. Arksey, H. & O’Malley, L. Scoping studies: towards a methodological framework. Int. \\n',\n",
       "  'J. Soc. Res. Methodol. 8, 19–32 (2005). \\n',\n",
       "  '119. Pham, M. T. et al. A scoping review of scoping reviews: advancing the approach and \\n',\n",
       "  'enhancing the consistency. Res. Synth. Methods 5, 371–385 (2014). \\n',\n",
       "  '120. Liberati, A. et al. The PRISMA Statement for Reporting Systematic Reviews and \\n',\n",
       "  'Meta-Analyses of Studies That Evaluate Health Care Interventions: Explanation and \\n',\n",
       "  'Elaboration. PLOS Med. 6, e1000100 (2009). \\n',\n",
       "  '121. Boddington, P. Alphabetical List of Resources. Ethics for Artificial Intelligence \\n',\n",
       "  '(2018). Available at: https://www.cs.ox.ac.uk/efai/resources/alphabetical-list-of-\\n',\n",
       "  'resources/. (Accessed: 4th May 2019) \\n',\n",
       "  '122. Winfield, A. Alan Winfield’s Web Log: A Round Up of Robotics and AI ethics. Alan \\n',\n",
       "  'Winfield’s Web Log (2017). \\n',\n",
       "  '123. Future of Life Institute. National and International AI Strategies. Future of Life \\n',\n",
       "  'Institute (2018). Available at: https://futureoflife.org/national-international-ai-\\n',\n",
       "  'strategies/. (Accessed: 4th May 2019) \\n',\n",
       "  '124. Future of Life Institute. Summaries of AI Policy Resources. Future of Life Institute \\n',\n",
       "  '(2018). Available at: https://futureoflife.org/ai-policy-resources/. (Accessed: 4th May \\n',\n",
       "  '2019) \\n',\n",
       "  '125. Hagstrom, C., Kendall, S. & Cunningham, H. Googling for grey: using Google and \\n',\n",
       "  'Duckduckgo to find grey literature. in Abstracts of the 23rd Cochrane Colloquium 10 \\n',\n",
       "  '(Suppl): LRO 3.6, 40 (Cochrane Database of Systematic Reviews, 2015). \\n',\n",
       "  ' \\n'],\n",
       " [' \\n',\n",
       "  '13 \\n',\n",
       "  '126. Piasecki, J., Waligora, M. & Dranseika, V. Google Search as an Additional Source in \\n',\n",
       "  'Systematic Reviews. Sci. Eng. Ethics (2017). doi:10.1007/s11948-017-0010-4 \\n',\n",
       "  '127. Moher, D., Liberati, A., Tetzlaff, J., Altman, D. G. & Group, T. P. Preferred Reporting \\n',\n",
       "  'Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement. PLOS \\n',\n",
       "  'Med. 6, e1000097 (2009). \\n',\n",
       "  '128. Saldaña, J. The coding manual for qualitative researchers. (Sage, 2013). \\n',\n",
       "  '129. Noblit, G. W. & Hare, R. D. Meta-Ethnography: Synthesizing Qualitative Studies. \\n',\n",
       "  '(SAGE, 1988). \\n',\n",
       "  '130. Daniels, N. Justice and Justification: Reflective Equilibrium in Theory and Practice. \\n',\n",
       "  '(Cambridge University Press, 1996). \\n',\n",
       "  ' \\n \\n',\n",
       "  ' \\n'],\n",
       " [' \\n \\nSupplementary Information for \\n \\nArtificial Intelligence: the global landscape of ethics guidelines \\n \\n \\n \\nAnna Jobin a, Marcello Ienca a, Effy Vayena a* \\n \\n \\n \\na Health Ethics & Policy Lab, ETH Zurich, 8092 Zurich, Switzerland \\n \\n* Corresponding author: effy.vayena@hest.ethz.ch \\n \\n \\n \\n© The authors 2019 \\n \\n \\n \\n \\n \\n \\nThis PDF file includes: \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  'Tables S1 to S3 \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  '1 \\n'],\n",
       " ['Table S1. Ethics guidelines for AI by date of publishing (incl. details) \\n \\n',\n",
       "  'Name of Docu-\\nment/Website \\n',\n",
       "  'Name of guide-\\nlines/principles \\n',\n",
       "  'Issuer \\n',\n",
       "  'Country \\nof issuer \\n',\n",
       "  'Type of issuer \\n',\n",
       "  ' \\n',\n",
       "  'Principles of robotics \\n',\n",
       "  'Ethique de la re-\\ncherche en robotique \\nUnified Ethical Frame \\nfor Big Data Analysis. \\nIAF Big Data Ethics \\nInitiative, Part A \\nEthics Policy \\n',\n",
       "  'The AI Now Report. \\nThe Social and Eco-\\nnomic Implications of \\nArtificial Intelligence \\nTechnologies in the \\nNear-Term \\nTenets \\n',\n",
       "  'Preparing for the fu-\\nture of Artificial Intel-\\nligence \\n',\n",
       "  'The National Artificial \\nIntelligence Research \\nand Development \\nStrategic Plan \\n',\n",
       "  'R&D Strategy \\n',\n",
       "  'Position on Robotics \\nand Artificial Intelli-\\ngence \\n',\n",
       "  'Principles for Ac-\\ncountable Algorithms \\nand a Social Impact \\nStatement for Algo-\\nrithms \\nStatement on Algo-\\nrithmic Transparency \\nand Accountability \\n',\n",
       "  'Report with recom-\\nmendations to the \\nCommission on Civil \\nLaw Rules on Robot-\\nics \\nAI Principles \\n',\n",
       "  'The Japanese Society \\nfor Artificial Intelli-\\ngence Ethical Guide-\\nlines \\nReport on Artificial \\nIntelligence and Hu-\\nman Society (Unoffi-\\ncial translation) \\n',\n",
       "  '3. Principles // 6. \\nRecommendations \\nGreen position on \\nRobotics and Artifi-\\ncial Intelligence \\nPrinciples for Ac-\\ncountable Algo-\\nrithms \\n',\n",
       "  'Principles for Algo-\\nrithmic Transpar-\\nency and Accounta-\\nbility \\nMotion for a Euro-\\npean Parliament \\nResolution \\n',\n",
       "  'The Japanese Soci-\\nety for Artificial In-\\ntelligence Ethical \\nGuidelines \\n4.1 Ethical issues \\n',\n",
       "  'Artificial Intelligence \\nand Machine Learn-\\ning: Policy Paper \\n',\n",
       "  'Guiding principles \\nand recommenda-\\ntions \\n',\n",
       "  'Machine learning: the \\npower and promise of \\ncomputers that learn \\nby example \\nThe Ethics of Code: \\nDeveloping AI for \\nBusiness with Five \\nCore Principles \\nAutomated and Con-\\nnected Driving: Re-\\nport \\n',\n",
       "  'Chapter six – A \\nnew wave of ma-\\nchine learning re-\\nsearch \\nThe Ethics of Code: \\nDeveloping AI for \\nBusiness with Five \\nCore Principles \\nEthical rules for au-\\ntomated and con-\\nnected vehicular \\ntraffic \\n',\n",
       "  ' \\n',\n",
       "  'AI Principles \\n',\n",
       "  'Future of Life Institute \\n',\n",
       "  'USA \\n',\n",
       "  'Principles for de-\\nsigners, builders \\nand users of robots \\nPréconisations \\n',\n",
       "  'Values for an Ethi-\\ncal Frame \\n',\n",
       "  \"IIIM's Ethics Policy \\n\",\n",
       "  'Key recommenda-\\ntions \\n',\n",
       "  'Engineering and Phys-\\nical Sciences Research \\nCouncil UK (EPSRC) \\nCERNA (Allistene) \\n',\n",
       "  'The Information Ac-\\ncountability Founda-\\ntion \\n',\n",
       "  'UK \\n',\n",
       "  'Science founda-\\ntion \\n',\n",
       "  'France \\n',\n",
       "  'Research alliance \\n',\n",
       "  'UK \\n',\n",
       "  'NPO/Charity \\n',\n",
       "  'Icelandic Institute for \\nIntelligent Machines \\n(IIIM) \\nAI Now Institute \\n',\n",
       "  'Iceland \\n',\n",
       "  'USA \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion \\nAcademic and \\nresearch institu-\\ntion \\n',\n",
       "  'Tenets \\n',\n",
       "  'Partnership on AI \\n',\n",
       "  'Recommendations \\nin this Report \\n',\n",
       "  'n.a. \\n',\n",
       "  'USA \\n',\n",
       "  'Private sector al-\\nliance \\nGovernmental \\nagencies/organi-\\nzations \\n',\n",
       "  '29-Sep-\\n2016 \\nxx-Oct-\\n2016 \\n',\n",
       "  'USA \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'xx-Oct-\\n2016 \\n',\n",
       "  'Date of \\npublish-\\ning \\n1-Apr-\\n2011 \\n',\n",
       "  'xx-Nov-\\n2014 \\nxx-Mar-\\n2015 \\n',\n",
       "  '31-Aug-\\n2015 \\n',\n",
       "  '22-Sep-\\n2016 \\n',\n",
       "  'Target audience \\n',\n",
       "  'Retrieval \\n',\n",
       "  'multiple (public, \\ndevelopers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'researchers \\n',\n",
       "  'unspecified \\n',\n",
       "  'Citation \\nchaining \\nCitation \\nchaining \\n',\n",
       "  'self \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'unspecified \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'self \\n',\n",
       "  'multiple (stake-\\nholders engaged \\nat variouspoints \\nin the produc-\\ntion, use, govern-\\nance, and assess-\\nment of AI sys-\\ntems) \\nself \\n',\n",
       "  'Web search \\nresults 1-30 \\nLinkhubs \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Executive Office of \\nthe President; National \\nScience and Technol-\\nogy Council; Commit-\\ntee on Technology \\n',\n",
       "  'National Science and \\nTechnology Council; \\nNetworking and Infor-\\nmation Technology \\nResearch and Devel-\\nopment Subcommittee \\nThe Greens (Green \\nWorking Group Ro-\\nbots)   \\n',\n",
       "  'Fairness, Accountabil-\\nity, and Transparency \\nin Machine Learning \\n(FATML) \\n',\n",
       "  'Association for Com-\\nputing Machinery \\n(ACM) \\n',\n",
       "  'EU \\n',\n",
       "  'Political Party \\n',\n",
       "  '22-Nov-\\n2016 \\n',\n",
       "  'multiple (EU \\nparliament, pu-\\nblic, self) \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  '24-Nov-\\n2016 \\n',\n",
       "  'multiple (devel-\\nopers and prod-\\nuct managers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'USA \\n',\n",
       "  'Prof. Associa-\\ntion/Society \\n',\n",
       "  '12-Jan-\\n2017 \\n',\n",
       "  'multiple (devel-\\nopers, deployers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'European Parliament \\n',\n",
       "  'EU \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  '27-Jan-\\n2017 \\n',\n",
       "  'public sector \\n(lawmakers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Japanese Society for \\nArtificial Intelligence \\n',\n",
       "  'Japan \\n',\n",
       "  'Advisory Board on \\nArtificial Intelligence \\nand Human Society \\n(initiative of the Min-\\nister of State for Sci-\\nence and Technology \\nPolicy) \\nInternet Society \\n',\n",
       "  'Miscellaneous \\n(mixed \\ncrowdsourced, \\nNPO) \\nProf. Associa-\\ntion/Society \\n',\n",
       "  '30-Jan-\\n2017 \\n',\n",
       "  '28-Feb-\\n2017 \\n',\n",
       "  '24-Mar-\\n2017 \\n',\n",
       "  'Japan \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'NPO/charity \\n',\n",
       "  '18-Apr-\\n2017 \\n',\n",
       "  'The Royal Society \\n',\n",
       "  'UK \\n',\n",
       "  'Prof. Associa-\\ntion/Society \\n',\n",
       "  'xx-Apr-\\n2017 \\n',\n",
       "  'Sage \\n',\n",
       "  'UK \\n',\n",
       "  'Company \\n',\n",
       "  'Federal Ministry of \\nTransport and Digital \\nInfrastructure, Ethics \\nCommission \\n',\n",
       "  'Germany \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '27-Jun-\\n2017 \\n',\n",
       "  'xx-Jun-\\n2017 \\n',\n",
       "  'unspecified \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'self (incl AI) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'multiple (re-\\nsearchers, gov-\\nernment, busi-\\nnesses, public, \\neducators) \\n',\n",
       "  'multiple (policy-\\nmakers, other \\nstakeholders in \\nthe wider Inter-\\nnet ecosystem) \\nunspecified \\n',\n",
       "  'self \\n',\n",
       "  'multiple (auto-\\nmated & con-\\nnected vehicular \\ntraffic) \\n',\n",
       "  ' \\n',\n",
       "  '2 \\n'],\n",
       " ['Mid- to Long-Term \\nMaster Plan in Prepa-\\nration for the Intelli-\\ngent Information Soci-\\nety \\nDraft AI R&D Guide-\\nlines for International \\nDiscussions \\n',\n",
       "  'Big data, artificial in-\\ntelligence, machine \\nlearning and data pro-\\ntection \\nReport of COMEST \\non Robotics Ethics \\n(only section \"Recom-\\nmendations\" taken \\ninto account) \\nEthical Principles for \\nArtificial Intelligence \\nand Data Analytics \\n',\n",
       "  'AI - Our approach \\n',\n",
       "  'DeepMind Ethics & \\nSociety Principles \\nHuman Rights in the \\nRobot Age Report \\n',\n",
       "  'Tasks (8-12) \\n',\n",
       "  'Government of the \\nRepublic of Korea \\n',\n",
       "  'South \\nKorea \\n',\n",
       "  'Japan \\n',\n",
       "  \"Institute for Infor-\\nmation and Communi-\\ncations Policy (IICP), \\nThe Conference to-\\nward AI Network So-\\nciety \\nInformation Commis-\\nsioner's Office \\n\",\n",
       "  'AI R&D Principles \\n',\n",
       "  'Key recommenda-\\ntions \\n',\n",
       "  'Relevant ethical \\nprinciples and val-\\nues \\n',\n",
       "  'Ethical Principles \\nfor Artificial Intelli-\\ngence and Data An-\\nalytics \\nAI - Our approach \\n',\n",
       "  'Software & Infor-\\nmation Industry Asso-\\nciation (SIIA), Public \\nPolicy Division \\nMicrosoft \\n',\n",
       "  'Our Five Core Prin-\\nciples \\nRecommendations \\n',\n",
       "  'DeepMind Ethics & \\nSociety \\nThe Rathenau Institute \\n',\n",
       "  'Artificial Intelligence. \\nThe Public Policy Op-\\nportunity \\nITI AI Policy Princi-\\nples \\n',\n",
       "  'Summary of Rec-\\nommendations \\n',\n",
       "  'ITI AI Policy Prin-\\nciples \\n',\n",
       "  'AI Now 2017 Report \\n',\n",
       "  'Recommendations, \\nExecutive Summary \\n',\n",
       "  'Intel Corporation \\n',\n",
       "  'Information Technol-\\nogy Industry Council \\n(ITI) \\nAI Now Institute \\n',\n",
       "  'Montréal Declara-\\ntion: Responsible \\nAI \\nEthically Aligned \\nDesign. A Vision \\nfor Prioritizing Hu-\\nman Well-being \\nwith Autonomous \\nand Intelligent Sys-\\ntems, version 2 \\nFrom principles to \\npolicy recommen-\\ndations \\n',\n",
       "  'Université de Mont-\\nréal \\n',\n",
       "  'Institute of Electrical \\nand Electronics Engi-\\nneers (IEEE), The \\nIEEE Global Initiative \\non Ethics of Autono-\\nmous and Intelligent \\nSystems \\nFrench Data Protec-\\ntion Authority (CNIL)  \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '20-Jul-\\n2017 \\n',\n",
       "  '28-Jul-\\n2017 \\n',\n",
       "  'self (gov) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'multiple (sys-\\ntems and devel-\\nopers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'UK \\n',\n",
       "  'Gov \\n',\n",
       "  '4-Sep-\\n2017 \\n',\n",
       "  'organisations \\n',\n",
       "  'Web search \\nresults 1-30 \\n',\n",
       "  'COMEST/UNESCO \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  '14-Sep-\\n2017 \\n',\n",
       "  'unspecified \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Private sector al-\\nliance \\n',\n",
       "  '15-Sep-\\n2017 \\n',\n",
       "  'private sector \\n(industry organi-\\nzations) \\n',\n",
       "  ' \\n',\n",
       "  'USA \\n',\n",
       "  'UK \\n',\n",
       "  'Nether-\\nlands \\n',\n",
       "  'USA \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'USA \\n',\n",
       "  'Company \\n',\n",
       "  'Company \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion (Gov) \\nCompany \\n',\n",
       "  'Private sector al-\\nliance \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion \\n',\n",
       "  '7-Oct-\\n2017 \\n10-Oct-\\n2017 \\n11-Oct-\\n2017 \\n',\n",
       "  '18-Oct-\\n2017 \\n',\n",
       "  '24-Oct-\\n2017 \\n',\n",
       "  'xx-Oct-\\n2017 \\n',\n",
       "  'Canada \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion \\nProf. Associa-\\ntion/Society \\n',\n",
       "  '3-Nov-\\n2017 \\n',\n",
       "  '12-Dec-\\n2017 \\n',\n",
       "  'self \\n',\n",
       "  'self \\n',\n",
       "  'public sector \\n(Council of Eu-\\nrope) \\npublic sector \\n(policy makers) \\n',\n",
       "  'self (members) \\n',\n",
       "  'multiple (core \\npublic agencies, \\ncompanies, in-\\ndustry, universi-\\nties, conferences, \\nother stakehold-\\ners) \\nmultiple (public, \\ndevelopers, pol-\\nicy makers) \\nunspecified \\n',\n",
       "  'Web search \\nresults 1-30 \\nCitation \\nchaining \\nCitation \\nchaining \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'France \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '15-Dec-\\n2017 \\n',\n",
       "  'unspecified \\n',\n",
       "  'Linkhubs \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  'Montréal Declaration: \\nResponsible AI \\n',\n",
       "  'Ethically Aligned De-\\nsign. A Vision for Pri-\\noritizing Human Well-\\nbeing with Autono-\\nmous and Intelligent \\nSystems, version 2 \\n',\n",
       "  'How can humans keep \\nthe upper hand? Re-\\nport on the ethical \\nmatters raised by AI \\nalgorithms (only sec-\\ntion \"From principles \\nto policy recommen-\\ndations\") \\nTop 10 Principles for \\nEthical Artificial Intel-\\nligence \\nBusiness Ethics and \\nArtificial Intelligence \\n',\n",
       "  'IBM’s Principles for \\nTrust and Transpar-\\nency \\nArtificial intelligence \\nand privacy \\n',\n",
       "  'The Malicious Use  of \\nArtificial Intelligence: \\nForecasting, Preven-\\ntion,  and Mitigation \\n',\n",
       "  'White Paper: How to \\nPrevent Discrimina-\\ntory Outcomes in Ma-\\nchine Learning \\n',\n",
       "  'Federation/Union \\n',\n",
       "  '17-Dec-\\n2017 \\n',\n",
       "  'multiple (unions, \\nworkers) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Top 10 Principles \\nfor Ethical Artifi-\\ncial Intelligence \\nFundamental Val-\\nues and Principles \\n',\n",
       "  'IBM’s Principles \\nfor Trust and Trans-\\nparency \\nRecommendations \\nfor privacy friendly \\ndevelopment and \\nuse of AI \\n',\n",
       "  'Four High-Level \\nRecommendations \\n',\n",
       "  'UNI Global Union \\n',\n",
       "  'Institute of Business \\nEthics \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'UK \\n',\n",
       "  'Private sector al-\\nliance \\n',\n",
       "  ' IBM \\n',\n",
       "  'USA \\n',\n",
       "  'Company \\n',\n",
       "  'The Norwegian Data \\nProtection Authority \\n',\n",
       "  'Norway \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Miscellaneous \\n(mixed aca-\\ndemic, NPO) \\n',\n",
       "  '11-Jan-\\n2018 \\n',\n",
       "  '17-Jan-\\n2018 \\n',\n",
       "  'xx-Jan-\\n2018 \\n',\n",
       "  '20-Feb-\\n2018 \\n',\n",
       "  'private sector \\n(users of AI in \\nbusiness) \\nself \\n',\n",
       "  'multiple (devel-\\nopers, system \\nsuppliers, organi-\\nsations, end us-\\ners, authorities) \\nunspecified \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\nWeb search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Future of Humanity \\nInstitute; University of \\nOxford; Centre for the \\nStudy of Existential \\nRisk; University of \\nCambridge; Center for \\na New American Se-\\ncurity; Electronic \\nFrontier Foundation; \\nOpenAI \\n',\n",
       "  'Executive summary  WEF, Global Future \\nCouncil on Human \\nRights 2016-2018 \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'NPO/Charity \\n',\n",
       "  '12-Mar-\\n2018 \\n',\n",
       "  'private sector \\n(companies) \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  ' \\n',\n",
       "  '3 \\n'],\n",
       " ['Mission Villani \\n',\n",
       "  'France \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '29-Mar-\\n2018 \\n',\n",
       "  'public sector \\n(French govern-\\nment/parliament) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  'xx-Mar-\\n2018 \\n',\n",
       "  'public sector (EU \\nCommission) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'For a meaningful Arti-\\nficial Intelligence. To-\\nwards a French and \\nEuropean strategy \\n',\n",
       "  \"Statement on Artificial \\nIntelligence, Robotics \\nand 'Autonomous' \\nSystems \\nL'intelligenzia artifi-\\nciale al servizio del \\ncittadino \\n\",\n",
       "  '\"Part 5 — What are \\nthe Ethics of AI?; \\nPart 6 — For Inclu-\\nsive and Diverse \\nArtificial Intelli-\\ngence\" \\nEthical principles \\nand democratic pre-\\nrequisites \\n',\n",
       "  'Sfida 1: Etica \\n',\n",
       "  'OpenAI Charter \\n',\n",
       "  'OpenAI Charter \\n',\n",
       "  'OpenAI \\n',\n",
       "  \"European Commis-\\nsion, European Group \\non Ethics in Science \\nand New Technologies \\nAgenzia per l'Italia \\nDigitale (AGID) \\n\",\n",
       "  'UK House of Lords, \\nSelect Committee on \\nArtificial Intelligence \\n',\n",
       "  'EU \\n',\n",
       "  'Italy \\n',\n",
       "  'USA \\n',\n",
       "  'UK \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'NPO/charity(*) \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'Privacy International \\n& Article 19 \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'NPO/Charity \\n',\n",
       "  'AI Guidelines \\n',\n",
       "  'Deutsche Telekom \\n',\n",
       "  'Germany \\n',\n",
       "  'Company \\n',\n",
       "  'Access Now ; Am-\\nnesty International \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Miscellaneous \\n(mixed NGO, \\nNPO) \\n',\n",
       "  'Personal Data Protec-\\ntion Commission Sin-\\ngapore \\n',\n",
       "  'Singa-\\npore \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '5-Jun-\\n2018 \\n',\n",
       "  'Our principles \\n',\n",
       "  'Google \\n',\n",
       "  'National Institution for \\nTransforming India \\n(Niti Aayog) \\n',\n",
       "  'USA \\n',\n",
       "  'India \\n',\n",
       "  'Company \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  '7-Jun-\\n2018 \\n8-Jun-\\n2018 \\n',\n",
       "  'no title. P. 125: \"… \\nwe suggest five \\noverarching princi-\\nples for an AI \\nCode:\" \\nConclusions and \\nRecommendations \\n',\n",
       "  'The Toronto Decla-\\nration: Protecting \\nthe right to equality \\nand non-discrimina-\\ntion in machine \\nlearning systems \\nPrinciples for re-\\nsponsible AI \\n',\n",
       "  'Ethics, Privacy, Se-\\ncurity and Artificial \\nIntelligence. To-\\nwards a “Responsi-\\nble AI” \\n',\n",
       "  'Charlevoix Com-\\nmon Vision for the \\nFuture of Artificial \\nIntelligence \\nPolicy Recommen-\\ndations on Aug-\\nmented Intelligence \\nin Health Care H-\\n480.940 \\nProposals \\n',\n",
       "  'Five Areas of Ethi-\\ncal Focus \\n',\n",
       "  'xx-Mar-\\n2018 \\n',\n",
       "  '9-Apr-\\n2018 \\n16-Apr-\\n2018 \\n',\n",
       "  '25-Apr-\\n2018 \\n',\n",
       "  '11-May-\\n2018 \\n16-May-\\n2018 \\n',\n",
       "  'multiple (govern-\\nment, schools, \\nhealthcare insti-\\ntutions) \\nself \\n',\n",
       "  'public sector \\n(UK govern-\\nment) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'multiple (states, \\ncompanies, civil \\nsociety) \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'self \\n',\n",
       "  'multiple (states, \\nprivate sector ac-\\ntors) \\n',\n",
       "  'Web search \\nresults 1-30 \\nLinkhubs \\n',\n",
       "  'multiple (busi-\\nness; Trade asso-\\nciations and \\nchambers, pro-\\nfessional bodies \\nand interest \\ngroups) \\nself \\n',\n",
       "  'self (Indian gov-\\nernment) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'Web search \\nresults 1-30 \\nLinkhubs \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\nWeb search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\nWeb search \\nresults 31-\\n200 \\nLinkhubs \\n',\n",
       "  '2-Jul-\\n2018 \\n',\n",
       "  '2-Sep-\\n2018 \\n',\n",
       "  '3-Sep-\\n2018 \\n',\n",
       "  '5-Sep-\\n2018 \\n',\n",
       "  'public sector \\n(states/countries) \\n',\n",
       "  'designers \\n',\n",
       "  'multiple (indus-\\ntry, doctors, reg-\\nulators) \\ndevelopers \\n',\n",
       "  '10-Sep-\\n2018 \\n',\n",
       "  'multiple (Finnish \\nworld of work) \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  'AI in the UK: ready, \\nwilling and able? (re-\\nport, only section \"An \\nAI Code\" taken into \\naccount) \\nPrivacy and Freedom \\nof Expression In the \\nAge of Artificial Intel-\\nligence \\nAI Guidelines \\n',\n",
       "  'The Toronto Declara-\\ntion: Protecting the \\nright to equality and \\nnon-discrimination in \\nmachine learning sys-\\ntems \\nDiscussion Paper on \\nArtificial Intelligence \\n(AI) and Personal \\nData - Fostering Re-\\nsponsible Develop-\\nment and Adoption of \\nAI \\nOur principles \\n',\n",
       "  'Discussion Paper: Na-\\ntional Strategy for Ar-\\ntificial Intelligence \\n(only section \"Ethics, \\nPrivacy, Security and \\nArtificial Intelligence. \\nTowards a “Responsi-\\nble AI”\") \\nCharlevoix Common \\nVision for the Future \\nof Artificial Intelli-\\ngence \\nPolicy Recommenda-\\ntions on Augmented \\nIntelligence in Health \\nCare H-480.940 \\n',\n",
       "  'Artificial Intelligence: \\nopen questions about \\ngender inclusion \\nEveryday Ethics for \\nArtificial Intelligence. \\nA practical guide for \\ndesigners & develop-\\ners \\nArtificial Intelligence \\n(AI) in Health \\n',\n",
       "  'Initial code of conduct \\nfor data-driven health \\nand care technology \\nWork in the age of ar-\\ntificial intelligence. \\nFour perspectives on \\nthe economy, employ-\\nment, skills and ethics \\n(only section \"Good \\napplication of artificial \\nintelligence technol-\\nogy and ethics\") \\nSAP’s guiding princi-\\nples for artificial intel-\\nligence \\nSony Group AI Ethics \\nGuidelines \\nEthics Framework - \\nResponsible AI \\n',\n",
       "  'Leaders of the G7 \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  '9-Jun-\\n2018 \\n',\n",
       "  'self (gov) \\n',\n",
       "  'Linkhubs \\n',\n",
       "  'American Medical As-\\nsociation (AMA) \\n',\n",
       "  'USA \\n',\n",
       "  'Prof. Associa-\\ntion/Society \\n',\n",
       "  '14-Jun-\\n2018 \\n',\n",
       "  'self \\n',\n",
       "  'W20 \\n',\n",
       "  'IBM \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  'USA \\n',\n",
       "  'Company \\n',\n",
       "  'Key recommenda-\\ntions \\n',\n",
       "  'Royal College of Phy-\\nsicians \\n',\n",
       "  '10 Principles \\n',\n",
       "  'UK Department of \\nHealth & Social Care \\n',\n",
       "  'UK \\n',\n",
       "  'UK \\n',\n",
       "  'Values of a good \\nartificial intelli-\\ngence society \\n',\n",
       "  'Ministry of Economic \\nAffairs and Employ-\\nment \\n',\n",
       "  'Finland \\n',\n",
       "  'Prof. Associa-\\ntion/Society \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\nGovernmental \\nagencies/organi-\\nzations \\n',\n",
       "  'SAP’s guiding prin-\\nciples for artificial \\nintelligence \\nSony Group AI Eth-\\nics Guidelines \\nFramework \\n',\n",
       "  'SAP \\n',\n",
       "  'SONY \\n',\n",
       "  'Machine Intelligence \\nGarage Ethics Com-\\nmittee \\n',\n",
       "  'Germany \\n',\n",
       "  'Company \\n',\n",
       "  'Japan \\n',\n",
       "  'UK \\n',\n",
       "  'Company \\n',\n",
       "  'n.a. \\n',\n",
       "  '18-Sep-\\n2018 \\n',\n",
       "  '25-Sep-\\n2018 \\n28-Sep-\\n2018 \\n',\n",
       "  'self \\n',\n",
       "  'self (group) \\n',\n",
       "  'private sector \\n(start-ups) \\n',\n",
       "  'Web search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 1-30 \\nWeb search \\nresults 31-\\n200 \\n',\n",
       "  ' \\n',\n",
       "  '4 \\n'],\n",
       " ['Dutch Artificial Intel-\\nligence Manifesto \\n',\n",
       "  'Multidisciplinary \\nchallenges \\n',\n",
       "  'Governing Artificial \\nIntelligence. Uphold-\\ning Human Rights & \\nDignity \\n',\n",
       "  'Recommendations \\n',\n",
       "  'Special Interest Group \\non Artificial Intelli-\\ngence (SIGAI), ICT \\nPlatform Netherlands \\n(IPN) \\nData & Society \\n',\n",
       "  'Nether-\\nlands \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion \\n',\n",
       "  'USA \\n',\n",
       "  'Research (NPO) \\n',\n",
       "  'Tieto’s AI ethics \\nguidelines \\n',\n",
       "  'Tieto’s AI ethics \\nguidelines \\n',\n",
       "  'Tieto \\n',\n",
       "  'Finland \\n',\n",
       "  'Company \\n',\n",
       "  'Six Policy Recom-\\nmendations \\n',\n",
       "  'Intel Corporation \\n',\n",
       "  'USA \\n',\n",
       "  'Company \\n',\n",
       "  'Universal Guide-\\nlines for Artificial \\nIntelligence \\n\"… guiding princi-\\nples …\"  \\n',\n",
       "  'AI Principles of Te-\\nlefónica \\nUnity’s six guiding \\nAI principles are as \\nfollows \\n',\n",
       "  'The Public Voice \\n',\n",
       "  'ICDPPC \\n',\n",
       "  'Telefonica \\n',\n",
       "  'Unity Technologies \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Spain \\n',\n",
       "  'USA \\n',\n",
       "  'Mixed (coalition \\nof NGOs, ICOs \\netc.) \\nIGO/supra-na-\\ntional \\n',\n",
       "  'Company \\n',\n",
       "  'Company \\n',\n",
       "  'Guideline \\n',\n",
       "  'Microsoft \\n',\n",
       "  'USA \\n',\n",
       "  'Company \\n',\n",
       "  'Recommendations \\n',\n",
       "  'AI Now Institute \\n',\n",
       "  'USA \\n',\n",
       "  'Academic and \\nresearch institu-\\ntion \\nProf. Associa-\\ntion/Society \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  ' \\n',\n",
       "  'xx-Sep-\\n2018 \\n',\n",
       "  '10-Oct-\\n2018 \\n',\n",
       "  '17-Oct-\\n2018 \\n',\n",
       "  '22-Oct-\\n2018 \\n',\n",
       "  '23-Oct-\\n2018 \\n',\n",
       "  '23-Oct-\\n2018 \\n',\n",
       "  '30-Oct-\\n2018 \\n28-Nov-\\n2018 \\n',\n",
       "  'xx-Nov-\\n2018 \\n',\n",
       "  'xx-Dec-\\n2018 \\n',\n",
       "  '26-Feb-\\n2019 \\n',\n",
       "  'multiple (Dutch \\ngovernment, re-\\nsearchers)  \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'multiple (compa-\\nnies, researchers, \\ngovernments, \\npolicy makers, \\nUN) \\nself \\n',\n",
       "  'public sector \\n(policy makers) \\n',\n",
       "  'multiple (institu-\\ntions, govern-\\nments) \\nunspecified \\n',\n",
       "  'self \\n',\n",
       "  'self \\n',\n",
       "  'developers \\n',\n",
       "  'multiple \\n',\n",
       "  'self \\n',\n",
       "  'Citation \\nchaining \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\nWeb search \\nresults 31-\\n200 \\n',\n",
       "  'Web search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 1-30 \\nManual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  'Intel’s AI Privacy Pol-\\nicy White Paper. Pro-\\ntecting individuals’ \\nprivacy and data in the \\nartificial intelligence \\nworld \\nUniversal Guidelines \\nfor Artificial Intelli-\\ngence \\nDeclaration on ethics \\nand data protection in \\nArtificial Intelligence \\nAI Principles of Tele-\\nfónica \\nIntroducing Unity’s \\nGuiding Principles for \\nEthical AI – Unity \\nBlog \\nResponsible bots: 10 \\nguidelines for devel-\\nopers of conversa-\\ntional AI \\nAI Now 2018 Report \\n',\n",
       "  'Ethics of AI in Radiol-\\nogy: European and \\nNorth American Mul-\\ntisociety Statement \\n',\n",
       "  'European ethical \\nCharter on the use of \\nArtificial Intelligence \\nin judicial systems and \\ntheir environment \\n',\n",
       "  \"Ethically Aligned De-\\nsign: A Vision for Pri-\\noritizing Human Well-\\nbeing with Autono-\\nmous and Intelligent \\nSystems, First Edition \\n(EAD1e) \\nArtificial Intelligence. \\nAustralia's Ethics \\nFramework. A discus-\\nsion Paper \\nEthics Guidelines for \\nTrustworthy AI \\n\",\n",
       "  'Ethical, social, and po-\\nlitical challenges of \\nArtificial Intelligence \\nin Health \\nThe responsible AI \\nframework \\n',\n",
       "  'Digital Decisions \\n',\n",
       "  'Responsible AI and \\nrobotics. An ethical \\nframework. \\nCommitments and \\nprinciples \\n',\n",
       "  'Science, Law and So-\\nciety (SLS) Initiative \\n',\n",
       "  'EU \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  'xx-Feb-\\n2019 \\n',\n",
       "  'multiple (public \\nand private \\nstakeholders) \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'interna-\\ntional \\n',\n",
       "  'Prof. Associa-\\ntion/Society \\n',\n",
       "  '25-Mar-\\n2019 \\n',\n",
       "  'Conclusion \\n',\n",
       "  '\"The five principles \\nof the Ethical Char-\\nter on the Use of \\nArtificial Intelli-\\ngence in Judicial \\nSystems and their \\nenvironment\" \\nGeneral Principles \\n',\n",
       "  'Core principles for \\nAI; A toolkit for \\nethical AI \\n',\n",
       "  'American College of \\nRadiology; European \\nSociety of Radiology; \\nRadiology Society of \\nNorth America; Soci-\\nety for Imaging Infor-\\nmatics in Medicine; \\nEuropean Society of \\nMedical Imaging In-\\nformatics; Canadian \\nAssociation of Radiol-\\nogists; American As-\\nsociation of Physicists \\nin Medicine \\nConcil of Europe: Eu-\\nropean Commission \\nfor the efficiency of \\nJustice (CEPEJ) \\n',\n",
       "  'Institute of Electrical \\nand Electronics Engi-\\nneers (IEEE), The \\nIEEE Global Initiative \\non Ethics of Autono-\\nmous and Intelligent \\nSystems \\nDepartment of Indus-\\ntry Innovation and \\nScience \\n',\n",
       "  'Ethical Principles in \\nthe Context of AI \\nSystems \\nConclusion \\n',\n",
       "  'High-Level Expert \\nGroup on Artificial In-\\ntelligence \\nFuture Advocacy \\n',\n",
       "  'EU \\n',\n",
       "  'UK \\n',\n",
       "  'Australia \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'IGO/supra-na-\\ntional \\n',\n",
       "  'Company \\n',\n",
       "  'Operating AI \\n',\n",
       "  'PriceWaterhouse-\\nCoopers UK \\n',\n",
       "  'UK \\n',\n",
       "  'Company \\n',\n",
       "  'VI. Solutions Part \\n1: Principles \\nOur view \\n',\n",
       "  'Center for Democracy \\n& Technology \\nAccenture UK \\n',\n",
       "  'USA \\n',\n",
       "  'UK \\n',\n",
       "  'NPO/charity \\n',\n",
       "  'Company \\n',\n",
       "  'OP Group \\n',\n",
       "  'Finland \\n',\n",
       "  'Company \\n',\n",
       "  '5-Apr-\\n2019 \\n',\n",
       "  '8-Apr-\\n2019 \\n',\n",
       "  'xx-Apr-\\n2019 \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'OP Financial \\nGroup’s ethical \\nguidelines for artifi-\\ncial intelligence \\nPrinciples for the \\nGovernance of AI \\n',\n",
       "  'The Future Society \\n',\n",
       "  'USA \\n',\n",
       "  'NPO/charity \\n',\n",
       "  'n.a. \\n',\n",
       "  'multiple (tech-\\nnologists, educa-\\ntors, and policy \\nmaker) \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'unspecified \\n',\n",
       "  'multiple (all \\nstakeholders) \\n',\n",
       "  'unspecified \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'multiple (clients)  Web search \\n',\n",
       "  'unspecified \\n',\n",
       "  'private sector \\n',\n",
       "  'self \\n',\n",
       "  'public sector \\n(policy makers) \\n',\n",
       "  'results 31-\\n200 \\nCitation \\nchaining \\nWeb search \\nresults 1-30 \\n',\n",
       "  'Web search \\nresults 31-\\n200 \\n',\n",
       "  'Linkhubs \\n',\n",
       "  '5 \\n'],\n",
       " ['10 Principles of re-\\nsponsible AI \\n',\n",
       "  'Summary of our \\nproposed Recom-\\nmendations \\n',\n",
       "  'Women leading in AI \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'Action Points \\n',\n",
       "  'AI4People \\n',\n",
       "  'EU \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'n.a. \\n',\n",
       "  'public sector (na-\\ntional and inter-\\nnational policy \\nmakers) \\nunspecified \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  'AI4People—An Ethi-\\ncal Framework for a \\nGood AI Society: Op-\\nportunities, Risks, \\nPrinciples, and Rec-\\nommendations \\nAI Principles & Ethics \\n',\n",
       "  'AI Principles; AI \\nguidelines \\n',\n",
       "  'Smart Dubai \\n',\n",
       "  'UAE \\n',\n",
       "  'Governmental \\nagencies/organi-\\nzations \\n',\n",
       "  'n.a. \\n2018? \\n',\n",
       "  'self \\n',\n",
       "  'Manual in-\\nclusion \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  ' \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  '6 \\n'],\n",
       " ['Table S2. Screening and Eligibility (details) \\n \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n- \\n',\n",
       "  '- \\n',\n",
       "  '- \\n',\n",
       "  'Types: websites and documents published online or parts thereof such as policy documents, principles, \\nguidelines, recommendations, dedicated webpages, institutional reports and declarations; \\n',\n",
       "  'Issuers: institutions, associations and organizations such as companies, corporations, NGOs, NPOs, aca-\\ndemic and professional societies, governmental institutions and affiliated organizations; \\nLanguage: English, German, French, Italian, Greek (the languages spoken by the researchers). \\nTypes: videos, images, audio/podcasts, books, blog articles, academic articles, journalistic articles, syl-\\nlabi, legislation, official standards, conference summaries; \\n',\n",
       "  'Issuers: individual authors; \\n',\n",
       "  'Language: others than those above. \\n',\n",
       "  'which refer to “artificial intelligence” and/or “AI”, either explicitly in their title or within their descrip-\\ntion (example: UK, House of Lords: “AI in the UK: ready, willing and able”); or \\nwhich do not contain the above reference in their title but mention “robot” or “robotics” instead and ref-\\nerence AI or artificial intelligence explicitly as being part of robots and/or robotics (example: “Principles \\nof robotics”); or \\nwhich do not contain the above reference in their title but are thematically equivalent (by referring to \\n“algorithms”, “predictive analytics”, “cognitive computing”, “machine learning”, “deep learning”, “au-\\ntonomous” or “automated” instead (example: “Automated and Connected Driving: Report”). \\nwhich self-proclaim to be a principle or guideline (including “ethics/ethical”, “principles”, “tenets”, \\n“declaration”, “policy”, “guidelines”, “values” etc.); or \\nwhich is expressed in normative or prescriptive language (i.e. with modal verbs or imperatives); or \\nwhich is principle- or value-based (i.e. indicating a preference and/or a commitment to a certain ethical \\nvision or course of action). \\nwebsites and documents about robotics that do not mention artificial intelligence as being part of ro-\\nbots/robotics; and \\nwebsites and documents about data or data ethics that do not mention artificial intelligence as being part \\nof data; \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  'Screening  \\nSources consid-\\nered: \\n',\n",
       "  'Sources ex-\\ncluded: \\n',\n",
       "  'Eligibility \\nSources in-\\ncluded: \\n',\n",
       "  'Excluded \\nsources: \\n',\n",
       "  ' \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  '7 \\n'],\n",
       " [' \\n',\n",
       "  'Question ad-\\ndressed \\nWhat? \\n',\n",
       "  'Table S3. Categorization after themeing and code mapping \\n \\n',\n",
       "  'Thematic family \\n',\n",
       "  'Themes \\n',\n",
       "  'Ethical Principles & Values \\n',\n",
       "  'Technical and methodological aspects \\n',\n",
       "  'Ethical Principles \\n',\n",
       "  'Beneficence  \\nNon-maleficence \\nTrust \\nTransparency & Explainability \\nFreedom and autonomy (incl. consent) \\nPrivacy \\nJustice, Fairness & Equity \\nResponsibility & Accountability  \\nDignity \\nSustainability \\nSolidarity \\n',\n",
       "  'Specific functionalities \\n',\n",
       "  'Feedback & feedback-loop  \\nDecision-making \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\nV. \\nVI. \\nVII. \\nVIII. \\nIX. \\nX. \\nXI. \\n',\n",
       "  'I. \\nII. \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\nV. \\nVI. \\nVII. \\nVIII. \\nIX. \\nX. \\n',\n",
       "  'Data & datasets  \\n',\n",
       "  'Data origin/input \\nData use \\nMetadata \\nAlgorithms \\n',\n",
       "  'Methodological challenges \\n',\n",
       "  'Methodology \\nMetris & measurements \\nTests, testing \\nAmbiguity & uncertainty \\nAccuracy \\nReliability \\nEvidence and validation \\nBlack-box (opacity) \\nData security \\nQuality (of data/system/etc.) \\n',\n",
       "  'Impact \\n',\n",
       "  'Who? \\n',\n",
       "  'Design & development \\n',\n",
       "  'Users \\n',\n",
       "  ' \\n',\n",
       "  '  Benefits \\n',\n",
       "  'AI strengths, advantages \\nKnowledge \\nInnovation \\nEnhancement \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\n  Risks \\nI. \\nRisks \\nII. \\nMalfunction \\nIII. \\nMisuse & dual-use \\nIV. \\nDeception \\nV. \\nDiscrimination (duplicate in Justice&Fairness) \\nVI. \\nSurveillance \\nVII. \\nManipulation \\nVIII. \\nArms race \\n Impact assessment \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\nV. \\nVI. \\nI. \\nII. \\nIII. \\nIV. \\nI. \\nII. \\nIII. \\nIV. \\nV. \\n',\n",
       "  'Impact \\nGoals/Purposes/Intentions \\nPublic opinion \\nRisk evaluation & mitigation (duplicate in Risks) \\nMonitoring/Precaution \\nFuture of work \\nIndustry \\nAI researchers \\nDesigners \\nDevelopers  \\nEnd users \\nOrganisations \\nPublic sector actors \\nMilitary \\nCommunities \\n',\n",
       "  ' \\n',\n",
       "  '8 \\n'],\n",
       " ['Specific stakeholders \\n',\n",
       "  'How? \\n',\n",
       "  'Social engagement \\n',\n",
       "  'Soft policy \\n',\n",
       "  'Economic incentives \\n',\n",
       "  'Regulation & audits \\n',\n",
       "  'I. \\nII. \\nIII. \\nIV. \\nV. \\nI. \\nII. \\nIII. \\nIV. \\nI. \\nII. \\nIII. \\nIV. \\nV. \\nVI. \\nVII. \\nVIII. \\nIX. \\nX. \\nXI. \\nXII. \\nXIII. \\n',\n",
       "  'Ethical and/or auditing committees \\nGovernment \\nPolicy makers \\nResearchers & scientists \\nVulnerable groups & minorities \\nKnowledge commons \\nEducation & training \\nPublic deliberation & democratic processes \\nStakeholder involvement & partnerships \\nStandards \\nCertification \\nBest practices \\nWhistleblowing \\nBusiness model & strategy \\nFunding & investments \\nTaxes/taxation \\nLaws & regulation (general) \\nData protection regulation \\nIP law \\nHuman rights treaties \\nOther rights & laws \\nAudits & auditing \\n',\n",
       "  ' \\n',\n",
       "  ' \\n \\n',\n",
       "  ' \\n',\n",
       "  ' \\n',\n",
       "  '9 \\n']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_text_from_pdf(file_name)[\"separated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
