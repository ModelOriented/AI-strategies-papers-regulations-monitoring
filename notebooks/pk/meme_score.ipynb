{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "btdf = pd.read_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/processed_big.parquet')\n",
    "cit_df = pd.read_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset.parquet')\n",
    "cdf = cit_df[['paper_id','inbound_citations','outbound_citations']]\n",
    "df = pd.merge(btdf,cdf,on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('meme_score.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum inbound_citations that has meme of publication with this meme and\\sum inbound_citations of publication with this meme\n",
    "sum (pub that has a meme and does not have a meme-carrer in inbound_citations)/sum(pub that do not cite meme carrers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_list = dict()\n",
    "memes=[]\n",
    "for chunks_list in df['noun_chunks_cleaned']:\n",
    "    for chunk in chunks_list:\n",
    "        if chunk not in meme_list:\n",
    "            meme_list[chunk]=1\n",
    "            memes.append(chunk)\n",
    "        else:\n",
    "            meme_list[chunk]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_lens</th>\n",
       "      <th>nouns</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>noun_chunks_cleaned</th>\n",
       "      <th>inbound_citations</th>\n",
       "      <th>outbound_citations</th>\n",
       "      <th>inbound_citations_clear</th>\n",
       "      <th>outbound_citations_clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199668001</td>\n",
       "      <td>196</td>\n",
       "      <td>[Road, construction, projects, territory, over...</td>\n",
       "      <td>[Road construction projects, the territory, th...</td>\n",
       "      <td>[road, construction, project, on, the, territo...</td>\n",
       "      <td>[road construction project, territory, republi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[106476531, 67083539, 36731616, 34616216, 1096...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2879234</td>\n",
       "      <td>235</td>\n",
       "      <td>[nets, CNNs, performance, history, approaches,...</td>\n",
       "      <td>[Convolutional neural nets, CNNs, remarkable p...</td>\n",
       "      <td>[convolutional, neural, net, (, cnn, ), have, ...</td>\n",
       "      <td>[convolutional neural net, cnn, remarkable per...</td>\n",
       "      <td>[11015941, 52160763, 199488257, 23874112, 4241...</td>\n",
       "      <td>[206592419, 215721, 10111903, 1003907, 3198903...</td>\n",
       "      <td>[340420, 471907, 250792]</td>\n",
       "      <td>[215721, 127386, 392527]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17786914</td>\n",
       "      <td>120</td>\n",
       "      <td>[results, benchmarks, modeling, speech, recogn...</td>\n",
       "      <td>[excellent results, benchmarks, acoustic model...</td>\n",
       "      <td>[recently, ,, deep, neural, networks(DNNs, ), ...</td>\n",
       "      <td>[excellent result, benchmark, acoustic modelin...</td>\n",
       "      <td>[198931159]</td>\n",
       "      <td>[9530137, 398770, 207168299, 14832074, 1799800...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[398770, 299222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17432300</td>\n",
       "      <td>235</td>\n",
       "      <td>[characters, structure, character, arrangement...</td>\n",
       "      <td>[East-Asian characters, a rich hierarchical st...</td>\n",
       "      <td>[east, -, asian, character, possess, a, rich, ...</td>\n",
       "      <td>[east asian character, rich hierarchical struc...</td>\n",
       "      <td>[15983137, 7625356, 15404413, 199472639, 47640...</td>\n",
       "      <td>[371064, 3246932, 8991475, 36725681, 32031694,...</td>\n",
       "      <td>[467570]</td>\n",
       "      <td>[371064]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204957502</td>\n",
       "      <td>33</td>\n",
       "      <td>[Internet, articles, multimedia, content, life...</td>\n",
       "      <td>[the Internet, countless articles, multimedia ...</td>\n",
       "      <td>[with, the, internet, become, widespread, ,, c...</td>\n",
       "      <td>[internet, countless article, multimedia conte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    paper_id  doc_lens                                              nouns  \\\n",
       "0  199668001       196  [Road, construction, projects, territory, over...   \n",
       "1    2879234       235  [nets, CNNs, performance, history, approaches,...   \n",
       "2   17786914       120  [results, benchmarks, modeling, speech, recogn...   \n",
       "3   17432300       235  [characters, structure, character, arrangement...   \n",
       "4  204957502        33  [Internet, articles, multimedia, content, life...   \n",
       "\n",
       "                                         noun_chunks  \\\n",
       "0  [Road construction projects, the territory, th...   \n",
       "1  [Convolutional neural nets, CNNs, remarkable p...   \n",
       "2  [excellent results, benchmarks, acoustic model...   \n",
       "3  [East-Asian characters, a rich hierarchical st...   \n",
       "4  [the Internet, countless articles, multimedia ...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [road, construction, project, on, the, territo...   \n",
       "1  [convolutional, neural, net, (, cnn, ), have, ...   \n",
       "2  [recently, ,, deep, neural, networks(DNNs, ), ...   \n",
       "3  [east, -, asian, character, possess, a, rich, ...   \n",
       "4  [with, the, internet, become, widespread, ,, c...   \n",
       "\n",
       "                                 noun_chunks_cleaned  \\\n",
       "0  [road construction project, territory, republi...   \n",
       "1  [convolutional neural net, cnn, remarkable per...   \n",
       "2  [excellent result, benchmark, acoustic modelin...   \n",
       "3  [east asian character, rich hierarchical struc...   \n",
       "4  [internet, countless article, multimedia conte...   \n",
       "\n",
       "                                   inbound_citations  \\\n",
       "0                                                 []   \n",
       "1  [11015941, 52160763, 199488257, 23874112, 4241...   \n",
       "2                                        [198931159]   \n",
       "3  [15983137, 7625356, 15404413, 199472639, 47640...   \n",
       "4                                                 []   \n",
       "\n",
       "                                  outbound_citations  \\\n",
       "0  [106476531, 67083539, 36731616, 34616216, 1096...   \n",
       "1  [206592419, 215721, 10111903, 1003907, 3198903...   \n",
       "2  [9530137, 398770, 207168299, 14832074, 1799800...   \n",
       "3  [371064, 3246932, 8991475, 36725681, 32031694,...   \n",
       "4                                                 []   \n",
       "\n",
       "    inbound_citations_clear  outbound_citations_clear  \n",
       "0                        []                        []  \n",
       "1  [340420, 471907, 250792]  [215721, 127386, 392527]  \n",
       "2                        []          [398770, 299222]  \n",
       "3                  [467570]                  [371064]  \n",
       "4                        []                        []  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/ppaul/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#for i in df.iterrows:\n",
    "#    memes[0] in i['noun_chunks_cleaned']#df[]all() not in df['outbound_citations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc=[]\n",
    "out=[]\n",
    "for i,row in df.iterrows():\n",
    "    cit =[]\n",
    "    for cited in row['outbound_citations']:\n",
    "        cited = int(cited)\n",
    "        if cited in df['paper_id']:\n",
    "            cit.append(cited)\n",
    "        \n",
    "    out.append(cit)\n",
    "    cit=[]\n",
    "    for citing in row['inbound_citations']:\n",
    "        citing = int(citing)\n",
    "        if citing in df['paper_id']:\n",
    "            cit.append(citing)\n",
    "    inc.append(cit)\n",
    "df['inbound_citations_clear']=inc\n",
    "df['outbound_citations_clear']=out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('meme_score.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noun_chunks_cleaned'] = df['noun_chunks_cleaned'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['noun_chunks_cleaned'].str.contains('a a b b',regex=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = MultiLabelBinarizer(sparse_output=True)\n",
    "memes_enc = enc.fit_transform(df['noun_chunks_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a a a topology',\n",
       " 'a a b b',\n",
       " 'a a baseline approach',\n",
       " 'a a baseline single classifier framework',\n",
       " 'a a big pool',\n",
       " 'a a brute force optimization',\n",
       " 'a a cad system design',\n",
       " 'a a classical rule base system',\n",
       " 'a a classification tree',\n",
       " 'a a clear functional separation',\n",
       " 'a a comparison',\n",
       " 'a a compound rule base expert system',\n",
       " 'a a concert like condition',\n",
       " 'a a contextual combination',\n",
       " 'a a conventional feedforward multilayer neural network',\n",
       " 'a a d tree expository',\n",
       " 'a a data fidelity term',\n",
       " 'a a datum drive initial segmentation',\n",
       " 'a a decision theory model',\n",
       " 'a a design',\n",
       " 'a a design workflow',\n",
       " 'a a domain level plan recognizer',\n",
       " 'a a family',\n",
       " 'a a fast prototype sdr platform',\n",
       " 'a a fault detector',\n",
       " 'a a first order approximation',\n",
       " 'a a fuzzy expert system',\n",
       " 'a a general image sentiment classifier',\n",
       " 'a a generator g',\n",
       " 'a a good feature extraction technique',\n",
       " 'a a hybrid assemble architecture',\n",
       " 'a a knowledge base',\n",
       " 'a a learning framework',\n",
       " 'a a lostcontract',\n",
       " 'a a method',\n",
       " 'a a modular linguistic analysis pipeline',\n",
       " 'a a multi headed model structure',\n",
       " 'a a multi threaded grid search method',\n",
       " 'a a multilayer perceptron',\n",
       " 'a a naive bayesian classifier',\n",
       " 'a a near center classifier',\n",
       " 'a a neural network',\n",
       " 'a a neural network regression',\n",
       " 'a a new numerical regularization method',\n",
       " 'a a non contextual segmentation stage',\n",
       " 'a a nontraditional methodology',\n",
       " 'a a novel method',\n",
       " 'a a novel semantic sensitive framework',\n",
       " 'a a novel semantic sensitive video content characterization',\n",
       " 'a a outer radius',\n",
       " 'a a packet classifier',\n",
       " 'a a parameter fast fourier transform',\n",
       " 'a a pattern recognition classifier',\n",
       " 'a a pedagogical game agent',\n",
       " 'a a pipeline approach',\n",
       " 'a a post facto quality metric',\n",
       " 'a a predictor',\n",
       " 'a a provider machine learning model',\n",
       " 'a a pyramid base algorithm',\n",
       " 'a a ranking',\n",
       " 'a a real time hand gesture formation monitor',\n",
       " 'a a recurrent encoder',\n",
       " 'a a retrain algorithm',\n",
       " 'a a robust technique',\n",
       " 'a a rule',\n",
       " 'a a rule base approach',\n",
       " 'a a segmentation component',\n",
       " 'a a self supervise training',\n",
       " 'a a semantic medical event characterization technique',\n",
       " 'a a semantic sensitive video content representation and semantic video concept model framework',\n",
       " 'a a semantic senstive video content representation framework',\n",
       " 'a a simulate dynamical system',\n",
       " 'a a single classifier',\n",
       " 'a a single well production system',\n",
       " 'a a slang classifier',\n",
       " 'a a star algorithm',\n",
       " 'a a statistical mechanism',\n",
       " 'a a statistically significant reduction',\n",
       " 'a a stochastic image segmentation algorithm',\n",
       " 'a a storage process',\n",
       " 'a a summer institute',\n",
       " 'a a sup',\n",
       " 'a a support vector machine',\n",
       " 'a a survey',\n",
       " 'a a system architecture',\n",
       " 'a a systematic analysis',\n",
       " 'a a theoretical and empirical comparative analysis',\n",
       " 'a a tool',\n",
       " 'a a toolset',\n",
       " 'a a tracking platform',\n",
       " 'a a training algorithm',\n",
       " 'a a trustworthiness score',\n",
       " 'a a vector quantization',\n",
       " 'a a very small subset',\n",
       " 'a a voice recognition system',\n",
       " 'a a vr system',\n",
       " 'a a well understanding',\n",
       " 'a a wrapper procedure',\n",
       " 'a abdelmoty',\n",
       " 'a abelian group unification',\n",
       " 'a ability',\n",
       " 'a abundance quantization b feature selection c literature analysis d selection',\n",
       " 'a abundant compute power',\n",
       " 'a accelerator',\n",
       " 'a access',\n",
       " 'a accuracy',\n",
       " 'a accuracy preserve b data efficient and c high expressive power',\n",
       " 'a accurate depth recovery',\n",
       " 'a acoustic spectral variability',\n",
       " 'a acquire worker',\n",
       " 'a acres',\n",
       " 'a activity',\n",
       " 'a ad',\n",
       " 'a adaline',\n",
       " 'a adapter interface a',\n",
       " 'a adaptive feature',\n",
       " 'a advanced robotic project',\n",
       " 'a agent',\n",
       " 'a agent model',\n",
       " 'a ai',\n",
       " 'a ailable inria research report no page',\n",
       " 'a algorithm',\n",
       " 'a algorithm de sign generic design strategy',\n",
       " 'a algorithm fit all approach',\n",
       " 'a all feature vector',\n",
       " 'a all spectral band',\n",
       " 'a all time series',\n",
       " 'a alt',\n",
       " 'a alzheimer patient datum',\n",
       " 'a ambiguous road surface condition',\n",
       " 'a an accurate model',\n",
       " 'a an action system',\n",
       " 'a an algorithm',\n",
       " 'a an approach',\n",
       " 'a an architecture',\n",
       " 'a an arm trajectory base method',\n",
       " 'a an auditory map',\n",
       " 'a an augment semantic classification',\n",
       " 'a an auto derive feature base inception network',\n",
       " 'a an automatic coarse to fine figure ground scene segmentation module',\n",
       " 'a an automatic recommender',\n",
       " 'a an autonomous agent',\n",
       " 'a an edge device',\n",
       " 'a an effective component wise analysis approach',\n",
       " 'a an efficient decision make procedure',\n",
       " 'a an embed semantic medical search engine',\n",
       " 'a an encoding',\n",
       " 'a an enlarged spectral library',\n",
       " 'a an exist approach',\n",
       " 'a an experimental study',\n",
       " 'a an expert system',\n",
       " 'a an identification',\n",
       " 'a an impulse classifier',\n",
       " 'a an infer phase',\n",
       " 'a an influx',\n",
       " 'a an intelligent regulatory advisor',\n",
       " 'a an lda model',\n",
       " 'a an n gram language model',\n",
       " 'a an nvef word pair identifier',\n",
       " 'a an overview',\n",
       " 'a analysing method',\n",
       " 'a analysis',\n",
       " 'a analyze',\n",
       " 'a anatomical connectivity',\n",
       " 'a ancillary information',\n",
       " 'a and b call',\n",
       " 'a and b cohort',\n",
       " 'a and b coordinate',\n",
       " 'a and b matrix',\n",
       " 'a and b network',\n",
       " 'a and b parameter',\n",
       " 'a and b plane',\n",
       " 'a and b template circuit',\n",
       " 'a and b template optimization',\n",
       " 'a and b type inspection',\n",
       " 'a and base model',\n",
       " 'a and c direction',\n",
       " 'a and c pair',\n",
       " 'a and equation',\n",
       " 'a and its function realization',\n",
       " 'a and method empirical behavior',\n",
       " 'a and model b',\n",
       " 'a and optimization base approach',\n",
       " 'a and pheromone mechanism',\n",
       " 'a and t classification',\n",
       " 'a ann',\n",
       " 'a ann instance',\n",
       " 'a ann observer',\n",
       " 'a annotate chord sequence',\n",
       " 'a annuli',\n",
       " 'a answer pattern',\n",
       " 'a application',\n",
       " 'a applications',\n",
       " 'a approach',\n",
       " 'a appropriate database training corpus',\n",
       " 'a appropriate method',\n",
       " 'a approximate general inference algorithm',\n",
       " 'a arai',\n",
       " 'a arc weights',\n",
       " 'a area',\n",
       " 'a arrival forecast curve',\n",
       " 'a artefact product structure',\n",
       " 'a artifact',\n",
       " 'a artificial intelligent base approach',\n",
       " 'a artificial neural',\n",
       " 'a aspect',\n",
       " 'a asse et al',\n",
       " 'a athlete',\n",
       " 'a atomic primitive type',\n",
       " 'a atrial fibrillation',\n",
       " 'a attribute',\n",
       " 'a auc',\n",
       " 'a auditory cortical neuron',\n",
       " 'a augment cityscapes and camvid dataset',\n",
       " 'a autoencoder b',\n",
       " 'a automate hyperparameter tuning',\n",
       " 'a automate ranking',\n",
       " 'a automate storage',\n",
       " 'a automate synthesis',\n",
       " 'a automatic image datum registration',\n",
       " 'a automatic recognition',\n",
       " 'a automatic selection',\n",
       " 'a automatic vessel tracking',\n",
       " 'a availability',\n",
       " 'a average',\n",
       " 'a avoidance',\n",
       " 'a axis',\n",
       " 'a b',\n",
       " 'a b a',\n",
       " 'a b a σ',\n",
       " 'a b and a machine learning algorithm',\n",
       " 'a b and c subset',\n",
       " 'a b and d class',\n",
       " 'a b and i template',\n",
       " 'a b and x site',\n",
       " 'a b b a c b a',\n",
       " 'a b c',\n",
       " 'a b c and d class',\n",
       " 'a b c d',\n",
       " 'a b c d e f',\n",
       " 'a b c form',\n",
       " 'a b c lbd triple',\n",
       " 'a b ccd september december cloud free image',\n",
       " 'a b charge couple device',\n",
       " 'a b color space',\n",
       " 'a b component',\n",
       " 'a b d e',\n",
       " 'a b experiment',\n",
       " 'a b fig',\n",
       " 'a b figure',\n",
       " 'a b iff',\n",
       " 'a b neither classification response',\n",
       " 'a b orientation map',\n",
       " 'a b p',\n",
       " 'a b parameter',\n",
       " 'a b r',\n",
       " 'a b s',\n",
       " 'a b sampling',\n",
       " 'a b stack',\n",
       " 'a b test',\n",
       " 'a b test like experiment',\n",
       " 'a b test result',\n",
       " 'a b testing',\n",
       " 'a b testing approach',\n",
       " 'a b testing experiment',\n",
       " 'a b testing method',\n",
       " 'a b testing metric',\n",
       " 'a b testing platform',\n",
       " 'a b testing result',\n",
       " 'a b testing scenario',\n",
       " 'a back end pipeline',\n",
       " 'a back propagation neural network',\n",
       " 'a backbone',\n",
       " 'a backbone visualization',\n",
       " 'a backdrop telephone speech technology',\n",
       " 'a backend self decommission protocol',\n",
       " 'a background',\n",
       " 'a backpropagation algorithm',\n",
       " 'a backpropagation method',\n",
       " 'a backpropagation multilayer perceptron and radial basis support vector machine',\n",
       " 'a backward and forward non rigid alignment strategy',\n",
       " 'a backward pass',\n",
       " 'a bacterial census',\n",
       " 'a bad case performance',\n",
       " 'a bad idea',\n",
       " 'a bag',\n",
       " 'a bag of word bow model',\n",
       " 'a balance',\n",
       " 'a balanced approach',\n",
       " 'a balanced bagging algorithm',\n",
       " 'a balanced low level activity state',\n",
       " 'a balanced revenue based resource sharing scheme',\n",
       " 'a balanced set',\n",
       " 'a balanced training set',\n",
       " 'a balancing',\n",
       " 'a ball',\n",
       " 'a bam',\n",
       " 'a bandit algorithm',\n",
       " 'a bank',\n",
       " 'a bank interleaving architecture',\n",
       " 'a bare bones approach',\n",
       " 'a barrel',\n",
       " 'a barren plateau',\n",
       " 'a barrier',\n",
       " 'a basden',\n",
       " 'a base',\n",
       " 'a base approach',\n",
       " 'a base classifier performance',\n",
       " 'a base graphical modeling',\n",
       " 'a base model',\n",
       " 'a base specie detector',\n",
       " 'a baseline',\n",
       " 'a baseline algorithm',\n",
       " 'a baseline condition',\n",
       " 'a baseline method',\n",
       " 'a baseline system',\n",
       " 'a basic alignment',\n",
       " 'a basic approach',\n",
       " 'a basic cnn b cnn',\n",
       " 'a basic feature',\n",
       " 'a basic form',\n",
       " 'a basic mechanism',\n",
       " 'a basic method',\n",
       " 'a basic nnar model',\n",
       " 'a basic phone usage',\n",
       " 'a basic pre',\n",
       " 'a basic problem',\n",
       " 'a basic qualitative ca based model',\n",
       " 'a basic summary',\n",
       " 'a basic vector model',\n",
       " 'a basic video browser',\n",
       " 'a basis',\n",
       " 'a basque question answering system',\n",
       " 'a batch',\n",
       " 'a batch algorithm',\n",
       " 'a batch learning process',\n",
       " 'a batch mode',\n",
       " 'a bayes classifier',\n",
       " 'a bayes net toolkit',\n",
       " 'a bayesian additive regression tree model',\n",
       " 'a bayesian approach',\n",
       " 'a bayesian base classifier',\n",
       " 'a bayesian cbr system',\n",
       " 'a bayesian classifier',\n",
       " 'a bayesian computer vision system',\n",
       " 'a bayesian decision base neural network',\n",
       " 'a bayesian entropy',\n",
       " 'a bayesian framework',\n",
       " 'a bayesian learning application',\n",
       " 'a bayesian network',\n",
       " 'a bayesian network approach',\n",
       " 'a bayesian neural network',\n",
       " 'a bayesian neural network approach',\n",
       " 'a bayesian optimization algorithm',\n",
       " 'a bayesian segmentation framework',\n",
       " 'a bayesian statistical interpretation',\n",
       " 'a bb algorithm',\n",
       " 'a bcg system',\n",
       " 'a bci',\n",
       " 'a bci detect detailed movement imagination',\n",
       " 'a bci device',\n",
       " 'a bci paradigm',\n",
       " 'a bcmi',\n",
       " 'a bdi approach',\n",
       " 'a be b mode',\n",
       " 'a beacon base localization system',\n",
       " 'a beginner guide',\n",
       " 'a behavior',\n",
       " 'a behavior base architecture',\n",
       " 'a behavior change',\n",
       " 'a behavior integration mechanism',\n",
       " 'a behavioral analysis',\n",
       " 'a behavioral study',\n",
       " 'a behavioural control framework',\n",
       " 'a belief',\n",
       " 'a belief revision model',\n",
       " 'a belief theoretic relational database',\n",
       " 'a believability',\n",
       " 'a believable sensory experience',\n",
       " 'a believesthat b',\n",
       " 'a benchmark',\n",
       " 'a benchmark dataset',\n",
       " 'a benchmark evaluation',\n",
       " 'a benchmark image dataset',\n",
       " 'a benchmark setup',\n",
       " 'a benefit',\n",
       " 'a ber',\n",
       " 'a bernoulli neural network',\n",
       " 'a berthing position',\n",
       " 'a best practice analysis',\n",
       " 'a beta deposition',\n",
       " 'a beta test',\n",
       " 'a bewildering range',\n",
       " 'a bfgs matrix inverse approximation',\n",
       " 'a bi convex maximum likelihood base solution',\n",
       " 'a bi criteria neural control scheme',\n",
       " 'a bi criterion scheme',\n",
       " 'a bi criterion velocity minimization neural planning scheme',\n",
       " 'a bi directional gated recurrent unit',\n",
       " 'a bi directional mapping',\n",
       " 'a bi level optimization',\n",
       " 'a bias',\n",
       " 'a biased competition model',\n",
       " 'a biased training datum',\n",
       " 'a bibliography',\n",
       " 'a bibliometric tool',\n",
       " 'a biclustering method',\n",
       " 'a bid',\n",
       " 'a bidimensional view',\n",
       " 'a bidirectional interaction',\n",
       " 'a bidirectional structure',\n",
       " 'a bifurcation phenomenon',\n",
       " 'a big amount',\n",
       " 'a big attack surface',\n",
       " 'a big challenge',\n",
       " 'a big data collection unit',\n",
       " 'a big dataset',\n",
       " 'a big datum',\n",
       " 'a big datum analytic',\n",
       " 'a big datum environment',\n",
       " 'a big impact',\n",
       " 'a big issue',\n",
       " 'a big learning classifier systems',\n",
       " 'a big number',\n",
       " 'a big piece',\n",
       " 'a big player base',\n",
       " 'a big problem',\n",
       " 'a big reward',\n",
       " 'a bilevel rendition result',\n",
       " 'a bilingual segment',\n",
       " 'a billing model',\n",
       " 'a bilstm',\n",
       " 'a bimodal palmprint verification feature level fusion',\n",
       " 'a binarization method',\n",
       " 'a binarization process',\n",
       " 'a binarize neural network',\n",
       " 'a binary block code',\n",
       " 'a binary classification',\n",
       " 'a binary classification problem',\n",
       " 'a binary classifier',\n",
       " 'a binary classifier sub class distribution',\n",
       " 'a binary decision tree implementation',\n",
       " 'a binary layer',\n",
       " 'a binary random process',\n",
       " 'a binary relevance',\n",
       " 'a binary representation',\n",
       " 'a binary sequence',\n",
       " 'a binary training class',\n",
       " 'a binary vector',\n",
       " 'a bio inspire approach',\n",
       " 'a bio inspire connectionist approach',\n",
       " 'a bio inspire method',\n",
       " 'a bio medical signal analysis flow',\n",
       " 'a bio plausible structure',\n",
       " 'a bioartificial ecosystem',\n",
       " 'a biogeography based optimization',\n",
       " 'a biological development model',\n",
       " 'a biological nervous system',\n",
       " 'a biological neural network',\n",
       " 'a biologically hardwire notion',\n",
       " 'a biologically inspire module',\n",
       " 'a biologically motivated and computationally efficient natural language a question answer system',\n",
       " 'a biologically motivated approach',\n",
       " 'a biologically motivated scheme',\n",
       " 'a biomedical article',\n",
       " 'a biometric',\n",
       " 'a biometric encryption approach incorporating fingerprint indexing',\n",
       " 'a biometric identification',\n",
       " 'a biomimetic sensor',\n",
       " 'a biomimetic system',\n",
       " 'a biophysical model',\n",
       " 'a biopsy',\n",
       " 'a bipolar possibilistic representation',\n",
       " 'a bird',\n",
       " 'a bird eye grid',\n",
       " 'a birth date',\n",
       " 'a bit',\n",
       " 'a bit facial asymmetry code',\n",
       " 'a bizarre system',\n",
       " 'a black box',\n",
       " 'a black box optimization',\n",
       " 'a blackboard expert system shell',\n",
       " 'a blast e',\n",
       " 'a blind denoising task',\n",
       " 'a blind scenario technique',\n",
       " 'a blind watermarking scheme',\n",
       " 'a bloch',\n",
       " 'a block',\n",
       " 'a block base image segmentation technique',\n",
       " 'a block based human model',\n",
       " 'a block result',\n",
       " 'a blockchain base framework',\n",
       " 'a blockchain technology',\n",
       " 'a blocking problem',\n",
       " 'a blog',\n",
       " 'a blood glucose level estimation model',\n",
       " 'a blossoming',\n",
       " 'a blue strip',\n",
       " 'a blueprint',\n",
       " 'a boaster',\n",
       " 'a boat',\n",
       " 'a body',\n",
       " 'a bof approach',\n",
       " 'a bolt joint',\n",
       " 'a bond',\n",
       " 'a bone',\n",
       " 'a bone dl cnn',\n",
       " 'a book',\n",
       " 'a boolean encoding',\n",
       " 'a boon',\n",
       " 'a boost algorithm',\n",
       " 'a boost approach',\n",
       " 'a boot loader',\n",
       " 'a bootstrappe module',\n",
       " 'a border training algorithm',\n",
       " 'a bottleneck combination strategy',\n",
       " 'a bottleneck problem',\n",
       " 'a bottom up approach',\n",
       " 'a bottom up workflow mining approach',\n",
       " 'a bound',\n",
       " 'a boundary',\n",
       " 'a boundary refinement method',\n",
       " 'a boundary web',\n",
       " 'a bounded index',\n",
       " 'a bounded search space',\n",
       " 'a bounding box',\n",
       " 'a bounding box regression method',\n",
       " 'a bow shape serial position curve',\n",
       " 'a box',\n",
       " 'a box classification',\n",
       " 'a box consistency checking',\n",
       " 'a bp drilling diagnosis model',\n",
       " 'a bp neural network model',\n",
       " 'a bpnn',\n",
       " 'a bracket scoring procedure',\n",
       " 'a bradford book',\n",
       " 'a brain',\n",
       " 'a brain body robot interface',\n",
       " 'a brain connectivity',\n",
       " 'a brain function',\n",
       " 'a brain or nerve cell',\n",
       " 'a brainstorming session',\n",
       " 'a branch',\n",
       " 'a branch and bound algorithm',\n",
       " 'a brave new world',\n",
       " 'a breach',\n",
       " 'a break',\n",
       " 'a break notification',\n",
       " 'a breakdown',\n",
       " 'a breakthrough disruptive situational management',\n",
       " 'a bridge',\n",
       " 'a brief description',\n",
       " 'a brief historical review',\n",
       " 'a brief history',\n",
       " 'a brief index',\n",
       " 'a brief introduction',\n",
       " 'a brief qverview',\n",
       " 'a brief review',\n",
       " 'a brilliant student',\n",
       " 'a broad and difficult to define category',\n",
       " 'a broad array',\n",
       " 'a broad base program',\n",
       " 'a broad category',\n",
       " 'a broad comparative analysis',\n",
       " 'a broad context',\n",
       " 'a broad document class',\n",
       " 'a broad medical image dataset',\n",
       " 'a broad negative class',\n",
       " 'a broad range',\n",
       " 'a broad scope',\n",
       " 'a broad subject',\n",
       " 'a broad survey',\n",
       " 'a broad theme',\n",
       " 'a broader perspective',\n",
       " 'a broadly applicable unified theoretical framework',\n",
       " 'a broker approach',\n",
       " 'a brown',\n",
       " 'a brute force',\n",
       " 'a bsolute georeferencing',\n",
       " 'a bsp',\n",
       " 'a bsp model',\n",
       " 'a buffer',\n",
       " 'a buffering strategy',\n",
       " 'a bug',\n",
       " 'a build in automatic safeguard mechanism',\n",
       " 'a building',\n",
       " 'a building representation',\n",
       " 'a bunch',\n",
       " 'a bundant dynamic hand gesture',\n",
       " 'a burden',\n",
       " 'a burst',\n",
       " 'a bus',\n",
       " 'a business outcome',\n",
       " 'a butler agent',\n",
       " 'a by product',\n",
       " 'a c',\n",
       " 'a c c',\n",
       " 'a c drfs',\n",
       " 'a c energy consumption',\n",
       " 'a c globally interpolatory spline',\n",
       " 'a c system',\n",
       " 'a c t',\n",
       " 'a ca approach',\n",
       " 'a ca rule model',\n",
       " 'a cache base distributed terabyte text retrieval system',\n",
       " 'a cache base semi stream join',\n",
       " 'a cad environment',\n",
       " 'a cad system',\n",
       " 'a cad tool',\n",
       " 'a caddbt',\n",
       " 'a cade system',\n",
       " 'a cae system',\n",
       " 'a caf znn model',\n",
       " 'a calculate tonality coefficient',\n",
       " 'a calculation',\n",
       " 'a calculus',\n",
       " 'a calibration method',\n",
       " 'a calibration process',\n",
       " 'a calibration purpose',\n",
       " 'a calibration recording',\n",
       " 'a calibration session',\n",
       " 'a calibration target',\n",
       " 'a callback mechanism',\n",
       " 'a camera',\n",
       " 'a camera configuration',\n",
       " 'a camera drive interactive table',\n",
       " 'a camera model non linear response function',\n",
       " 'a canadians',\n",
       " 'a cancer',\n",
       " 'a candidate parametric object',\n",
       " 'a candidate passage',\n",
       " 'a canonical correlation analysis classifier',\n",
       " 'a cap',\n",
       " 'a capability',\n",
       " 'a capacity',\n",
       " 'a capacity trading portfolio',\n",
       " 'a capsule structure',\n",
       " 'a captcha',\n",
       " 'a car',\n",
       " 'a carbonaro',\n",
       " 'a cardiologist',\n",
       " 'a careful relabeling mechanism',\n",
       " 'a carefully design parameter setting',\n",
       " 'a cart',\n",
       " 'a cart model',\n",
       " 'a cas',\n",
       " 'a cascade',\n",
       " 'a cascade and global hybrid system',\n",
       " 'a cascade depth neural network',\n",
       " 'a cascade formation',\n",
       " 'a cascade graph convolutional recurrent neural network',\n",
       " 'a cascade pixel domain transcoder',\n",
       " 'a cascade technique',\n",
       " 'a cascade use',\n",
       " 'a cascade utilisation',\n",
       " 'a case',\n",
       " 'a case accuracy',\n",
       " 'a case base approach',\n",
       " 'a case base reasoner adaptive',\n",
       " 'a case base reasoning',\n",
       " 'a case base reasoning approach',\n",
       " 'a case base recognition',\n",
       " 'a case base system',\n",
       " 'a case control study',\n",
       " 'a case edge intensity threshold',\n",
       " 'a case feature selection',\n",
       " 'a case study',\n",
       " 'a case study empirical comparison',\n",
       " 'a case study inferring queue sizes',\n",
       " 'a cat',\n",
       " 'a catalog',\n",
       " 'a catalogue',\n",
       " 'a catalyst',\n",
       " 'a categorization',\n",
       " 'a categorization help',\n",
       " 'a categorization phase',\n",
       " 'a categorization system',\n",
       " 'a categorization task',\n",
       " 'a category',\n",
       " 'a catheter',\n",
       " 'a catv and internet combined framework',\n",
       " 'a cauchy distribution',\n",
       " 'a causal analysis',\n",
       " 'a causal blueprint',\n",
       " 'a causal extraction scheme',\n",
       " 'a causal graph',\n",
       " 'a causal knowledge driven negotiation mechanism',\n",
       " 'a causal model',\n",
       " 'a causal modeling framework',\n",
       " 'a causal theory',\n",
       " 'a causative attack',\n",
       " 'a cause',\n",
       " 'a cav',\n",
       " 'a caveat',\n",
       " 'a cbr based game recommender',\n",
       " 'a cbr driven genetic algorithm',\n",
       " 'a cbr system',\n",
       " 'a ccnn',\n",
       " 'a ccuracy rate',\n",
       " 'a ccxg definition and annotation system',\n",
       " 'a cdn',\n",
       " 'a cdns',\n",
       " 'a cdss',\n",
       " 'a ceiling fan',\n",
       " 'a celebration',\n",
       " 'a cell',\n",
       " 'a cell ability',\n",
       " 'a cell protein',\n",
       " 'a cell segmentation',\n",
       " 'a cell type',\n",
       " 'a cellular automata model',\n",
       " 'a cellular automaton model',\n",
       " 'a cellular automaton simulation',\n",
       " 'a cellular neural network',\n",
       " 'a cellular structure',\n",
       " 'a center constrain meb problem',\n",
       " 'a centerline',\n",
       " 'a central agent',\n",
       " 'a central aspect',\n",
       " 'a central interdisciplinary area',\n",
       " 'a central pattern generator',\n",
       " 'a central phenomenon',\n",
       " 'a central processing system',\n",
       " 'a centrality',\n",
       " 'a centralization',\n",
       " 'a centralized abstraction and replicated view architecture',\n",
       " 'a centralized approach',\n",
       " 'a centralized network design problem',\n",
       " 'a centralized state repository approach',\n",
       " 'a century',\n",
       " 'a century ago the term computer aid diagnosis',\n",
       " 'a century research',\n",
       " 'a cerebellar adaptive timing competence',\n",
       " 'a cerebral biopsy',\n",
       " 'a certain amount',\n",
       " 'a certain degree',\n",
       " 'a certain machining operation',\n",
       " 'a certain pattern',\n",
       " 'a certify accuracy',\n",
       " 'a cgm algorithm',\n",
       " 'a chain',\n",
       " 'a chain process',\n",
       " 'a chain structure',\n",
       " 'a chair',\n",
       " 'a challenge',\n",
       " 'a challenge problem',\n",
       " 'a challenge uav dataset',\n",
       " 'a challenging',\n",
       " 'a challenging and complex task',\n",
       " 'a challenging and time consume task',\n",
       " 'a challenging classification task',\n",
       " 'a challenging context',\n",
       " 'a challenging domain',\n",
       " 'a challenging environment',\n",
       " 'a challenging goal',\n",
       " 'a challenging issue',\n",
       " 'a challenging mission',\n",
       " 'a challenging problem',\n",
       " 'a challenging setting',\n",
       " 'a challenging target',\n",
       " 'a challenging task',\n",
       " 'a challenging topic',\n",
       " 'a challenging use case',\n",
       " 'a challenging venture',\n",
       " 'a change',\n",
       " 'a change detection algorithm enabling intelligent background dimension reduction',\n",
       " 'a change detection framework',\n",
       " 'a change management',\n",
       " 'a change validation system',\n",
       " 'a channel',\n",
       " 'a channel d image',\n",
       " 'a channel database',\n",
       " 'a channel density',\n",
       " 'a channel model',\n",
       " 'a chaos map',\n",
       " 'a chaotic attractor',\n",
       " 'a chaotic iterative network',\n",
       " 'a chaotic neural network optimization problem',\n",
       " 'a chaotic set',\n",
       " 'a character',\n",
       " 'a character image classifier',\n",
       " 'a character proposal module',\n",
       " 'a character recognition system',\n",
       " 'a characterisation',\n",
       " 'a characteristic',\n",
       " 'a characteristic appearance',\n",
       " 'a characterization',\n",
       " 'a charger',\n",
       " 'a chassis',\n",
       " 'a chatbot',\n",
       " 'a cheaply craft target',\n",
       " 'a check',\n",
       " 'a checker',\n",
       " 'a checkerboard',\n",
       " 'a chemical',\n",
       " 'a chemical intelligence approach',\n",
       " 'a chessboard',\n",
       " 'a child',\n",
       " 'a chinese automatic interactive feedback system',\n",
       " 'a chinese corpus',\n",
       " 'a chinese dialect',\n",
       " 'a chinese mobile phone input method',\n",
       " 'a chip',\n",
       " 'a chip builder',\n",
       " 'a chip predictor',\n",
       " 'a chl',\n",
       " 'a choice',\n",
       " 'a choose plaintext steganalysis',\n",
       " 'a chording glove',\n",
       " 'a choreographed dance',\n",
       " 'a choreography',\n",
       " 'a chronic disease',\n",
       " 'a chronological history base execution time estimation model',\n",
       " 'a chunk',\n",
       " 'a chunk driven bootstrapping approach',\n",
       " 'a ci',\n",
       " 'a cider',\n",
       " 'a circuit',\n",
       " 'a circuit involving complex walking tasks',\n",
       " 'a circularity',\n",
       " 'a circumstance',\n",
       " 'a circumstance witness',\n",
       " 'a citation metric',\n",
       " 'a city',\n",
       " 'a claim',\n",
       " 'a clarification',\n",
       " 'a class',\n",
       " 'a class balanced and class imbalanced setting',\n",
       " 'a class centroid',\n",
       " 'a class classification',\n",
       " 'a class classification module',\n",
       " 'a class density',\n",
       " 'a class hierarchy',\n",
       " 'a class imbalance',\n",
       " 'a class incremental way',\n",
       " 'a class indifferent method b class conscious method',\n",
       " 'a class library',\n",
       " 'a class problem',\n",
       " 'a class sentiment prediction',\n",
       " 'a class set',\n",
       " 'a class solution',\n",
       " 'a class specific subspace',\n",
       " 'a class specific visualization strategy',\n",
       " 'a classic coherent receiver',\n",
       " 'a classic convolutional neural network',\n",
       " 'a classic naive bayesian classifier',\n",
       " 'a classical architecture',\n",
       " 'a classical benchmark',\n",
       " 'a classical column',\n",
       " 'a classical communication technique',\n",
       " 'a classical fix length fl universal classifier',\n",
       " 'a classical logical thought',\n",
       " 'a classical nonlinear ica task',\n",
       " 'a classical setting',\n",
       " 'a classication',\n",
       " 'a classification',\n",
       " 'a classification algorithm',\n",
       " 'a classification approach',\n",
       " 'a classification architecture',\n",
       " 'a classification class pnn classifier',\n",
       " 'a classification expert system',\n",
       " 'a classification method',\n",
       " 'a classification model',\n",
       " 'a classification module',\n",
       " 'a classification network',\n",
       " 'a classification performance',\n",
       " 'a classification problem',\n",
       " 'a classification procedure',\n",
       " 'a classification process',\n",
       " 'a classification rule',\n",
       " 'a classification system',\n",
       " 'a classification task',\n",
       " 'a classification technique',\n",
       " 'a classification tree',\n",
       " 'a classifier',\n",
       " 'a classifier arrangement',\n",
       " 'a classifier base approach',\n",
       " 'a classifier building',\n",
       " 'a classifier estimate',\n",
       " 'a classifier fusion algorithm',\n",
       " 'a classifier generator',\n",
       " 'a classifier involvement',\n",
       " 'a classifier level',\n",
       " 'a classifier log domain multiplier',\n",
       " 'a classifier structure',\n",
       " 'a classifier system',\n",
       " 'a classify function',\n",
       " 'a clause',\n",
       " 'a clean decomposition',\n",
       " 'a clean speech task',\n",
       " 'a clear characterization',\n",
       " 'a clear cut or nonlinear decision',\n",
       " 'a clear delimitation',\n",
       " 'a clear demarcation',\n",
       " 'a clear distinction',\n",
       " 'a clear semantic channel',\n",
       " 'a clearly justify statistical approach',\n",
       " 'a client',\n",
       " 'a client rank aggregator',\n",
       " 'a client server approach',\n",
       " 'a client server system',\n",
       " 'a client side logger',\n",
       " 'a clinical and control group',\n",
       " 'a clinical and dermoscopic image',\n",
       " 'a clinical causal model',\n",
       " 'a clinical decision support system',\n",
       " 'a clinical label',\n",
       " 'a clinical nlp task',\n",
       " 'a clinical tool',\n",
       " 'a clinician judgment',\n",
       " 'a clip approach',\n",
       " 'a clique',\n",
       " 'a cloned software tool',\n",
       " 'a cloning template',\n",
       " 'a close interaction',\n",
       " 'a close liason',\n",
       " 'a close loop controller',\n",
       " 'a close loop workflow',\n",
       " 'a close mapping',\n",
       " 'a close relationship',\n",
       " 'a closed b open and unbounded convex hypersurface',\n",
       " 'a closed boundary',\n",
       " 'a closed form solution',\n",
       " 'a closed geometry',\n",
       " 'a closed homogenous network',\n",
       " 'a closed loop setup',\n",
       " 'a closed loop system',\n",
       " 'a closed system approach',\n",
       " 'a closed world',\n",
       " 'a closed world scenario',\n",
       " 'a closely couple multi agent environment',\n",
       " 'a closure system',\n",
       " 'a cloud',\n",
       " 'a cloud base ubiquitous mobile healthcare system',\n",
       " 'a cloud ecosystem',\n",
       " 'a clue',\n",
       " 'a cluster',\n",
       " 'a cluster algorithm',\n",
       " 'a cluster analysis',\n",
       " 'a cluster base evolutionary algorithm',\n",
       " 'a cluster base genetic fuzzy mining approach',\n",
       " 'a cluster feature weighting case base reasoning',\n",
       " 'a cluster formulation',\n",
       " 'a cluster network',\n",
       " 'a cluster part',\n",
       " 'a cluster procedure',\n",
       " 'a cluster strategy',\n",
       " 'a cluster structure',\n",
       " 'a cluster validity assessment index',\n",
       " 'a clustered retrieval approach',\n",
       " 'a clustering',\n",
       " 'a clustering base backpacking algorithm',\n",
       " 'a clustering base channel assignment algorithm',\n",
       " 'a clustering base extraction algorithm',\n",
       " 'a clustering base feature weighting approach',\n",
       " 'a clustering mechanism',\n",
       " 'a clustering model',\n",
       " 'a clustering process',\n",
       " 'a clustering technique',\n",
       " 'a clutter',\n",
       " 'a clutter model',\n",
       " 'a cnf formula hierarchy',\n",
       " 'a cnn',\n",
       " 'a cnn accelerator',\n",
       " 'a cnn algorithm',\n",
       " 'a cnn architecture',\n",
       " 'a cnn architecture model',\n",
       " 'a cnn base classifier',\n",
       " 'a cnn base image representation',\n",
       " 'a cnn base md yolo framework',\n",
       " 'a cnn base system',\n",
       " 'a cnn classifier object class prediction',\n",
       " 'a cnn input',\n",
       " 'a cnn model',\n",
       " 'a cnn whole image proposal',\n",
       " 'a co attention base social temporal context extractor',\n",
       " 'a co design technique',\n",
       " 'a co evolution training strategy',\n",
       " 'a co evolutionary epidemiological model',\n",
       " 'a co processing accelerator',\n",
       " 'a co ranking framework',\n",
       " 'a co training approach',\n",
       " 'a coached collaborative learning environment',\n",
       " 'a coalition',\n",
       " 'a coalition evaluation algorithm',\n",
       " 'a coarse and fine bayesian belief propagation',\n",
       " 'a coarse grain approach',\n",
       " 'a coarse grain classifier',\n",
       " 'a coarse grain mapping method',\n",
       " 'a coarse to fine quantization procedure',\n",
       " 'a cochleagram',\n",
       " 'a cockpit',\n",
       " 'a code',\n",
       " 'a code automate',\n",
       " 'a code generation approach',\n",
       " 'a code scheme',\n",
       " 'a code service',\n",
       " 'a code smell',\n",
       " 'a code unit cu decision method',\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbadałam częstości memów. \n",
    "Wykasowałam memy\n",
    "\n",
    "OneHotEncoding memów w paperach cytowanych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a mask to apply to list of memes(nonexistent as of now)\n",
    "memes_mask = np.nonzero(memes_enc.sum(axis=0)-1)[1]\n",
    "memes_enc_cleaned = memes_enc[:,memes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         3036974\n",
       "2          398942\n",
       "3          137087\n",
       "4           70562\n",
       "5           42965\n",
       "           ...   \n",
       "1836            1\n",
       "1839            1\n",
       "1840            1\n",
       "1841            1\n",
       "251321          1\n",
       "Length: 2099, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency of memes\n",
    "pd.DataFrame(np.sort(memes_enc.sum(axis=0))).T.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['paper_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['memes_in_cited'] = df['inbound_citations_clear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "415360it [01:30, 6127.23it/s]"
     ]
    }
   ],
   "source": [
    "#I want new column of unique noun chunks in all cited papers\n",
    "for i,paper in tqdm(df.iterrows()):\n",
    "    if paper['outbound_citations_clear'].size>0:\n",
    "        #only memes in cited papers:\n",
    "        c = df.iloc[paper['outbound_citations_clear']]['noun_chunks_cleaned']\n",
    "        \n",
    "        paper['memes_in_cited'] = set(c.explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_lens</th>\n",
       "      <th>nouns</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>noun_chunks_cleaned</th>\n",
       "      <th>inbound_citations</th>\n",
       "      <th>outbound_citations</th>\n",
       "      <th>inbound_citations_clear</th>\n",
       "      <th>outbound_citations_clear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199668001</th>\n",
       "      <td>199668001</td>\n",
       "      <td>196</td>\n",
       "      <td>[Road, construction, projects, territory, over...</td>\n",
       "      <td>[Road construction projects, the territory, th...</td>\n",
       "      <td>[road, construction, project, on, the, territo...</td>\n",
       "      <td>[road construction project, territory, republi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[106476531, 67083539, 36731616, 34616216, 1096...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879234</th>\n",
       "      <td>2879234</td>\n",
       "      <td>235</td>\n",
       "      <td>[nets, CNNs, performance, history, approaches,...</td>\n",
       "      <td>[Convolutional neural nets, CNNs, remarkable p...</td>\n",
       "      <td>[convolutional, neural, net, (, cnn, ), have, ...</td>\n",
       "      <td>[convolutional neural net, cnn, remarkable per...</td>\n",
       "      <td>[11015941, 52160763, 199488257, 23874112, 4241...</td>\n",
       "      <td>[206592419, 215721, 10111903, 1003907, 3198903...</td>\n",
       "      <td>[340420, 471907, 250792]</td>\n",
       "      <td>[215721, 127386, 392527]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17786914</th>\n",
       "      <td>17786914</td>\n",
       "      <td>120</td>\n",
       "      <td>[results, benchmarks, modeling, speech, recogn...</td>\n",
       "      <td>[excellent results, benchmarks, acoustic model...</td>\n",
       "      <td>[recently, ,, deep, neural, networks(DNNs, ), ...</td>\n",
       "      <td>[excellent result, benchmark, acoustic modelin...</td>\n",
       "      <td>[198931159]</td>\n",
       "      <td>[9530137, 398770, 207168299, 14832074, 1799800...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[398770, 299222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432300</th>\n",
       "      <td>17432300</td>\n",
       "      <td>235</td>\n",
       "      <td>[characters, structure, character, arrangement...</td>\n",
       "      <td>[East-Asian characters, a rich hierarchical st...</td>\n",
       "      <td>[east, -, asian, character, possess, a, rich, ...</td>\n",
       "      <td>[east asian character, rich hierarchical struc...</td>\n",
       "      <td>[15983137, 7625356, 15404413, 199472639, 47640...</td>\n",
       "      <td>[371064, 3246932, 8991475, 36725681, 32031694,...</td>\n",
       "      <td>[467570]</td>\n",
       "      <td>[371064]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204957502</th>\n",
       "      <td>204957502</td>\n",
       "      <td>33</td>\n",
       "      <td>[Internet, articles, multimedia, content, life...</td>\n",
       "      <td>[the Internet, countless articles, multimedia ...</td>\n",
       "      <td>[with, the, internet, become, widespread, ,, c...</td>\n",
       "      <td>[internet, countless article, multimedia conte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127628365</th>\n",
       "      <td>127628365</td>\n",
       "      <td>179</td>\n",
       "      <td>[models, strength, phenomena, reality, self, o...</td>\n",
       "      <td>[Abstract Probabilistic models, their strength...</td>\n",
       "      <td>[Abstract, Probabilistic, model, have, prove, ...</td>\n",
       "      <td>[abstract probabilistic model, strength, many ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11619477</th>\n",
       "      <td>11619477</td>\n",
       "      <td>189</td>\n",
       "      <td>[AD, courses, patients, period, time, points, ...</td>\n",
       "      <td>[Alzheimer's Disease (AD, different courses, s...</td>\n",
       "      <td>[Alzheimer, 's, Disease, (, ad, ), can, take, ...</td>\n",
       "      <td>[alzheimer disease ad, different course, patie...</td>\n",
       "      <td>[204230004]</td>\n",
       "      <td>[34935848, 27355075, 9895278, 8461070, 3276119...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807289</th>\n",
       "      <td>5807289</td>\n",
       "      <td>217</td>\n",
       "      <td>[Concurrency, bugs, software, testing, nature,...</td>\n",
       "      <td>[Concurrency bugs, software testing, their non...</td>\n",
       "      <td>[concurrency, bug, be, notoriously, difficult,...</td>\n",
       "      <td>[concurrency bug, software testing, non determ...</td>\n",
       "      <td>[15460152, 69949082, 5076939, 18091491, 678683...</td>\n",
       "      <td>[9005386, 17620776, 3439914, 978769, 2941443, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894398</th>\n",
       "      <td>15894398</td>\n",
       "      <td>87</td>\n",
       "      <td>[model, snake, reconstruction, volumetric, ima...</td>\n",
       "      <td>[a new statistic deformable model, discriminan...</td>\n",
       "      <td>[we, propose, a, new, statistic, deformable, m...</td>\n",
       "      <td>[new statistic deformable model, discriminant ...</td>\n",
       "      <td>[2469979, 14334601, 3080024, 18147424]</td>\n",
       "      <td>[14001890, 30582, 63717849, 29187618, 12849354...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[30582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15895702</th>\n",
       "      <td>15895702</td>\n",
       "      <td>243</td>\n",
       "      <td>[BackgroundThe, conservation, sequences, genom...</td>\n",
       "      <td>[BackgroundThe conservation, sequences, relate...</td>\n",
       "      <td>[backgroundthe, conservation, of, sequence, be...</td>\n",
       "      <td>[backgroundthe conservation, sequence, relate ...</td>\n",
       "      <td>[9533661, 196612986, 10506251, 54820054, 13868...</td>\n",
       "      <td>[3243833, 18690884, 7777003, 1677744, 3189433,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[251692]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            paper_id  doc_lens  \\\n",
       "paper_id                         \n",
       "199668001  199668001       196   \n",
       "2879234      2879234       235   \n",
       "17786914    17786914       120   \n",
       "17432300    17432300       235   \n",
       "204957502  204957502        33   \n",
       "...              ...       ...   \n",
       "127628365  127628365       179   \n",
       "11619477    11619477       189   \n",
       "5807289      5807289       217   \n",
       "15894398    15894398        87   \n",
       "15895702    15895702       243   \n",
       "\n",
       "                                                       nouns  \\\n",
       "paper_id                                                       \n",
       "199668001  [Road, construction, projects, territory, over...   \n",
       "2879234    [nets, CNNs, performance, history, approaches,...   \n",
       "17786914   [results, benchmarks, modeling, speech, recogn...   \n",
       "17432300   [characters, structure, character, arrangement...   \n",
       "204957502  [Internet, articles, multimedia, content, life...   \n",
       "...                                                      ...   \n",
       "127628365  [models, strength, phenomena, reality, self, o...   \n",
       "11619477   [AD, courses, patients, period, time, points, ...   \n",
       "5807289    [Concurrency, bugs, software, testing, nature,...   \n",
       "15894398   [model, snake, reconstruction, volumetric, ima...   \n",
       "15895702   [BackgroundThe, conservation, sequences, genom...   \n",
       "\n",
       "                                                 noun_chunks  \\\n",
       "paper_id                                                       \n",
       "199668001  [Road construction projects, the territory, th...   \n",
       "2879234    [Convolutional neural nets, CNNs, remarkable p...   \n",
       "17786914   [excellent results, benchmarks, acoustic model...   \n",
       "17432300   [East-Asian characters, a rich hierarchical st...   \n",
       "204957502  [the Internet, countless articles, multimedia ...   \n",
       "...                                                      ...   \n",
       "127628365  [Abstract Probabilistic models, their strength...   \n",
       "11619477   [Alzheimer's Disease (AD, different courses, s...   \n",
       "5807289    [Concurrency bugs, software testing, their non...   \n",
       "15894398   [a new statistic deformable model, discriminan...   \n",
       "15895702   [BackgroundThe conservation, sequences, relate...   \n",
       "\n",
       "                                                      lemmas  \\\n",
       "paper_id                                                       \n",
       "199668001  [road, construction, project, on, the, territo...   \n",
       "2879234    [convolutional, neural, net, (, cnn, ), have, ...   \n",
       "17786914   [recently, ,, deep, neural, networks(DNNs, ), ...   \n",
       "17432300   [east, -, asian, character, possess, a, rich, ...   \n",
       "204957502  [with, the, internet, become, widespread, ,, c...   \n",
       "...                                                      ...   \n",
       "127628365  [Abstract, Probabilistic, model, have, prove, ...   \n",
       "11619477   [Alzheimer, 's, Disease, (, ad, ), can, take, ...   \n",
       "5807289    [concurrency, bug, be, notoriously, difficult,...   \n",
       "15894398   [we, propose, a, new, statistic, deformable, m...   \n",
       "15895702   [backgroundthe, conservation, of, sequence, be...   \n",
       "\n",
       "                                         noun_chunks_cleaned  \\\n",
       "paper_id                                                       \n",
       "199668001  [road construction project, territory, republi...   \n",
       "2879234    [convolutional neural net, cnn, remarkable per...   \n",
       "17786914   [excellent result, benchmark, acoustic modelin...   \n",
       "17432300   [east asian character, rich hierarchical struc...   \n",
       "204957502  [internet, countless article, multimedia conte...   \n",
       "...                                                      ...   \n",
       "127628365  [abstract probabilistic model, strength, many ...   \n",
       "11619477   [alzheimer disease ad, different course, patie...   \n",
       "5807289    [concurrency bug, software testing, non determ...   \n",
       "15894398   [new statistic deformable model, discriminant ...   \n",
       "15895702   [backgroundthe conservation, sequence, relate ...   \n",
       "\n",
       "                                           inbound_citations  \\\n",
       "paper_id                                                       \n",
       "199668001                                                 []   \n",
       "2879234    [11015941, 52160763, 199488257, 23874112, 4241...   \n",
       "17786914                                         [198931159]   \n",
       "17432300   [15983137, 7625356, 15404413, 199472639, 47640...   \n",
       "204957502                                                 []   \n",
       "...                                                      ...   \n",
       "127628365                                                 []   \n",
       "11619477                                         [204230004]   \n",
       "5807289    [15460152, 69949082, 5076939, 18091491, 678683...   \n",
       "15894398              [2469979, 14334601, 3080024, 18147424]   \n",
       "15895702   [9533661, 196612986, 10506251, 54820054, 13868...   \n",
       "\n",
       "                                          outbound_citations  \\\n",
       "paper_id                                                       \n",
       "199668001  [106476531, 67083539, 36731616, 34616216, 1096...   \n",
       "2879234    [206592419, 215721, 10111903, 1003907, 3198903...   \n",
       "17786914   [9530137, 398770, 207168299, 14832074, 1799800...   \n",
       "17432300   [371064, 3246932, 8991475, 36725681, 32031694,...   \n",
       "204957502                                                 []   \n",
       "...                                                      ...   \n",
       "127628365                                                 []   \n",
       "11619477   [34935848, 27355075, 9895278, 8461070, 3276119...   \n",
       "5807289    [9005386, 17620776, 3439914, 978769, 2941443, ...   \n",
       "15894398   [14001890, 30582, 63717849, 29187618, 12849354...   \n",
       "15895702   [3243833, 18690884, 7777003, 1677744, 3189433,...   \n",
       "\n",
       "            inbound_citations_clear  outbound_citations_clear  \n",
       "paper_id                                                       \n",
       "199668001                        []                        []  \n",
       "2879234    [340420, 471907, 250792]  [215721, 127386, 392527]  \n",
       "17786914                         []          [398770, 299222]  \n",
       "17432300                   [467570]                  [371064]  \n",
       "204957502                        []                        []  \n",
       "...                             ...                       ...  \n",
       "127628365                        []                        []  \n",
       "11619477                         []                        []  \n",
       "5807289                          []                        []  \n",
       "15894398                         []                   [30582]  \n",
       "15895702                         []                  [251692]  \n",
       "\n",
       "[505000 rows x 10 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'memes in cited'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'memes in cited'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\notebooks\\pk\\meme_score.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/notebooks/pk/meme_score.ipynb#ch0000042?line=0'>1</a>\u001b[0m cited_memes_enc \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39;49m\u001b[39mmemes in cited\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'memes in cited'"
     ]
    }
   ],
   "source": [
    "cited_memes_enc = enc.fit_transform(df['memes_in_cited'])\n",
    "cited_memes_enc_cleaned = cited_memes_enc[:,memes_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3883767 [00:11<2498:41:11,  2.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\data\\s2orc\\meme_score.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=10'>11</a>\u001b[0m \u001b[39m#does it cite meme carrers?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=11'>12</a>\u001b[0m c_spark \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39moutbound_citations_clear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39many\u001b[39m(df[c][\u001b[39m'\u001b[39m\u001b[39mpaper_id\u001b[39m\u001b[39m'\u001b[39m]),regex\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=12'>13</a>\u001b[0m c_stick \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mdf[\u001b[39m'\u001b[39;49m\u001b[39moutbound_citations_clear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(\u001b[39many\u001b[39;49m(df[c][\u001b[39m'\u001b[39;49m\u001b[39mpaper_id\u001b[39;49m\u001b[39m'\u001b[39;49m]),regex\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=15'>16</a>\u001b[0m p_spark1\u001b[39m.\u001b[39mappend((c_spark\u001b[39m&\u001b[39mc)\u001b[39m.\u001b[39msum())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=16'>17</a>\u001b[0m p_spark2\u001b[39m.\u001b[39mappend(c_spark\u001b[39m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:125\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 125\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:1222\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[0;32m   1215\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1218\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1219\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1220\u001b[0m     )\n\u001b[1;32m-> 1222\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_contains(pat, case, flags, na, regex)\n\u001b[0;32m   1223\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result, fill_value\u001b[39m=\u001b[39mna, returns_string\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:131\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m    129\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n\u001b[0;32m    130\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: upper_pat \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mupper()\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_map(f, na, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:71\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[1;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[0;32m     69\u001b[0m map_convert \u001b[39m=\u001b[39m convert \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(mask)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer_mask(arr, f, mask\u001b[39m.\u001b[39;49mview(np\u001b[39m.\u001b[39;49muint8), map_convert)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     73\u001b[0m     \u001b[39m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     p_err \u001b[39m=\u001b[39m (\n\u001b[0;32m     76\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m((takes)|(missing)) (?(2)from \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ to )?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?(3)required )positional arguments?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2822\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:127\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m case:\n\u001b[1;32m--> 127\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: pat \u001b[39min\u001b[39;00m x\n\u001b[0;32m    128\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/ppaul/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "p_spark1 = []\n",
    "p_spark2 = []\n",
    "p_stick1 = []\n",
    "p_stick2 = []\n",
    "for key in tqdm(memes):\n",
    "    #does it have meme? in OneHot: memes_enc\n",
    "    c = df['noun_chunks_cleaned'].str.contains(key,regex=False)\n",
    "    #does it cite meme carrers? in OneHot: all memes in citated\n",
    "    c_spark = df['outbound_citations_clear'].str.contains(any(df[c]['paper_id']),regex=False)\n",
    "    c_stick = ~c_spark\n",
    "    \n",
    "\n",
    "    p_spark1.append((c_spark&c).sum())\n",
    "    p_spark2.append(c_spark.sum())\n",
    "    p_stick1.append((c_stick&c).sum())\n",
    "    p_stick2.append(c_stick.sum())\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d54a113c73c7cd2d522d52b538c9e8d75641ec0b9017fac754b3c03c32c6a70"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
