{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "btdf = pd.read_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/processed_big.parquet')\n",
    "cit_df = pd.read_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset.parquet')\n",
    "cdf = cit_df[['paper_id','inbound_citations','outbound_citations']]\n",
    "df = pd.merge(btdf,cdf,on='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset_with_affiliations_extended_oa.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset_with_affiliations_extended_oa.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>out_citations_count</th>\n",
       "      <th>in_citations_count</th>\n",
       "      <th>outbound_citations</th>\n",
       "      <th>inbound_citations</th>\n",
       "      <th>open_alex</th>\n",
       "      <th>institutions</th>\n",
       "      <th>countries</th>\n",
       "      <th>types</th>\n",
       "      <th>unique_institutions</th>\n",
       "      <th>BT_percent</th>\n",
       "      <th>authors_number</th>\n",
       "      <th>double_affiliation</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199668001</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.1007/s00521-019-04443-y</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>[106476531, 67083539, 36731616, 34616216, 1096...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'author': {'display_name': 'Ksenija Tijanić'...</td>\n",
       "      <td>[[University of Rijeka], [University of Rijeka...</td>\n",
       "      <td>[[HR], [HR], [HR]]</td>\n",
       "      <td>[[education], [education], [education]]</td>\n",
       "      <td>[University of Osijek, University of Rijeka]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8392651</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.1016/j.future.2012.05.026</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "      <td>[214797870, 58458964, 17936051, 12869238, 5121...</td>\n",
       "      <td>[49339994, 9108558, 55589961, 14721032, 532882...</td>\n",
       "      <td>[{'author': {'display_name': 'Kathleen Ericson...</td>\n",
       "      <td>[[Colorado State University], [Colorado State ...</td>\n",
       "      <td>[[US], [US]]</td>\n",
       "      <td>[[education], [education]]</td>\n",
       "      <td>[Colorado State University]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>62653139</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.1016/j.aci.2014.07.002</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>[37784376, 16497245, 27557292, 6492502, 360497...</td>\n",
       "      <td>[155109586, 56086061, 22896920, 52883785, 7804...</td>\n",
       "      <td>[{'author': {'display_name': 'Neda Abdelhamid'...</td>\n",
       "      <td>[[De Montfort University]]</td>\n",
       "      <td>[[GB]]</td>\n",
       "      <td>[[education]]</td>\n",
       "      <td>[De Montfort University]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>62656209</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.4995/var.2012.4372</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>[190739834, 8675354, 60452706, 109165564, 1384...</td>\n",
       "      <td>[42927847, 64895295]</td>\n",
       "      <td>[{'author': {'display_name': 'Vera Moitinho', ...</td>\n",
       "      <td>[[Autonomous University of Barcelona], [Autono...</td>\n",
       "      <td>[[ES], [ES]]</td>\n",
       "      <td>[[education], [education]]</td>\n",
       "      <td>[Autonomous University of Barcelona]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>88483477</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.1117/12.2511890</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[42407660, 79871509, 38824009, 22018015, 20776...</td>\n",
       "      <td>[210123596]</td>\n",
       "      <td>[{'author': {'display_name': 'Xiangyuan Ma', '...</td>\n",
       "      <td>[[Sun Yat-sen University], [University of Mich...</td>\n",
       "      <td>[[CN], [US], [US], [US], [US], [US], [US], [US...</td>\n",
       "      <td>[[education], [education], [education], [educa...</td>\n",
       "      <td>[United States Food and Drug Administration, U...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557669</th>\n",
       "      <td>16710555</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>10.1007/978-3-642-13022-9_59</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[57256200, 46011309, 5907868, 1049011, 1170894...</td>\n",
       "      <td>[65535570, 14191836]</td>\n",
       "      <td>[{'author': {'display_name': 'Amber McKenzie',...</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[[], [], [], []]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557671</th>\n",
       "      <td>16715952</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>10.1007/978-3-642-40991-2_26</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>[901118, 14091499, 14672953, 183466, 10366378,...</td>\n",
       "      <td>[3999959, 10791446, 14102602, 10317326, 156242...</td>\n",
       "      <td>[{'author': {'display_name': 'Kai-Wei Chang', ...</td>\n",
       "      <td>[[University of Illinois Urbana-Champaign], [U...</td>\n",
       "      <td>[[US], [US], [US]]</td>\n",
       "      <td>[[education], [education], [education]]</td>\n",
       "      <td>[University of Illinois Urbana-Champaign]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557675</th>\n",
       "      <td>64996845</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.1007/978-3-319-77276-9_30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[181671411]</td>\n",
       "      <td>[{'author': {'display_name': 'S. Johny Samuael...</td>\n",
       "      <td>[[Texas A&amp;M University – Corpus Christi], [Uni...</td>\n",
       "      <td>[[US], [None], [None]]</td>\n",
       "      <td>[[education], [None], [None]]</td>\n",
       "      <td>[Holy Cross Coll, University VOC College of En...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557677</th>\n",
       "      <td>211545971</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>10.1155/2020/1375426</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>[71150591, 51868425, 2528603, 96431222, 102440...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'author': {'display_name': 'Cheng Xu', 'id':...</td>\n",
       "      <td>[[Beijing Union University], [Beijing Union Un...</td>\n",
       "      <td>[[CN], [CN], [CN], [CN]]</td>\n",
       "      <td>[[education], [education], [education], [gover...</td>\n",
       "      <td>[State Administration of Work Safety, Beijing ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557680</th>\n",
       "      <td>25305708</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>10.1007/11427469_30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[110050694]</td>\n",
       "      <td>[{'author': {'display_name': 'Y.D. Song', 'id'...</td>\n",
       "      <td>[[North Carolina Agricultural and Technical St...</td>\n",
       "      <td>[[US], [US], [US], [US], [US]]</td>\n",
       "      <td>[[education], [education], [education], [educa...</td>\n",
       "      <td>[University of Maryland, College Park, North C...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166455 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_id    year                           doi  out_citations_count  \\\n",
       "0       199668001  2019.0    10.1007/s00521-019-04443-y                   27   \n",
       "8         8392651  2013.0  10.1016/j.future.2012.05.026                   26   \n",
       "11       62653139  2015.0     10.1016/j.aci.2014.07.002                   19   \n",
       "12       62656209  2012.0         10.4995/var.2012.4372                    5   \n",
       "17       88483477  2019.0            10.1117/12.2511890                    7   \n",
       "...           ...     ...                           ...                  ...   \n",
       "557669   16710555  2010.0  10.1007/978-3-642-13022-9_59                   10   \n",
       "557671   16715952  2013.0  10.1007/978-3-642-40991-2_26                   19   \n",
       "557675   64996845  2018.0  10.1007/978-3-319-77276-9_30                    0   \n",
       "557677  211545971  2020.0          10.1155/2020/1375426                   43   \n",
       "557680   25305708  2005.0           10.1007/11427469_30                    0   \n",
       "\n",
       "        in_citations_count                                 outbound_citations  \\\n",
       "0                        0  [106476531, 67083539, 36731616, 34616216, 1096...   \n",
       "8                       21  [214797870, 58458964, 17936051, 12869238, 5121...   \n",
       "11                      16  [37784376, 16497245, 27557292, 6492502, 360497...   \n",
       "12                       2  [190739834, 8675354, 60452706, 109165564, 1384...   \n",
       "17                       1  [42407660, 79871509, 38824009, 22018015, 20776...   \n",
       "...                    ...                                                ...   \n",
       "557669                   2  [57256200, 46011309, 5907868, 1049011, 1170894...   \n",
       "557671                  12  [901118, 14091499, 14672953, 183466, 10366378,...   \n",
       "557675                   1                                                 []   \n",
       "557677                   0  [71150591, 51868425, 2528603, 96431222, 102440...   \n",
       "557680                   1                                                 []   \n",
       "\n",
       "                                        inbound_citations  \\\n",
       "0                                                      []   \n",
       "8       [49339994, 9108558, 55589961, 14721032, 532882...   \n",
       "11      [155109586, 56086061, 22896920, 52883785, 7804...   \n",
       "12                                   [42927847, 64895295]   \n",
       "17                                            [210123596]   \n",
       "...                                                   ...   \n",
       "557669                               [65535570, 14191836]   \n",
       "557671  [3999959, 10791446, 14102602, 10317326, 156242...   \n",
       "557675                                        [181671411]   \n",
       "557677                                                 []   \n",
       "557680                                        [110050694]   \n",
       "\n",
       "                                                open_alex  \\\n",
       "0       [{'author': {'display_name': 'Ksenija Tijanić'...   \n",
       "8       [{'author': {'display_name': 'Kathleen Ericson...   \n",
       "11      [{'author': {'display_name': 'Neda Abdelhamid'...   \n",
       "12      [{'author': {'display_name': 'Vera Moitinho', ...   \n",
       "17      [{'author': {'display_name': 'Xiangyuan Ma', '...   \n",
       "...                                                   ...   \n",
       "557669  [{'author': {'display_name': 'Amber McKenzie',...   \n",
       "557671  [{'author': {'display_name': 'Kai-Wei Chang', ...   \n",
       "557675  [{'author': {'display_name': 'S. Johny Samuael...   \n",
       "557677  [{'author': {'display_name': 'Cheng Xu', 'id':...   \n",
       "557680  [{'author': {'display_name': 'Y.D. Song', 'id'...   \n",
       "\n",
       "                                             institutions  \\\n",
       "0       [[University of Rijeka], [University of Rijeka...   \n",
       "8       [[Colorado State University], [Colorado State ...   \n",
       "11                             [[De Montfort University]]   \n",
       "12      [[Autonomous University of Barcelona], [Autono...   \n",
       "17      [[Sun Yat-sen University], [University of Mich...   \n",
       "...                                                   ...   \n",
       "557669                                   [[], [], [], []]   \n",
       "557671  [[University of Illinois Urbana-Champaign], [U...   \n",
       "557675  [[Texas A&M University – Corpus Christi], [Uni...   \n",
       "557677  [[Beijing Union University], [Beijing Union Un...   \n",
       "557680  [[North Carolina Agricultural and Technical St...   \n",
       "\n",
       "                                                countries  \\\n",
       "0                                      [[HR], [HR], [HR]]   \n",
       "8                                            [[US], [US]]   \n",
       "11                                                 [[GB]]   \n",
       "12                                           [[ES], [ES]]   \n",
       "17      [[CN], [US], [US], [US], [US], [US], [US], [US...   \n",
       "...                                                   ...   \n",
       "557669                                   [[], [], [], []]   \n",
       "557671                                 [[US], [US], [US]]   \n",
       "557675                             [[US], [None], [None]]   \n",
       "557677                           [[CN], [CN], [CN], [CN]]   \n",
       "557680                     [[US], [US], [US], [US], [US]]   \n",
       "\n",
       "                                                    types  \\\n",
       "0                 [[education], [education], [education]]   \n",
       "8                              [[education], [education]]   \n",
       "11                                          [[education]]   \n",
       "12                             [[education], [education]]   \n",
       "17      [[education], [education], [education], [educa...   \n",
       "...                                                   ...   \n",
       "557669                                   [[], [], [], []]   \n",
       "557671            [[education], [education], [education]]   \n",
       "557675                      [[education], [None], [None]]   \n",
       "557677  [[education], [education], [education], [gover...   \n",
       "557680  [[education], [education], [education], [educa...   \n",
       "\n",
       "                                      unique_institutions  BT_percent  \\\n",
       "0            [University of Osijek, University of Rijeka]         0.0   \n",
       "8                             [Colorado State University]         0.0   \n",
       "11                               [De Montfort University]         0.0   \n",
       "12                   [Autonomous University of Barcelona]         0.0   \n",
       "17      [United States Food and Drug Administration, U...         0.0   \n",
       "...                                                   ...         ...   \n",
       "557669                                                 []         0.0   \n",
       "557671          [University of Illinois Urbana-Champaign]         0.0   \n",
       "557675  [Holy Cross Coll, University VOC College of En...         0.0   \n",
       "557677  [State Administration of Work Safety, Beijing ...         0.0   \n",
       "557680  [University of Maryland, College Park, North C...         0.0   \n",
       "\n",
       "        authors_number  double_affiliation  company  \n",
       "0                    3                 0.0      0.0  \n",
       "8                    2                 0.0      0.0  \n",
       "11                   1                 0.0      0.0  \n",
       "12                   2                 0.0      0.0  \n",
       "17                  10                 0.0      0.0  \n",
       "...                ...                 ...      ...  \n",
       "557669               4                 0.0      0.0  \n",
       "557671               3                 0.0      0.0  \n",
       "557675               3                 0.0      0.0  \n",
       "557677               4                 0.0      0.0  \n",
       "557680               5                 0.0      0.0  \n",
       "\n",
       "[166455 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'author': {'display_name': 'Ksenija Tijanić', 'id': 'https://openalex.org/A2762169277', 'orcid': 'https://orcid.org/0000-0002-3633-2256'}, 'author_position': 'first', 'institutions': array([{'country_code': 'HR', 'display_name': 'University of Rijeka', 'id': 'https://openalex.org/I154347574', 'ror': 'https://ror.org/05r8dqr10', 'type': 'education'}],\n",
       "             dtype=object), 'raw_affiliation_string': 'Faculty of Civil Engineering , University of Rijeka , Rijeka , Croatia .'}                                                                                                                                                                                                                                       ,\n",
       "       {'author': {'display_name': 'Diana Car-Pušić', 'id': 'https://openalex.org/A1491253522', 'orcid': 'https://orcid.org/0000-0003-2555-335X'}, 'author_position': 'middle', 'institutions': array([{'country_code': 'HR', 'display_name': 'University of Rijeka', 'id': 'https://openalex.org/I154347574', 'ror': 'https://ror.org/05r8dqr10', 'type': 'education'}],\n",
       "             dtype=object), 'raw_affiliation_string': 'Faculty of Civil Engineering , University of Rijeka , Rijeka , Croatia .'}                                                                                                                                                                                                                                        ,\n",
       "       {'author': {'display_name': 'Marija Šperac', 'id': 'https://openalex.org/A2646844452', 'orcid': None}, 'author_position': 'last', 'institutions': array([{'country_code': 'HR', 'display_name': 'University of Osijek', 'id': 'https://openalex.org/I51314090', 'ror': 'https://ror.org/05sw4wc49', 'type': 'education'}],\n",
       "             dtype=object), 'raw_affiliation_string': 'Faculty of Civil Engineering Osijek , Josip Juraj Strossmayer University of Osijek , Osijek , Croatia'}                                                                                                                                                                   ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['open_alex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutions = []\n",
    "countries = []\n",
    "types = []\n",
    "for index, row in df.iterrows():\n",
    "    institutions_per_paper = []\n",
    "    countries_per_paper = []\n",
    "    types_per_paper = []\n",
    "    if row['open_alex'] is not None:\n",
    "        for author in row['open_alex']:\n",
    "            try:\n",
    "                institution_per_author = []\n",
    "                countries_per_author = []\n",
    "                types_per_author = []\n",
    "                for institution in author['institutions']:\n",
    "                    institution_per_author.append(institution['display_name'])\n",
    "                    countries_per_author.append(institution['country_code'])\n",
    "                    types_per_author.append(institution['type'])\n",
    "                institutions_per_paper.append(institution_per_author)\n",
    "                countries_per_paper.append(countries_per_author)\n",
    "                types_per_paper.append(types_per_author)\n",
    "            except KeyError:\n",
    "                institutions_per_paper.append(\"no data\")\n",
    "                countries_per_paper.append(\"no data\")\n",
    "                types_per_paper.append(\"no data\")\n",
    "    institutions.append(institutions_per_paper)\n",
    "    countries.append(countries_per_paper)\n",
    "    types.append(types_per_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['institutions'] = institutions\n",
    "df['countries'] = countries\n",
    "df['types'] = types\n",
    "\n",
    "\n",
    "unique_institutions_per_paper = []\n",
    "for paper in institutions:\n",
    "    unique_institutions = set()\n",
    "    if paper != []:\n",
    "        for author in paper:\n",
    "            for affiliation in author:\n",
    "                if affiliation not in unique_institutions:\n",
    "                    unique_institutions.add(affiliation)\n",
    "    unique_institutions_per_paper.append(list(unique_institutions))\n",
    "\n",
    "df['unique_institutions'] = unique_institutions_per_paper\n",
    "\n",
    "unique_institutions_joint = []\n",
    "for paper in unique_institutions_per_paper:\n",
    "    if paper == []:\n",
    "        unique_institutions_joint.append(\"no data\")\n",
    "    else:\n",
    "        for affiliation in paper:\n",
    "            unique_institutions_joint.append(affiliation)\n",
    "\n",
    "\n",
    "unique_types_per_paper = []\n",
    "for paper in types:\n",
    "    unique_types = set()\n",
    "    if paper != []:\n",
    "        for author in paper:\n",
    "            for type in author:\n",
    "                if type not in unique_types:\n",
    "                    if type is not None:\n",
    "                        unique_types.add(type)\n",
    "        unique_types = list(unique_types)\n",
    "        unique_types_str = ' '.join(unique_types)\n",
    "        if unique_types_str == '':\n",
    "            unique_types_str = 'no data'\n",
    "    else:\n",
    "        unique_types_str = 'no data'\n",
    "    unique_types_per_paper.append(unique_types_str)\n",
    "\n",
    "\n",
    "unique_countries_per_paper = []\n",
    "for paper in countries:\n",
    "    unique_countries = set()\n",
    "    if paper != []:\n",
    "        for author in paper:\n",
    "            for country in author:\n",
    "                if country not in unique_countries:\n",
    "                    unique_countries.add(country)\n",
    "    unique_countries_per_paper.append(list(unique_countries))\n",
    "\n",
    "unique_countries_joint = []\n",
    "for paper in unique_countries_per_paper:\n",
    "    if paper == []:\n",
    "        unique_countries_joint.append(\"no data\")\n",
    "    else:\n",
    "        for country in paper:\n",
    "            unique_countries_joint.append(country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_af = []\n",
    "company = []\n",
    "#percent of authors with double aff\n",
    "#company column\n",
    "for _,paper in df.iterrows():\n",
    "    is_c = 0\n",
    "    is_2 = 0\n",
    "    for institution_types in paper['types']:\n",
    "        for t in institution_types:\n",
    "            if t =='company':\n",
    "                is_c+=1\n",
    "                break\n",
    "        if is_c>0:\n",
    "            for t in institution_types:\n",
    "                if t !='company':\n",
    "                    is_2+=1\n",
    "                    break\n",
    "        \n",
    "    company.append(is_c/(len(paper['types'])+0.0001))\n",
    "    double_af.append(is_2/(len(paper['types'])+0.0001))\n",
    "df['double_affiliation'] = double_af\n",
    "df['company'] = company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>out_citations_count</th>\n",
       "      <th>in_citations_count</th>\n",
       "      <th>outbound_citations</th>\n",
       "      <th>inbound_citations</th>\n",
       "      <th>open_alex</th>\n",
       "      <th>institutions</th>\n",
       "      <th>countries</th>\n",
       "      <th>types</th>\n",
       "      <th>unique_institutions</th>\n",
       "      <th>BT_percent</th>\n",
       "      <th>authors_number</th>\n",
       "      <th>double_affiliation</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>59159027</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.1007/978-3-030-11009-3_14</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>[14042655, 52284663, 502946, 2255738, 14547347...</td>\n",
       "      <td>[201070554]</td>\n",
       "      <td>[{'author': {'display_name': 'Fabian Brickwedd...</td>\n",
       "      <td>[[Goethe University Frankfurt, Robert Bosch], ...</td>\n",
       "      <td>[[DE, DE], [DE], [DE]]</td>\n",
       "      <td>[[education, company], [company], [education]]</td>\n",
       "      <td>[Robert Bosch, Goethe University Frankfurt]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>4633214</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.1007/978-3-030-01252-6_4</td>\n",
       "      <td>28</td>\n",
       "      <td>157</td>\n",
       "      <td>[11096669, 15425191, 15195762, 2554264, 632505...</td>\n",
       "      <td>[209414673, 209376368, 199442423, 78088951, 21...</td>\n",
       "      <td>[{'author': {'display_name': 'Nanyang Wang', '...</td>\n",
       "      <td>[[Fudan University], [Princeton University], [...</td>\n",
       "      <td>[[CN], [US], [None], [CN], [CN], [CN]]</td>\n",
       "      <td>[[education], [education], [None], [education]...</td>\n",
       "      <td>[Intel Architecture Labs, Fudan University, Te...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.166664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>57310780</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10.1049/ip-f-2.1991.0008</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[123085040, 61410127, 3384915, 25472029, 62246...</td>\n",
       "      <td>[{'author': {'display_name': 'G. D. Tattersall...</td>\n",
       "      <td>[[University of East Anglia], [University of E...</td>\n",
       "      <td>[[GB], [GB], [GB]]</td>\n",
       "      <td>[[education], [education], [company]]</td>\n",
       "      <td>[University of East Anglia, BT Group]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>27121881</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>10.1162/artl.2008.14.2.203</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>[5530467, 98000441, 59704473, 36370590, 108515...</td>\n",
       "      <td>[16646425, 214903009, 5577321, 12448250, 27466...</td>\n",
       "      <td>[{'author': {'display_name': 'Larry Bull', 'id...</td>\n",
       "      <td>[[Schlumberger], [University of the West of En...</td>\n",
       "      <td>[[IE], [GB], [GB], [GB], [GB], [GB]]</td>\n",
       "      <td>[[company], [education], [education], [educati...</td>\n",
       "      <td>[Schlumberger, University of the West of England]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.166664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>59931238</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>10.1057/palgrave.kmrp.8500027</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>[59643147, 15453639, 9504560, 12476939, 557672...</td>\n",
       "      <td>[37932781]</td>\n",
       "      <td>[{'author': {'display_name': 'Albert L. Harris...</td>\n",
       "      <td>[[Appalachian State University], [Appalachian ...</td>\n",
       "      <td>[[US], [US], [CH]]</td>\n",
       "      <td>[[education], [education], [company]]</td>\n",
       "      <td>[Appalachian State University, Roche]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557159</th>\n",
       "      <td>91186755</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>10.1145/3306202</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>[22640035, 5804465, 2042448, 14796162, 6071358...</td>\n",
       "      <td>[204757908, 202750269, 166227926, 202699645]</td>\n",
       "      <td>[{'author': {'display_name': 'Raghid Morcel', ...</td>\n",
       "      <td>[[American University of Beirut], [American Un...</td>\n",
       "      <td>[[LB], [LB], [LB], [LB], [LB], [US], [US]]</td>\n",
       "      <td>[[education], [education], [education], [educa...</td>\n",
       "      <td>[American University of Beirut, Intel]</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557189</th>\n",
       "      <td>44073530</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.1145/3197517.3201283</td>\n",
       "      <td>65</td>\n",
       "      <td>89</td>\n",
       "      <td>[10320049, 13012110, 2803614, 203705211, 21547...</td>\n",
       "      <td>[195345045, 54134066, 52070144, 207900737, 210...</td>\n",
       "      <td>[{'author': {'display_name': 'Hyeongwoo Kim', ...</td>\n",
       "      <td>[[Max Planck Institute for Informatics], [Tech...</td>\n",
       "      <td>[[DE], [DE], [DE], [DE], [DE], [DE], [DE], [GB...</td>\n",
       "      <td>[[facility], [company], [facility], [facility]...</td>\n",
       "      <td>[Max Planck Institute for Informatics, Technic...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.199998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557344</th>\n",
       "      <td>46761335</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>10.1109/icodse.2017.8285884</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[207212687, 16875768, 17750108, 7792962, 63009...</td>\n",
       "      <td>[208280325]</td>\n",
       "      <td>[{'author': {'display_name': 'Pranjal Ambardek...</td>\n",
       "      <td>[[Intel], [Intel], [Intel]]</td>\n",
       "      <td>[[US], [US], [US]]</td>\n",
       "      <td>[[company], [company], [company]]</td>\n",
       "      <td>[Intel]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557358</th>\n",
       "      <td>3054554</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.1145/2786805.2804431</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>[13040187, 2437629, 6706547, 9279336, 20721271...</td>\n",
       "      <td>[21164835, 53285779, 52196064, 207591052, 645561]</td>\n",
       "      <td>[{'author': {'display_name': 'Juliana Saraiva'...</td>\n",
       "      <td>[[Federal University of Pernambuco], [Microsof...</td>\n",
       "      <td>[[BR], [US], [US]]</td>\n",
       "      <td>[[education], [company], [company]]</td>\n",
       "      <td>[Microsoft, Federal University of Pernambuco]</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557618</th>\n",
       "      <td>3569793</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.1117/12.2293699</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>[2617591, 6476085, 5258236, 206590483, 4937791...</td>\n",
       "      <td>[108364009, 198967782, 203642181, 209696181, 2...</td>\n",
       "      <td>[{'author': {'display_name': 'S Sindhu Ramacha...</td>\n",
       "      <td>[[Global Services], [Global Services], [Global...</td>\n",
       "      <td>[[SK], [SK], [SK], [SK]]</td>\n",
       "      <td>[[company], [company], [company], [company]]</td>\n",
       "      <td>[Global Services]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8720 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        paper_id    year                            doi  out_citations_count  \\\n",
       "53      59159027  2018.0   10.1007/978-3-030-11009-3_14                   25   \n",
       "88       4633214  2018.0    10.1007/978-3-030-01252-6_4                   28   \n",
       "155     57310780  1991.0       10.1049/ip-f-2.1991.0008                    0   \n",
       "234     27121881  2008.0     10.1162/artl.2008.14.2.203                   45   \n",
       "263     59931238  2004.0  10.1057/palgrave.kmrp.8500027                   15   \n",
       "...          ...     ...                            ...                  ...   \n",
       "557159  91186755  2019.0                10.1145/3306202                   34   \n",
       "557189  44073530  2018.0        10.1145/3197517.3201283                   65   \n",
       "557344  46761335  2017.0    10.1109/icodse.2017.8285884                   12   \n",
       "557358   3054554  2015.0        10.1145/2786805.2804431                   10   \n",
       "557618   3569793  2018.0             10.1117/12.2293699                   23   \n",
       "\n",
       "        in_citations_count                                 outbound_citations  \\\n",
       "53                       1  [14042655, 52284663, 502946, 2255738, 14547347...   \n",
       "88                     157  [11096669, 15425191, 15195762, 2554264, 632505...   \n",
       "155                      5                                                 []   \n",
       "234                     10  [5530467, 98000441, 59704473, 36370590, 108515...   \n",
       "263                      1  [59643147, 15453639, 9504560, 12476939, 557672...   \n",
       "...                    ...                                                ...   \n",
       "557159                   4  [22640035, 5804465, 2042448, 14796162, 6071358...   \n",
       "557189                  89  [10320049, 13012110, 2803614, 203705211, 21547...   \n",
       "557344                   1  [207212687, 16875768, 17750108, 7792962, 63009...   \n",
       "557358                   5  [13040187, 2437629, 6706547, 9279336, 20721271...   \n",
       "557618                  10  [2617591, 6476085, 5258236, 206590483, 4937791...   \n",
       "\n",
       "                                        inbound_citations  \\\n",
       "53                                            [201070554]   \n",
       "88      [209414673, 209376368, 199442423, 78088951, 21...   \n",
       "155     [123085040, 61410127, 3384915, 25472029, 62246...   \n",
       "234     [16646425, 214903009, 5577321, 12448250, 27466...   \n",
       "263                                            [37932781]   \n",
       "...                                                   ...   \n",
       "557159       [204757908, 202750269, 166227926, 202699645]   \n",
       "557189  [195345045, 54134066, 52070144, 207900737, 210...   \n",
       "557344                                        [208280325]   \n",
       "557358  [21164835, 53285779, 52196064, 207591052, 645561]   \n",
       "557618  [108364009, 198967782, 203642181, 209696181, 2...   \n",
       "\n",
       "                                                open_alex  \\\n",
       "53      [{'author': {'display_name': 'Fabian Brickwedd...   \n",
       "88      [{'author': {'display_name': 'Nanyang Wang', '...   \n",
       "155     [{'author': {'display_name': 'G. D. Tattersall...   \n",
       "234     [{'author': {'display_name': 'Larry Bull', 'id...   \n",
       "263     [{'author': {'display_name': 'Albert L. Harris...   \n",
       "...                                                   ...   \n",
       "557159  [{'author': {'display_name': 'Raghid Morcel', ...   \n",
       "557189  [{'author': {'display_name': 'Hyeongwoo Kim', ...   \n",
       "557344  [{'author': {'display_name': 'Pranjal Ambardek...   \n",
       "557358  [{'author': {'display_name': 'Juliana Saraiva'...   \n",
       "557618  [{'author': {'display_name': 'S Sindhu Ramacha...   \n",
       "\n",
       "                                             institutions  \\\n",
       "53      [[Goethe University Frankfurt, Robert Bosch], ...   \n",
       "88      [[Fudan University], [Princeton University], [...   \n",
       "155     [[University of East Anglia], [University of E...   \n",
       "234     [[Schlumberger], [University of the West of En...   \n",
       "263     [[Appalachian State University], [Appalachian ...   \n",
       "...                                                   ...   \n",
       "557159  [[American University of Beirut], [American Un...   \n",
       "557189  [[Max Planck Institute for Informatics], [Tech...   \n",
       "557344                        [[Intel], [Intel], [Intel]]   \n",
       "557358  [[Federal University of Pernambuco], [Microsof...   \n",
       "557618  [[Global Services], [Global Services], [Global...   \n",
       "\n",
       "                                                countries  \\\n",
       "53                                 [[DE, DE], [DE], [DE]]   \n",
       "88                 [[CN], [US], [None], [CN], [CN], [CN]]   \n",
       "155                                    [[GB], [GB], [GB]]   \n",
       "234                  [[IE], [GB], [GB], [GB], [GB], [GB]]   \n",
       "263                                    [[US], [US], [CH]]   \n",
       "...                                                   ...   \n",
       "557159         [[LB], [LB], [LB], [LB], [LB], [US], [US]]   \n",
       "557189  [[DE], [DE], [DE], [DE], [DE], [DE], [DE], [GB...   \n",
       "557344                                 [[US], [US], [US]]   \n",
       "557358                                 [[BR], [US], [US]]   \n",
       "557618                           [[SK], [SK], [SK], [SK]]   \n",
       "\n",
       "                                                    types  \\\n",
       "53         [[education, company], [company], [education]]   \n",
       "88      [[education], [education], [None], [education]...   \n",
       "155                 [[education], [education], [company]]   \n",
       "234     [[company], [education], [education], [educati...   \n",
       "263                 [[education], [education], [company]]   \n",
       "...                                                   ...   \n",
       "557159  [[education], [education], [education], [educa...   \n",
       "557189  [[facility], [company], [facility], [facility]...   \n",
       "557344                  [[company], [company], [company]]   \n",
       "557358                [[education], [company], [company]]   \n",
       "557618       [[company], [company], [company], [company]]   \n",
       "\n",
       "                                      unique_institutions  BT_percent  \\\n",
       "53            [Robert Bosch, Goethe University Frankfurt]    0.000000   \n",
       "88      [Intel Architecture Labs, Fudan University, Te...    0.166667   \n",
       "155                 [University of East Anglia, BT Group]    0.000000   \n",
       "234     [Schlumberger, University of the West of England]    0.000000   \n",
       "263                 [Appalachian State University, Roche]    0.000000   \n",
       "...                                                   ...         ...   \n",
       "557159             [American University of Beirut, Intel]    0.285714   \n",
       "557189  [Max Planck Institute for Informatics, Technic...    0.000000   \n",
       "557344                                            [Intel]    1.000000   \n",
       "557358      [Microsoft, Federal University of Pernambuco]    0.666667   \n",
       "557618                                  [Global Services]    0.000000   \n",
       "\n",
       "        authors_number  double_affiliation   company  \n",
       "53                   3            0.666644  0.666644  \n",
       "88                   6            0.166664  0.166664  \n",
       "155                  3            0.000000  0.333322  \n",
       "234                  6            0.833319  0.166664  \n",
       "263                  3            0.000000  0.333322  \n",
       "...                ...                 ...       ...  \n",
       "557159               7            0.000000  0.285710  \n",
       "557189              10            0.699993  0.199998  \n",
       "557344               3            0.000000  0.999967  \n",
       "557358               3            0.000000  0.666644  \n",
       "557618               4            0.000000  0.999975  \n",
       "\n",
       "[8720 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['company']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'BT_percent'}>]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df['BT_percent']!=0].hist(column = 'BT_percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\notebooks\\pk\\meme_score.ipynb Komórka 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/notebooks/pk/meme_score.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[df[\u001b[39m'\u001b[39;49m\u001b[39mBT_percent\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m!=\u001b[39m\u001b[39m0.0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "df[df['BT_percent']!=0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'to_parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\notebooks\\pk\\meme_score.ipynb Komórka 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/notebooks/pk/meme_score.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_parquet(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset_with_affiliations_extended_oa.parquet\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to_parquet'"
     ]
    }
   ],
   "source": [
    "df.to_parquet(r'C:/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/big_ai_dataset_with_affiliations_extended_oa.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum inbound_citations that has meme of publication with this meme and\\sum inbound_citations of publication with this meme\n",
    "sum (pub that has a meme and does not have a meme-carrer in inbound_citations)/sum(pub that do not cite meme carrers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_list = dict()\n",
    "memes=[]\n",
    "for chunks_list in df['noun_chunks_cleaned']:\n",
    "    for chunk in chunks_list:\n",
    "        if chunk not in meme_list:\n",
    "            meme_list[chunk]=1\n",
    "            memes.append(chunk)\n",
    "        else:\n",
    "            meme_list[chunk]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/ppaul/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#for i in df.iterrows:\n",
    "#    memes[0] in i['noun_chunks_cleaned']#df[]all() not in df['outbound_citations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc=[]\n",
    "out=[]\n",
    "for i,row in df.iterrows():\n",
    "    cit =[]\n",
    "    for cited in row['outbound_citations']:\n",
    "        cited = int(cited)\n",
    "        if cited in df['paper_id']:\n",
    "            cit.append(cited)\n",
    "        \n",
    "    out.append(cit)\n",
    "    cit=[]\n",
    "    for citing in row['inbound_citations']:\n",
    "        citing = int(citing)\n",
    "        if citing in df['paper_id']:\n",
    "            cit.append(citing)\n",
    "    inc.append(cit)\n",
    "df['inbound_citations_clear']=inc\n",
    "df['outbound_citations_clear']=out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('meme_score.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noun_chunks_cleaned'] = df['noun_chunks_cleaned'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['noun_chunks_cleaned'].str.contains('a a b b',regex=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = MultiLabelBinarizer(sparse_output=True)\n",
    "memes_enc = enc.fit_transform(df['noun_chunks_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'a a a topology',\n",
       " 'a a b b',\n",
       " 'a a baseline approach',\n",
       " 'a a baseline single classifier framework',\n",
       " 'a a big pool',\n",
       " 'a a brute force optimization',\n",
       " 'a a cad system design',\n",
       " 'a a classical rule base system',\n",
       " 'a a classification tree',\n",
       " 'a a clear functional separation',\n",
       " 'a a comparison',\n",
       " 'a a compound rule base expert system',\n",
       " 'a a concert like condition',\n",
       " 'a a contextual combination',\n",
       " 'a a conventional feedforward multilayer neural network',\n",
       " 'a a d tree expository',\n",
       " 'a a data fidelity term',\n",
       " 'a a datum drive initial segmentation',\n",
       " 'a a decision theory model',\n",
       " 'a a design',\n",
       " 'a a design workflow',\n",
       " 'a a domain level plan recognizer',\n",
       " 'a a family',\n",
       " 'a a fast prototype sdr platform',\n",
       " 'a a fault detector',\n",
       " 'a a first order approximation',\n",
       " 'a a fuzzy expert system',\n",
       " 'a a general image sentiment classifier',\n",
       " 'a a generator g',\n",
       " 'a a good feature extraction technique',\n",
       " 'a a hybrid assemble architecture',\n",
       " 'a a knowledge base',\n",
       " 'a a learning framework',\n",
       " 'a a lostcontract',\n",
       " 'a a method',\n",
       " 'a a modular linguistic analysis pipeline',\n",
       " 'a a multi headed model structure',\n",
       " 'a a multi threaded grid search method',\n",
       " 'a a multilayer perceptron',\n",
       " 'a a naive bayesian classifier',\n",
       " 'a a near center classifier',\n",
       " 'a a neural network',\n",
       " 'a a neural network regression',\n",
       " 'a a new numerical regularization method',\n",
       " 'a a non contextual segmentation stage',\n",
       " 'a a nontraditional methodology',\n",
       " 'a a novel method',\n",
       " 'a a novel semantic sensitive framework',\n",
       " 'a a novel semantic sensitive video content characterization',\n",
       " 'a a outer radius',\n",
       " 'a a packet classifier',\n",
       " 'a a parameter fast fourier transform',\n",
       " 'a a pattern recognition classifier',\n",
       " 'a a pedagogical game agent',\n",
       " 'a a pipeline approach',\n",
       " 'a a post facto quality metric',\n",
       " 'a a predictor',\n",
       " 'a a provider machine learning model',\n",
       " 'a a pyramid base algorithm',\n",
       " 'a a ranking',\n",
       " 'a a real time hand gesture formation monitor',\n",
       " 'a a recurrent encoder',\n",
       " 'a a retrain algorithm',\n",
       " 'a a robust technique',\n",
       " 'a a rule',\n",
       " 'a a rule base approach',\n",
       " 'a a segmentation component',\n",
       " 'a a self supervise training',\n",
       " 'a a semantic medical event characterization technique',\n",
       " 'a a semantic sensitive video content representation and semantic video concept model framework',\n",
       " 'a a semantic senstive video content representation framework',\n",
       " 'a a simulate dynamical system',\n",
       " 'a a single classifier',\n",
       " 'a a single well production system',\n",
       " 'a a slang classifier',\n",
       " 'a a star algorithm',\n",
       " 'a a statistical mechanism',\n",
       " 'a a statistically significant reduction',\n",
       " 'a a stochastic image segmentation algorithm',\n",
       " 'a a storage process',\n",
       " 'a a summer institute',\n",
       " 'a a sup',\n",
       " 'a a support vector machine',\n",
       " 'a a survey',\n",
       " 'a a system architecture',\n",
       " 'a a systematic analysis',\n",
       " 'a a theoretical and empirical comparative analysis',\n",
       " 'a a tool',\n",
       " 'a a toolset',\n",
       " 'a a tracking platform',\n",
       " 'a a training algorithm',\n",
       " 'a a trustworthiness score',\n",
       " 'a a vector quantization',\n",
       " 'a a very small subset',\n",
       " 'a a voice recognition system',\n",
       " 'a a vr system',\n",
       " 'a a well understanding',\n",
       " 'a a wrapper procedure',\n",
       " 'a abdelmoty',\n",
       " 'a abelian group unification',\n",
       " 'a ability',\n",
       " 'a abundance quantization b feature selection c literature analysis d selection',\n",
       " 'a abundant compute power',\n",
       " 'a accelerator',\n",
       " 'a access',\n",
       " 'a accuracy',\n",
       " 'a accuracy preserve b data efficient and c high expressive power',\n",
       " 'a accurate depth recovery',\n",
       " 'a acoustic spectral variability',\n",
       " 'a acquire worker',\n",
       " 'a acres',\n",
       " 'a activity',\n",
       " 'a ad',\n",
       " 'a adaline',\n",
       " 'a adapter interface a',\n",
       " 'a adaptive feature',\n",
       " 'a advanced robotic project',\n",
       " 'a agent',\n",
       " 'a agent model',\n",
       " 'a ai',\n",
       " 'a ailable inria research report no page',\n",
       " 'a algorithm',\n",
       " 'a algorithm de sign generic design strategy',\n",
       " 'a algorithm fit all approach',\n",
       " 'a all feature vector',\n",
       " 'a all spectral band',\n",
       " 'a all time series',\n",
       " 'a alt',\n",
       " 'a alzheimer patient datum',\n",
       " 'a ambiguous road surface condition',\n",
       " 'a an accurate model',\n",
       " 'a an action system',\n",
       " 'a an algorithm',\n",
       " 'a an approach',\n",
       " 'a an architecture',\n",
       " 'a an arm trajectory base method',\n",
       " 'a an auditory map',\n",
       " 'a an augment semantic classification',\n",
       " 'a an auto derive feature base inception network',\n",
       " 'a an automatic coarse to fine figure ground scene segmentation module',\n",
       " 'a an automatic recommender',\n",
       " 'a an autonomous agent',\n",
       " 'a an edge device',\n",
       " 'a an effective component wise analysis approach',\n",
       " 'a an efficient decision make procedure',\n",
       " 'a an embed semantic medical search engine',\n",
       " 'a an encoding',\n",
       " 'a an enlarged spectral library',\n",
       " 'a an exist approach',\n",
       " 'a an experimental study',\n",
       " 'a an expert system',\n",
       " 'a an identification',\n",
       " 'a an impulse classifier',\n",
       " 'a an infer phase',\n",
       " 'a an influx',\n",
       " 'a an intelligent regulatory advisor',\n",
       " 'a an lda model',\n",
       " 'a an n gram language model',\n",
       " 'a an nvef word pair identifier',\n",
       " 'a an overview',\n",
       " 'a analysing method',\n",
       " 'a analysis',\n",
       " 'a analyze',\n",
       " 'a anatomical connectivity',\n",
       " 'a ancillary information',\n",
       " 'a and b call',\n",
       " 'a and b cohort',\n",
       " 'a and b coordinate',\n",
       " 'a and b matrix',\n",
       " 'a and b network',\n",
       " 'a and b parameter',\n",
       " 'a and b plane',\n",
       " 'a and b template circuit',\n",
       " 'a and b template optimization',\n",
       " 'a and b type inspection',\n",
       " 'a and base model',\n",
       " 'a and c direction',\n",
       " 'a and c pair',\n",
       " 'a and equation',\n",
       " 'a and its function realization',\n",
       " 'a and method empirical behavior',\n",
       " 'a and model b',\n",
       " 'a and optimization base approach',\n",
       " 'a and pheromone mechanism',\n",
       " 'a and t classification',\n",
       " 'a ann',\n",
       " 'a ann instance',\n",
       " 'a ann observer',\n",
       " 'a annotate chord sequence',\n",
       " 'a annuli',\n",
       " 'a answer pattern',\n",
       " 'a application',\n",
       " 'a applications',\n",
       " 'a approach',\n",
       " 'a appropriate database training corpus',\n",
       " 'a appropriate method',\n",
       " 'a approximate general inference algorithm',\n",
       " 'a arai',\n",
       " 'a arc weights',\n",
       " 'a area',\n",
       " 'a arrival forecast curve',\n",
       " 'a artefact product structure',\n",
       " 'a artifact',\n",
       " 'a artificial intelligent base approach',\n",
       " 'a artificial neural',\n",
       " 'a aspect',\n",
       " 'a asse et al',\n",
       " 'a athlete',\n",
       " 'a atomic primitive type',\n",
       " 'a atrial fibrillation',\n",
       " 'a attribute',\n",
       " 'a auc',\n",
       " 'a auditory cortical neuron',\n",
       " 'a augment cityscapes and camvid dataset',\n",
       " 'a autoencoder b',\n",
       " 'a automate hyperparameter tuning',\n",
       " 'a automate ranking',\n",
       " 'a automate storage',\n",
       " 'a automate synthesis',\n",
       " 'a automatic image datum registration',\n",
       " 'a automatic recognition',\n",
       " 'a automatic selection',\n",
       " 'a automatic vessel tracking',\n",
       " 'a availability',\n",
       " 'a average',\n",
       " 'a avoidance',\n",
       " 'a axis',\n",
       " 'a b',\n",
       " 'a b a',\n",
       " 'a b a σ',\n",
       " 'a b and a machine learning algorithm',\n",
       " 'a b and c subset',\n",
       " 'a b and d class',\n",
       " 'a b and i template',\n",
       " 'a b and x site',\n",
       " 'a b b a c b a',\n",
       " 'a b c',\n",
       " 'a b c and d class',\n",
       " 'a b c d',\n",
       " 'a b c d e f',\n",
       " 'a b c form',\n",
       " 'a b c lbd triple',\n",
       " 'a b ccd september december cloud free image',\n",
       " 'a b charge couple device',\n",
       " 'a b color space',\n",
       " 'a b component',\n",
       " 'a b d e',\n",
       " 'a b experiment',\n",
       " 'a b fig',\n",
       " 'a b figure',\n",
       " 'a b iff',\n",
       " 'a b neither classification response',\n",
       " 'a b orientation map',\n",
       " 'a b p',\n",
       " 'a b parameter',\n",
       " 'a b r',\n",
       " 'a b s',\n",
       " 'a b sampling',\n",
       " 'a b stack',\n",
       " 'a b test',\n",
       " 'a b test like experiment',\n",
       " 'a b test result',\n",
       " 'a b testing',\n",
       " 'a b testing approach',\n",
       " 'a b testing experiment',\n",
       " 'a b testing method',\n",
       " 'a b testing metric',\n",
       " 'a b testing platform',\n",
       " 'a b testing result',\n",
       " 'a b testing scenario',\n",
       " 'a back end pipeline',\n",
       " 'a back propagation neural network',\n",
       " 'a backbone',\n",
       " 'a backbone visualization',\n",
       " 'a backdrop telephone speech technology',\n",
       " 'a backend self decommission protocol',\n",
       " 'a background',\n",
       " 'a backpropagation algorithm',\n",
       " 'a backpropagation method',\n",
       " 'a backpropagation multilayer perceptron and radial basis support vector machine',\n",
       " 'a backward and forward non rigid alignment strategy',\n",
       " 'a backward pass',\n",
       " 'a bacterial census',\n",
       " 'a bad case performance',\n",
       " 'a bad idea',\n",
       " 'a bag',\n",
       " 'a bag of word bow model',\n",
       " 'a balance',\n",
       " 'a balanced approach',\n",
       " 'a balanced bagging algorithm',\n",
       " 'a balanced low level activity state',\n",
       " 'a balanced revenue based resource sharing scheme',\n",
       " 'a balanced set',\n",
       " 'a balanced training set',\n",
       " 'a balancing',\n",
       " 'a ball',\n",
       " 'a bam',\n",
       " 'a bandit algorithm',\n",
       " 'a bank',\n",
       " 'a bank interleaving architecture',\n",
       " 'a bare bones approach',\n",
       " 'a barrel',\n",
       " 'a barren plateau',\n",
       " 'a barrier',\n",
       " 'a basden',\n",
       " 'a base',\n",
       " 'a base approach',\n",
       " 'a base classifier performance',\n",
       " 'a base graphical modeling',\n",
       " 'a base model',\n",
       " 'a base specie detector',\n",
       " 'a baseline',\n",
       " 'a baseline algorithm',\n",
       " 'a baseline condition',\n",
       " 'a baseline method',\n",
       " 'a baseline system',\n",
       " 'a basic alignment',\n",
       " 'a basic approach',\n",
       " 'a basic cnn b cnn',\n",
       " 'a basic feature',\n",
       " 'a basic form',\n",
       " 'a basic mechanism',\n",
       " 'a basic method',\n",
       " 'a basic nnar model',\n",
       " 'a basic phone usage',\n",
       " 'a basic pre',\n",
       " 'a basic problem',\n",
       " 'a basic qualitative ca based model',\n",
       " 'a basic summary',\n",
       " 'a basic vector model',\n",
       " 'a basic video browser',\n",
       " 'a basis',\n",
       " 'a basque question answering system',\n",
       " 'a batch',\n",
       " 'a batch algorithm',\n",
       " 'a batch learning process',\n",
       " 'a batch mode',\n",
       " 'a bayes classifier',\n",
       " 'a bayes net toolkit',\n",
       " 'a bayesian additive regression tree model',\n",
       " 'a bayesian approach',\n",
       " 'a bayesian base classifier',\n",
       " 'a bayesian cbr system',\n",
       " 'a bayesian classifier',\n",
       " 'a bayesian computer vision system',\n",
       " 'a bayesian decision base neural network',\n",
       " 'a bayesian entropy',\n",
       " 'a bayesian framework',\n",
       " 'a bayesian learning application',\n",
       " 'a bayesian network',\n",
       " 'a bayesian network approach',\n",
       " 'a bayesian neural network',\n",
       " 'a bayesian neural network approach',\n",
       " 'a bayesian optimization algorithm',\n",
       " 'a bayesian segmentation framework',\n",
       " 'a bayesian statistical interpretation',\n",
       " 'a bb algorithm',\n",
       " 'a bcg system',\n",
       " 'a bci',\n",
       " 'a bci detect detailed movement imagination',\n",
       " 'a bci device',\n",
       " 'a bci paradigm',\n",
       " 'a bcmi',\n",
       " 'a bdi approach',\n",
       " 'a be b mode',\n",
       " 'a beacon base localization system',\n",
       " 'a beginner guide',\n",
       " 'a behavior',\n",
       " 'a behavior base architecture',\n",
       " 'a behavior change',\n",
       " 'a behavior integration mechanism',\n",
       " 'a behavioral analysis',\n",
       " 'a behavioral study',\n",
       " 'a behavioural control framework',\n",
       " 'a belief',\n",
       " 'a belief revision model',\n",
       " 'a belief theoretic relational database',\n",
       " 'a believability',\n",
       " 'a believable sensory experience',\n",
       " 'a believesthat b',\n",
       " 'a benchmark',\n",
       " 'a benchmark dataset',\n",
       " 'a benchmark evaluation',\n",
       " 'a benchmark image dataset',\n",
       " 'a benchmark setup',\n",
       " 'a benefit',\n",
       " 'a ber',\n",
       " 'a bernoulli neural network',\n",
       " 'a berthing position',\n",
       " 'a best practice analysis',\n",
       " 'a beta deposition',\n",
       " 'a beta test',\n",
       " 'a bewildering range',\n",
       " 'a bfgs matrix inverse approximation',\n",
       " 'a bi convex maximum likelihood base solution',\n",
       " 'a bi criteria neural control scheme',\n",
       " 'a bi criterion scheme',\n",
       " 'a bi criterion velocity minimization neural planning scheme',\n",
       " 'a bi directional gated recurrent unit',\n",
       " 'a bi directional mapping',\n",
       " 'a bi level optimization',\n",
       " 'a bias',\n",
       " 'a biased competition model',\n",
       " 'a biased training datum',\n",
       " 'a bibliography',\n",
       " 'a bibliometric tool',\n",
       " 'a biclustering method',\n",
       " 'a bid',\n",
       " 'a bidimensional view',\n",
       " 'a bidirectional interaction',\n",
       " 'a bidirectional structure',\n",
       " 'a bifurcation phenomenon',\n",
       " 'a big amount',\n",
       " 'a big attack surface',\n",
       " 'a big challenge',\n",
       " 'a big data collection unit',\n",
       " 'a big dataset',\n",
       " 'a big datum',\n",
       " 'a big datum analytic',\n",
       " 'a big datum environment',\n",
       " 'a big impact',\n",
       " 'a big issue',\n",
       " 'a big learning classifier systems',\n",
       " 'a big number',\n",
       " 'a big piece',\n",
       " 'a big player base',\n",
       " 'a big problem',\n",
       " 'a big reward',\n",
       " 'a bilevel rendition result',\n",
       " 'a bilingual segment',\n",
       " 'a billing model',\n",
       " 'a bilstm',\n",
       " 'a bimodal palmprint verification feature level fusion',\n",
       " 'a binarization method',\n",
       " 'a binarization process',\n",
       " 'a binarize neural network',\n",
       " 'a binary block code',\n",
       " 'a binary classification',\n",
       " 'a binary classification problem',\n",
       " 'a binary classifier',\n",
       " 'a binary classifier sub class distribution',\n",
       " 'a binary decision tree implementation',\n",
       " 'a binary layer',\n",
       " 'a binary random process',\n",
       " 'a binary relevance',\n",
       " 'a binary representation',\n",
       " 'a binary sequence',\n",
       " 'a binary training class',\n",
       " 'a binary vector',\n",
       " 'a bio inspire approach',\n",
       " 'a bio inspire connectionist approach',\n",
       " 'a bio inspire method',\n",
       " 'a bio medical signal analysis flow',\n",
       " 'a bio plausible structure',\n",
       " 'a bioartificial ecosystem',\n",
       " 'a biogeography based optimization',\n",
       " 'a biological development model',\n",
       " 'a biological nervous system',\n",
       " 'a biological neural network',\n",
       " 'a biologically hardwire notion',\n",
       " 'a biologically inspire module',\n",
       " 'a biologically motivated and computationally efficient natural language a question answer system',\n",
       " 'a biologically motivated approach',\n",
       " 'a biologically motivated scheme',\n",
       " 'a biomedical article',\n",
       " 'a biometric',\n",
       " 'a biometric encryption approach incorporating fingerprint indexing',\n",
       " 'a biometric identification',\n",
       " 'a biomimetic sensor',\n",
       " 'a biomimetic system',\n",
       " 'a biophysical model',\n",
       " 'a biopsy',\n",
       " 'a bipolar possibilistic representation',\n",
       " 'a bird',\n",
       " 'a bird eye grid',\n",
       " 'a birth date',\n",
       " 'a bit',\n",
       " 'a bit facial asymmetry code',\n",
       " 'a bizarre system',\n",
       " 'a black box',\n",
       " 'a black box optimization',\n",
       " 'a blackboard expert system shell',\n",
       " 'a blast e',\n",
       " 'a blind denoising task',\n",
       " 'a blind scenario technique',\n",
       " 'a blind watermarking scheme',\n",
       " 'a bloch',\n",
       " 'a block',\n",
       " 'a block base image segmentation technique',\n",
       " 'a block based human model',\n",
       " 'a block result',\n",
       " 'a blockchain base framework',\n",
       " 'a blockchain technology',\n",
       " 'a blocking problem',\n",
       " 'a blog',\n",
       " 'a blood glucose level estimation model',\n",
       " 'a blossoming',\n",
       " 'a blue strip',\n",
       " 'a blueprint',\n",
       " 'a boaster',\n",
       " 'a boat',\n",
       " 'a body',\n",
       " 'a bof approach',\n",
       " 'a bolt joint',\n",
       " 'a bond',\n",
       " 'a bone',\n",
       " 'a bone dl cnn',\n",
       " 'a book',\n",
       " 'a boolean encoding',\n",
       " 'a boon',\n",
       " 'a boost algorithm',\n",
       " 'a boost approach',\n",
       " 'a boot loader',\n",
       " 'a bootstrappe module',\n",
       " 'a border training algorithm',\n",
       " 'a bottleneck combination strategy',\n",
       " 'a bottleneck problem',\n",
       " 'a bottom up approach',\n",
       " 'a bottom up workflow mining approach',\n",
       " 'a bound',\n",
       " 'a boundary',\n",
       " 'a boundary refinement method',\n",
       " 'a boundary web',\n",
       " 'a bounded index',\n",
       " 'a bounded search space',\n",
       " 'a bounding box',\n",
       " 'a bounding box regression method',\n",
       " 'a bow shape serial position curve',\n",
       " 'a box',\n",
       " 'a box classification',\n",
       " 'a box consistency checking',\n",
       " 'a bp drilling diagnosis model',\n",
       " 'a bp neural network model',\n",
       " 'a bpnn',\n",
       " 'a bracket scoring procedure',\n",
       " 'a bradford book',\n",
       " 'a brain',\n",
       " 'a brain body robot interface',\n",
       " 'a brain connectivity',\n",
       " 'a brain function',\n",
       " 'a brain or nerve cell',\n",
       " 'a brainstorming session',\n",
       " 'a branch',\n",
       " 'a branch and bound algorithm',\n",
       " 'a brave new world',\n",
       " 'a breach',\n",
       " 'a break',\n",
       " 'a break notification',\n",
       " 'a breakdown',\n",
       " 'a breakthrough disruptive situational management',\n",
       " 'a bridge',\n",
       " 'a brief description',\n",
       " 'a brief historical review',\n",
       " 'a brief history',\n",
       " 'a brief index',\n",
       " 'a brief introduction',\n",
       " 'a brief qverview',\n",
       " 'a brief review',\n",
       " 'a brilliant student',\n",
       " 'a broad and difficult to define category',\n",
       " 'a broad array',\n",
       " 'a broad base program',\n",
       " 'a broad category',\n",
       " 'a broad comparative analysis',\n",
       " 'a broad context',\n",
       " 'a broad document class',\n",
       " 'a broad medical image dataset',\n",
       " 'a broad negative class',\n",
       " 'a broad range',\n",
       " 'a broad scope',\n",
       " 'a broad subject',\n",
       " 'a broad survey',\n",
       " 'a broad theme',\n",
       " 'a broader perspective',\n",
       " 'a broadly applicable unified theoretical framework',\n",
       " 'a broker approach',\n",
       " 'a brown',\n",
       " 'a brute force',\n",
       " 'a bsolute georeferencing',\n",
       " 'a bsp',\n",
       " 'a bsp model',\n",
       " 'a buffer',\n",
       " 'a buffering strategy',\n",
       " 'a bug',\n",
       " 'a build in automatic safeguard mechanism',\n",
       " 'a building',\n",
       " 'a building representation',\n",
       " 'a bunch',\n",
       " 'a bundant dynamic hand gesture',\n",
       " 'a burden',\n",
       " 'a burst',\n",
       " 'a bus',\n",
       " 'a business outcome',\n",
       " 'a butler agent',\n",
       " 'a by product',\n",
       " 'a c',\n",
       " 'a c c',\n",
       " 'a c drfs',\n",
       " 'a c energy consumption',\n",
       " 'a c globally interpolatory spline',\n",
       " 'a c system',\n",
       " 'a c t',\n",
       " 'a ca approach',\n",
       " 'a ca rule model',\n",
       " 'a cache base distributed terabyte text retrieval system',\n",
       " 'a cache base semi stream join',\n",
       " 'a cad environment',\n",
       " 'a cad system',\n",
       " 'a cad tool',\n",
       " 'a caddbt',\n",
       " 'a cade system',\n",
       " 'a cae system',\n",
       " 'a caf znn model',\n",
       " 'a calculate tonality coefficient',\n",
       " 'a calculation',\n",
       " 'a calculus',\n",
       " 'a calibration method',\n",
       " 'a calibration process',\n",
       " 'a calibration purpose',\n",
       " 'a calibration recording',\n",
       " 'a calibration session',\n",
       " 'a calibration target',\n",
       " 'a callback mechanism',\n",
       " 'a camera',\n",
       " 'a camera configuration',\n",
       " 'a camera drive interactive table',\n",
       " 'a camera model non linear response function',\n",
       " 'a canadians',\n",
       " 'a cancer',\n",
       " 'a candidate parametric object',\n",
       " 'a candidate passage',\n",
       " 'a canonical correlation analysis classifier',\n",
       " 'a cap',\n",
       " 'a capability',\n",
       " 'a capacity',\n",
       " 'a capacity trading portfolio',\n",
       " 'a capsule structure',\n",
       " 'a captcha',\n",
       " 'a car',\n",
       " 'a carbonaro',\n",
       " 'a cardiologist',\n",
       " 'a careful relabeling mechanism',\n",
       " 'a carefully design parameter setting',\n",
       " 'a cart',\n",
       " 'a cart model',\n",
       " 'a cas',\n",
       " 'a cascade',\n",
       " 'a cascade and global hybrid system',\n",
       " 'a cascade depth neural network',\n",
       " 'a cascade formation',\n",
       " 'a cascade graph convolutional recurrent neural network',\n",
       " 'a cascade pixel domain transcoder',\n",
       " 'a cascade technique',\n",
       " 'a cascade use',\n",
       " 'a cascade utilisation',\n",
       " 'a case',\n",
       " 'a case accuracy',\n",
       " 'a case base approach',\n",
       " 'a case base reasoner adaptive',\n",
       " 'a case base reasoning',\n",
       " 'a case base reasoning approach',\n",
       " 'a case base recognition',\n",
       " 'a case base system',\n",
       " 'a case control study',\n",
       " 'a case edge intensity threshold',\n",
       " 'a case feature selection',\n",
       " 'a case study',\n",
       " 'a case study empirical comparison',\n",
       " 'a case study inferring queue sizes',\n",
       " 'a cat',\n",
       " 'a catalog',\n",
       " 'a catalogue',\n",
       " 'a catalyst',\n",
       " 'a categorization',\n",
       " 'a categorization help',\n",
       " 'a categorization phase',\n",
       " 'a categorization system',\n",
       " 'a categorization task',\n",
       " 'a category',\n",
       " 'a catheter',\n",
       " 'a catv and internet combined framework',\n",
       " 'a cauchy distribution',\n",
       " 'a causal analysis',\n",
       " 'a causal blueprint',\n",
       " 'a causal extraction scheme',\n",
       " 'a causal graph',\n",
       " 'a causal knowledge driven negotiation mechanism',\n",
       " 'a causal model',\n",
       " 'a causal modeling framework',\n",
       " 'a causal theory',\n",
       " 'a causative attack',\n",
       " 'a cause',\n",
       " 'a cav',\n",
       " 'a caveat',\n",
       " 'a cbr based game recommender',\n",
       " 'a cbr driven genetic algorithm',\n",
       " 'a cbr system',\n",
       " 'a ccnn',\n",
       " 'a ccuracy rate',\n",
       " 'a ccxg definition and annotation system',\n",
       " 'a cdn',\n",
       " 'a cdns',\n",
       " 'a cdss',\n",
       " 'a ceiling fan',\n",
       " 'a celebration',\n",
       " 'a cell',\n",
       " 'a cell ability',\n",
       " 'a cell protein',\n",
       " 'a cell segmentation',\n",
       " 'a cell type',\n",
       " 'a cellular automata model',\n",
       " 'a cellular automaton model',\n",
       " 'a cellular automaton simulation',\n",
       " 'a cellular neural network',\n",
       " 'a cellular structure',\n",
       " 'a center constrain meb problem',\n",
       " 'a centerline',\n",
       " 'a central agent',\n",
       " 'a central aspect',\n",
       " 'a central interdisciplinary area',\n",
       " 'a central pattern generator',\n",
       " 'a central phenomenon',\n",
       " 'a central processing system',\n",
       " 'a centrality',\n",
       " 'a centralization',\n",
       " 'a centralized abstraction and replicated view architecture',\n",
       " 'a centralized approach',\n",
       " 'a centralized network design problem',\n",
       " 'a centralized state repository approach',\n",
       " 'a century',\n",
       " 'a century ago the term computer aid diagnosis',\n",
       " 'a century research',\n",
       " 'a cerebellar adaptive timing competence',\n",
       " 'a cerebral biopsy',\n",
       " 'a certain amount',\n",
       " 'a certain degree',\n",
       " 'a certain machining operation',\n",
       " 'a certain pattern',\n",
       " 'a certify accuracy',\n",
       " 'a cgm algorithm',\n",
       " 'a chain',\n",
       " 'a chain process',\n",
       " 'a chain structure',\n",
       " 'a chair',\n",
       " 'a challenge',\n",
       " 'a challenge problem',\n",
       " 'a challenge uav dataset',\n",
       " 'a challenging',\n",
       " 'a challenging and complex task',\n",
       " 'a challenging and time consume task',\n",
       " 'a challenging classification task',\n",
       " 'a challenging context',\n",
       " 'a challenging domain',\n",
       " 'a challenging environment',\n",
       " 'a challenging goal',\n",
       " 'a challenging issue',\n",
       " 'a challenging mission',\n",
       " 'a challenging problem',\n",
       " 'a challenging setting',\n",
       " 'a challenging target',\n",
       " 'a challenging task',\n",
       " 'a challenging topic',\n",
       " 'a challenging use case',\n",
       " 'a challenging venture',\n",
       " 'a change',\n",
       " 'a change detection algorithm enabling intelligent background dimension reduction',\n",
       " 'a change detection framework',\n",
       " 'a change management',\n",
       " 'a change validation system',\n",
       " 'a channel',\n",
       " 'a channel d image',\n",
       " 'a channel database',\n",
       " 'a channel density',\n",
       " 'a channel model',\n",
       " 'a chaos map',\n",
       " 'a chaotic attractor',\n",
       " 'a chaotic iterative network',\n",
       " 'a chaotic neural network optimization problem',\n",
       " 'a chaotic set',\n",
       " 'a character',\n",
       " 'a character image classifier',\n",
       " 'a character proposal module',\n",
       " 'a character recognition system',\n",
       " 'a characterisation',\n",
       " 'a characteristic',\n",
       " 'a characteristic appearance',\n",
       " 'a characterization',\n",
       " 'a charger',\n",
       " 'a chassis',\n",
       " 'a chatbot',\n",
       " 'a cheaply craft target',\n",
       " 'a check',\n",
       " 'a checker',\n",
       " 'a checkerboard',\n",
       " 'a chemical',\n",
       " 'a chemical intelligence approach',\n",
       " 'a chessboard',\n",
       " 'a child',\n",
       " 'a chinese automatic interactive feedback system',\n",
       " 'a chinese corpus',\n",
       " 'a chinese dialect',\n",
       " 'a chinese mobile phone input method',\n",
       " 'a chip',\n",
       " 'a chip builder',\n",
       " 'a chip predictor',\n",
       " 'a chl',\n",
       " 'a choice',\n",
       " 'a choose plaintext steganalysis',\n",
       " 'a chording glove',\n",
       " 'a choreographed dance',\n",
       " 'a choreography',\n",
       " 'a chronic disease',\n",
       " 'a chronological history base execution time estimation model',\n",
       " 'a chunk',\n",
       " 'a chunk driven bootstrapping approach',\n",
       " 'a ci',\n",
       " 'a cider',\n",
       " 'a circuit',\n",
       " 'a circuit involving complex walking tasks',\n",
       " 'a circularity',\n",
       " 'a circumstance',\n",
       " 'a circumstance witness',\n",
       " 'a citation metric',\n",
       " 'a city',\n",
       " 'a claim',\n",
       " 'a clarification',\n",
       " 'a class',\n",
       " 'a class balanced and class imbalanced setting',\n",
       " 'a class centroid',\n",
       " 'a class classification',\n",
       " 'a class classification module',\n",
       " 'a class density',\n",
       " 'a class hierarchy',\n",
       " 'a class imbalance',\n",
       " 'a class incremental way',\n",
       " 'a class indifferent method b class conscious method',\n",
       " 'a class library',\n",
       " 'a class problem',\n",
       " 'a class sentiment prediction',\n",
       " 'a class set',\n",
       " 'a class solution',\n",
       " 'a class specific subspace',\n",
       " 'a class specific visualization strategy',\n",
       " 'a classic coherent receiver',\n",
       " 'a classic convolutional neural network',\n",
       " 'a classic naive bayesian classifier',\n",
       " 'a classical architecture',\n",
       " 'a classical benchmark',\n",
       " 'a classical column',\n",
       " 'a classical communication technique',\n",
       " 'a classical fix length fl universal classifier',\n",
       " 'a classical logical thought',\n",
       " 'a classical nonlinear ica task',\n",
       " 'a classical setting',\n",
       " 'a classication',\n",
       " 'a classification',\n",
       " 'a classification algorithm',\n",
       " 'a classification approach',\n",
       " 'a classification architecture',\n",
       " 'a classification class pnn classifier',\n",
       " 'a classification expert system',\n",
       " 'a classification method',\n",
       " 'a classification model',\n",
       " 'a classification module',\n",
       " 'a classification network',\n",
       " 'a classification performance',\n",
       " 'a classification problem',\n",
       " 'a classification procedure',\n",
       " 'a classification process',\n",
       " 'a classification rule',\n",
       " 'a classification system',\n",
       " 'a classification task',\n",
       " 'a classification technique',\n",
       " 'a classification tree',\n",
       " 'a classifier',\n",
       " 'a classifier arrangement',\n",
       " 'a classifier base approach',\n",
       " 'a classifier building',\n",
       " 'a classifier estimate',\n",
       " 'a classifier fusion algorithm',\n",
       " 'a classifier generator',\n",
       " 'a classifier involvement',\n",
       " 'a classifier level',\n",
       " 'a classifier log domain multiplier',\n",
       " 'a classifier structure',\n",
       " 'a classifier system',\n",
       " 'a classify function',\n",
       " 'a clause',\n",
       " 'a clean decomposition',\n",
       " 'a clean speech task',\n",
       " 'a clear characterization',\n",
       " 'a clear cut or nonlinear decision',\n",
       " 'a clear delimitation',\n",
       " 'a clear demarcation',\n",
       " 'a clear distinction',\n",
       " 'a clear semantic channel',\n",
       " 'a clearly justify statistical approach',\n",
       " 'a client',\n",
       " 'a client rank aggregator',\n",
       " 'a client server approach',\n",
       " 'a client server system',\n",
       " 'a client side logger',\n",
       " 'a clinical and control group',\n",
       " 'a clinical and dermoscopic image',\n",
       " 'a clinical causal model',\n",
       " 'a clinical decision support system',\n",
       " 'a clinical label',\n",
       " 'a clinical nlp task',\n",
       " 'a clinical tool',\n",
       " 'a clinician judgment',\n",
       " 'a clip approach',\n",
       " 'a clique',\n",
       " 'a cloned software tool',\n",
       " 'a cloning template',\n",
       " 'a close interaction',\n",
       " 'a close liason',\n",
       " 'a close loop controller',\n",
       " 'a close loop workflow',\n",
       " 'a close mapping',\n",
       " 'a close relationship',\n",
       " 'a closed b open and unbounded convex hypersurface',\n",
       " 'a closed boundary',\n",
       " 'a closed form solution',\n",
       " 'a closed geometry',\n",
       " 'a closed homogenous network',\n",
       " 'a closed loop setup',\n",
       " 'a closed loop system',\n",
       " 'a closed system approach',\n",
       " 'a closed world',\n",
       " 'a closed world scenario',\n",
       " 'a closely couple multi agent environment',\n",
       " 'a closure system',\n",
       " 'a cloud',\n",
       " 'a cloud base ubiquitous mobile healthcare system',\n",
       " 'a cloud ecosystem',\n",
       " 'a clue',\n",
       " 'a cluster',\n",
       " 'a cluster algorithm',\n",
       " 'a cluster analysis',\n",
       " 'a cluster base evolutionary algorithm',\n",
       " 'a cluster base genetic fuzzy mining approach',\n",
       " 'a cluster feature weighting case base reasoning',\n",
       " 'a cluster formulation',\n",
       " 'a cluster network',\n",
       " 'a cluster part',\n",
       " 'a cluster procedure',\n",
       " 'a cluster strategy',\n",
       " 'a cluster structure',\n",
       " 'a cluster validity assessment index',\n",
       " 'a clustered retrieval approach',\n",
       " 'a clustering',\n",
       " 'a clustering base backpacking algorithm',\n",
       " 'a clustering base channel assignment algorithm',\n",
       " 'a clustering base extraction algorithm',\n",
       " 'a clustering base feature weighting approach',\n",
       " 'a clustering mechanism',\n",
       " 'a clustering model',\n",
       " 'a clustering process',\n",
       " 'a clustering technique',\n",
       " 'a clutter',\n",
       " 'a clutter model',\n",
       " 'a cnf formula hierarchy',\n",
       " 'a cnn',\n",
       " 'a cnn accelerator',\n",
       " 'a cnn algorithm',\n",
       " 'a cnn architecture',\n",
       " 'a cnn architecture model',\n",
       " 'a cnn base classifier',\n",
       " 'a cnn base image representation',\n",
       " 'a cnn base md yolo framework',\n",
       " 'a cnn base system',\n",
       " 'a cnn classifier object class prediction',\n",
       " 'a cnn input',\n",
       " 'a cnn model',\n",
       " 'a cnn whole image proposal',\n",
       " 'a co attention base social temporal context extractor',\n",
       " 'a co design technique',\n",
       " 'a co evolution training strategy',\n",
       " 'a co evolutionary epidemiological model',\n",
       " 'a co processing accelerator',\n",
       " 'a co ranking framework',\n",
       " 'a co training approach',\n",
       " 'a coached collaborative learning environment',\n",
       " 'a coalition',\n",
       " 'a coalition evaluation algorithm',\n",
       " 'a coarse and fine bayesian belief propagation',\n",
       " 'a coarse grain approach',\n",
       " 'a coarse grain classifier',\n",
       " 'a coarse grain mapping method',\n",
       " 'a coarse to fine quantization procedure',\n",
       " 'a cochleagram',\n",
       " 'a cockpit',\n",
       " 'a code',\n",
       " 'a code automate',\n",
       " 'a code generation approach',\n",
       " 'a code scheme',\n",
       " 'a code service',\n",
       " 'a code smell',\n",
       " 'a code unit cu decision method',\n",
       " ...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbadałam częstości memów. \n",
    "Wykasowałam memy\n",
    "\n",
    "OneHotEncoding memów w paperach cytowanych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a mask to apply to list of memes(nonexistent as of now)\n",
    "memes_mask = np.nonzero(memes_enc.sum(axis=0)-1)[1]\n",
    "memes_enc_cleaned = memes_enc[:,memes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<505000x846793 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 14533478 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         3036974\n",
       "2          398942\n",
       "3          137087\n",
       "4           70562\n",
       "5           42965\n",
       "           ...   \n",
       "1836            1\n",
       "1839            1\n",
       "1840            1\n",
       "1841            1\n",
       "251321          1\n",
       "Length: 2099, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency of memes\n",
    "pd.DataFrame(np.sort(memes_enc.sum(axis=0))).T.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df['paper_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>doc_lens</th>\n",
       "      <th>nouns</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>noun_chunks_cleaned</th>\n",
       "      <th>inbound_citations</th>\n",
       "      <th>outbound_citations</th>\n",
       "      <th>inbound_citations_clear</th>\n",
       "      <th>outbound_citations_clear</th>\n",
       "      <th>memes_in_cited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paper_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199668001</th>\n",
       "      <td>199668001</td>\n",
       "      <td>196</td>\n",
       "      <td>[Road, construction, projects, territory, over...</td>\n",
       "      <td>[Road construction projects, the territory, th...</td>\n",
       "      <td>[road, construction, project, on, the, territo...</td>\n",
       "      <td>[road construction project, territory, republi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[106476531, 67083539, 36731616, 34616216, 1096...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879234</th>\n",
       "      <td>2879234</td>\n",
       "      <td>235</td>\n",
       "      <td>[nets, CNNs, performance, history, approaches,...</td>\n",
       "      <td>[Convolutional neural nets, CNNs, remarkable p...</td>\n",
       "      <td>[convolutional, neural, net, (, cnn, ), have, ...</td>\n",
       "      <td>[convolutional neural net, cnn, remarkable per...</td>\n",
       "      <td>[11015941, 52160763, 199488257, 23874112, 4241...</td>\n",
       "      <td>[206592419, 215721, 10111903, 1003907, 3198903...</td>\n",
       "      <td>[340420, 471907, 250792]</td>\n",
       "      <td>[215721, 127386, 392527]</td>\n",
       "      <td>[term, overall goal, numerous network activity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17786914</th>\n",
       "      <td>17786914</td>\n",
       "      <td>120</td>\n",
       "      <td>[results, benchmarks, modeling, speech, recogn...</td>\n",
       "      <td>[excellent results, benchmarks, acoustic model...</td>\n",
       "      <td>[recently, ,, deep, neural, networks(DNNs, ), ...</td>\n",
       "      <td>[excellent result, benchmark, acoustic modelin...</td>\n",
       "      <td>[198931159]</td>\n",
       "      <td>[9530137, 398770, 207168299, 14832074, 1799800...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[398770, 299222]</td>\n",
       "      <td>[very good computational efficiency, training ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432300</th>\n",
       "      <td>17432300</td>\n",
       "      <td>235</td>\n",
       "      <td>[characters, structure, character, arrangement...</td>\n",
       "      <td>[East-Asian characters, a rich hierarchical st...</td>\n",
       "      <td>[east, -, asian, character, possess, a, rich, ...</td>\n",
       "      <td>[east asian character, rich hierarchical struc...</td>\n",
       "      <td>[15983137, 7625356, 15404413, 199472639, 47640...</td>\n",
       "      <td>[371064, 3246932, 8991475, 36725681, 32031694,...</td>\n",
       "      <td>[467570]</td>\n",
       "      <td>[371064]</td>\n",
       "      <td>[geometric consistency, correspondence, image,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204957502</th>\n",
       "      <td>204957502</td>\n",
       "      <td>33</td>\n",
       "      <td>[Internet, articles, multimedia, content, life...</td>\n",
       "      <td>[the Internet, countless articles, multimedia ...</td>\n",
       "      <td>[with, the, internet, become, widespread, ,, c...</td>\n",
       "      <td>[internet, countless article, multimedia conte...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127628365</th>\n",
       "      <td>127628365</td>\n",
       "      <td>179</td>\n",
       "      <td>[models, strength, phenomena, reality, self, o...</td>\n",
       "      <td>[Abstract Probabilistic models, their strength...</td>\n",
       "      <td>[Abstract, Probabilistic, model, have, prove, ...</td>\n",
       "      <td>[abstract probabilistic model, strength, many ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11619477</th>\n",
       "      <td>11619477</td>\n",
       "      <td>189</td>\n",
       "      <td>[AD, courses, patients, period, time, points, ...</td>\n",
       "      <td>[Alzheimer's Disease (AD, different courses, s...</td>\n",
       "      <td>[Alzheimer, 's, Disease, (, ad, ), can, take, ...</td>\n",
       "      <td>[alzheimer disease ad, different course, patie...</td>\n",
       "      <td>[204230004]</td>\n",
       "      <td>[34935848, 27355075, 9895278, 8461070, 3276119...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5807289</th>\n",
       "      <td>5807289</td>\n",
       "      <td>217</td>\n",
       "      <td>[Concurrency, bugs, software, testing, nature,...</td>\n",
       "      <td>[Concurrency bugs, software testing, their non...</td>\n",
       "      <td>[concurrency, bug, be, notoriously, difficult,...</td>\n",
       "      <td>[concurrency bug, software testing, non determ...</td>\n",
       "      <td>[15460152, 69949082, 5076939, 18091491, 678683...</td>\n",
       "      <td>[9005386, 17620776, 3439914, 978769, 2941443, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894398</th>\n",
       "      <td>15894398</td>\n",
       "      <td>87</td>\n",
       "      <td>[model, snake, reconstruction, volumetric, ima...</td>\n",
       "      <td>[a new statistic deformable model, discriminan...</td>\n",
       "      <td>[we, propose, a, new, statistic, deformable, m...</td>\n",
       "      <td>[new statistic deformable model, discriminant ...</td>\n",
       "      <td>[2469979, 14334601, 3080024, 18147424]</td>\n",
       "      <td>[14001890, 30582, 63717849, 29187618, 12849354...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[30582]</td>\n",
       "      <td>[pattern recognition, common process, abundanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15895702</th>\n",
       "      <td>15895702</td>\n",
       "      <td>243</td>\n",
       "      <td>[BackgroundThe, conservation, sequences, genom...</td>\n",
       "      <td>[BackgroundThe conservation, sequences, relate...</td>\n",
       "      <td>[backgroundthe, conservation, of, sequence, be...</td>\n",
       "      <td>[backgroundthe conservation, sequence, relate ...</td>\n",
       "      <td>[9533661, 196612986, 10506251, 54820054, 13868...</td>\n",
       "      <td>[3243833, 18690884, 7777003, 1677744, 3189433,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[251692]</td>\n",
       "      <td>[traditional neural network and regression mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            paper_id  doc_lens  \\\n",
       "paper_id                         \n",
       "199668001  199668001       196   \n",
       "2879234      2879234       235   \n",
       "17786914    17786914       120   \n",
       "17432300    17432300       235   \n",
       "204957502  204957502        33   \n",
       "...              ...       ...   \n",
       "127628365  127628365       179   \n",
       "11619477    11619477       189   \n",
       "5807289      5807289       217   \n",
       "15894398    15894398        87   \n",
       "15895702    15895702       243   \n",
       "\n",
       "                                                       nouns  \\\n",
       "paper_id                                                       \n",
       "199668001  [Road, construction, projects, territory, over...   \n",
       "2879234    [nets, CNNs, performance, history, approaches,...   \n",
       "17786914   [results, benchmarks, modeling, speech, recogn...   \n",
       "17432300   [characters, structure, character, arrangement...   \n",
       "204957502  [Internet, articles, multimedia, content, life...   \n",
       "...                                                      ...   \n",
       "127628365  [models, strength, phenomena, reality, self, o...   \n",
       "11619477   [AD, courses, patients, period, time, points, ...   \n",
       "5807289    [Concurrency, bugs, software, testing, nature,...   \n",
       "15894398   [model, snake, reconstruction, volumetric, ima...   \n",
       "15895702   [BackgroundThe, conservation, sequences, genom...   \n",
       "\n",
       "                                                 noun_chunks  \\\n",
       "paper_id                                                       \n",
       "199668001  [Road construction projects, the territory, th...   \n",
       "2879234    [Convolutional neural nets, CNNs, remarkable p...   \n",
       "17786914   [excellent results, benchmarks, acoustic model...   \n",
       "17432300   [East-Asian characters, a rich hierarchical st...   \n",
       "204957502  [the Internet, countless articles, multimedia ...   \n",
       "...                                                      ...   \n",
       "127628365  [Abstract Probabilistic models, their strength...   \n",
       "11619477   [Alzheimer's Disease (AD, different courses, s...   \n",
       "5807289    [Concurrency bugs, software testing, their non...   \n",
       "15894398   [a new statistic deformable model, discriminan...   \n",
       "15895702   [BackgroundThe conservation, sequences, relate...   \n",
       "\n",
       "                                                      lemmas  \\\n",
       "paper_id                                                       \n",
       "199668001  [road, construction, project, on, the, territo...   \n",
       "2879234    [convolutional, neural, net, (, cnn, ), have, ...   \n",
       "17786914   [recently, ,, deep, neural, networks(DNNs, ), ...   \n",
       "17432300   [east, -, asian, character, possess, a, rich, ...   \n",
       "204957502  [with, the, internet, become, widespread, ,, c...   \n",
       "...                                                      ...   \n",
       "127628365  [Abstract, Probabilistic, model, have, prove, ...   \n",
       "11619477   [Alzheimer, 's, Disease, (, ad, ), can, take, ...   \n",
       "5807289    [concurrency, bug, be, notoriously, difficult,...   \n",
       "15894398   [we, propose, a, new, statistic, deformable, m...   \n",
       "15895702   [backgroundthe, conservation, of, sequence, be...   \n",
       "\n",
       "                                         noun_chunks_cleaned  \\\n",
       "paper_id                                                       \n",
       "199668001  [road construction project, territory, republi...   \n",
       "2879234    [convolutional neural net, cnn, remarkable per...   \n",
       "17786914   [excellent result, benchmark, acoustic modelin...   \n",
       "17432300   [east asian character, rich hierarchical struc...   \n",
       "204957502  [internet, countless article, multimedia conte...   \n",
       "...                                                      ...   \n",
       "127628365  [abstract probabilistic model, strength, many ...   \n",
       "11619477   [alzheimer disease ad, different course, patie...   \n",
       "5807289    [concurrency bug, software testing, non determ...   \n",
       "15894398   [new statistic deformable model, discriminant ...   \n",
       "15895702   [backgroundthe conservation, sequence, relate ...   \n",
       "\n",
       "                                           inbound_citations  \\\n",
       "paper_id                                                       \n",
       "199668001                                                 []   \n",
       "2879234    [11015941, 52160763, 199488257, 23874112, 4241...   \n",
       "17786914                                         [198931159]   \n",
       "17432300   [15983137, 7625356, 15404413, 199472639, 47640...   \n",
       "204957502                                                 []   \n",
       "...                                                      ...   \n",
       "127628365                                                 []   \n",
       "11619477                                         [204230004]   \n",
       "5807289    [15460152, 69949082, 5076939, 18091491, 678683...   \n",
       "15894398              [2469979, 14334601, 3080024, 18147424]   \n",
       "15895702   [9533661, 196612986, 10506251, 54820054, 13868...   \n",
       "\n",
       "                                          outbound_citations  \\\n",
       "paper_id                                                       \n",
       "199668001  [106476531, 67083539, 36731616, 34616216, 1096...   \n",
       "2879234    [206592419, 215721, 10111903, 1003907, 3198903...   \n",
       "17786914   [9530137, 398770, 207168299, 14832074, 1799800...   \n",
       "17432300   [371064, 3246932, 8991475, 36725681, 32031694,...   \n",
       "204957502                                                 []   \n",
       "...                                                      ...   \n",
       "127628365                                                 []   \n",
       "11619477   [34935848, 27355075, 9895278, 8461070, 3276119...   \n",
       "5807289    [9005386, 17620776, 3439914, 978769, 2941443, ...   \n",
       "15894398   [14001890, 30582, 63717849, 29187618, 12849354...   \n",
       "15895702   [3243833, 18690884, 7777003, 1677744, 3189433,...   \n",
       "\n",
       "            inbound_citations_clear  outbound_citations_clear  \\\n",
       "paper_id                                                        \n",
       "199668001                        []                        []   \n",
       "2879234    [340420, 471907, 250792]  [215721, 127386, 392527]   \n",
       "17786914                         []          [398770, 299222]   \n",
       "17432300                   [467570]                  [371064]   \n",
       "204957502                        []                        []   \n",
       "...                             ...                       ...   \n",
       "127628365                        []                        []   \n",
       "11619477                         []                        []   \n",
       "5807289                          []                        []   \n",
       "15894398                         []                   [30582]   \n",
       "15895702                         []                  [251692]   \n",
       "\n",
       "                                              memes_in_cited  \n",
       "paper_id                                                      \n",
       "199668001                                                 []  \n",
       "2879234    [term, overall goal, numerous network activity...  \n",
       "17786914   [very good computational efficiency, training ...  \n",
       "17432300   [geometric consistency, correspondence, image,...  \n",
       "204957502                                                 []  \n",
       "...                                                      ...  \n",
       "127628365                                                 []  \n",
       "11619477                                                  []  \n",
       "5807289                                                   []  \n",
       "15894398   [pattern recognition, common process, abundanc...  \n",
       "15895702   [traditional neural network and regression mod...  \n",
       "\n",
       "[505000 rows x 11 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505000it [01:04, 7776.69it/s]\n"
     ]
    }
   ],
   "source": [
    "memes_in_cited = []\n",
    "#I want new column of unique noun chunks in all cited papers\n",
    "for i,paper in tqdm(df.iterrows()):\n",
    "    if paper['outbound_citations_clear'].size>0:\n",
    "        #only memes in cited papers:\n",
    "        c = df.iloc[paper['outbound_citations_clear']]['noun_chunks_cleaned']\n",
    "        \n",
    "        memes_in_cited.append(list(set(c.explode())))\n",
    "    else:\n",
    "        memes_in_cited.append(list(set()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['memes_in_cited']=memes_in_cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['memes_in_cited'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_id\n",
       "2879234     96\n",
       "17786914    99\n",
       "17432300    83\n",
       "62651912    32\n",
       "62653139    27\n",
       "            ..\n",
       "11301469    24\n",
       "53770387    48\n",
       "6048192     27\n",
       "15894398    28\n",
       "15895702    15\n",
       "Name: memes_in_cited, Length: 115089, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['memes_in_cited'] = df['memes_in_cited'].dropna().apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_memes = a.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'behavior tracking',\n",
       " 'new graph learn algorithm',\n",
       " 'standard svm',\n",
       " 'its possible morphological constituent',\n",
       " 'policy gradient technique',\n",
       " 'expand operating space',\n",
       " 'validity guide fuzzy cluster evaluation',\n",
       " 'fertilizer',\n",
       " 'coke oven gas collector coupling',\n",
       " 'multi channel sample',\n",
       " 'autonomy framework',\n",
       " 'interactive play',\n",
       " 'bpa',\n",
       " 'model free base ipd controller',\n",
       " 'phonetic control sequence',\n",
       " 'specific artificial neural network paradigm',\n",
       " 'generate index',\n",
       " 'real time and accuracy index',\n",
       " 'osana',\n",
       " 'pattern evaluation',\n",
       " 'fp cluster',\n",
       " 'hardware intellectual property',\n",
       " 'challenge toartificial intelligence',\n",
       " 'combustible chemical residue',\n",
       " 'significantly low perplexity',\n",
       " 'other assessment method',\n",
       " 'current lead automate va coding method',\n",
       " 'combustor component',\n",
       " 'particular source',\n",
       " 'only authentication',\n",
       " 'such demand application',\n",
       " 'adequate believable behavior',\n",
       " 'amateur skilled forgery',\n",
       " 'main influence factor',\n",
       " 'substantial information',\n",
       " 'new research line',\n",
       " 'ram base genetic algorithms',\n",
       " 'expect occurrence',\n",
       " 'sentient computer',\n",
       " 'vlsi implementation feasibility',\n",
       " 'small modeling error',\n",
       " 'tibetan',\n",
       " 'honey bee colony',\n",
       " 'evaluation performance',\n",
       " 'semiosis',\n",
       " 'information geometric explanation',\n",
       " 'various lung tissue type',\n",
       " 'extensive motion and shape feature',\n",
       " 'mpeg video',\n",
       " 'dynamic location specific learning strategy',\n",
       " 'namely the training datum',\n",
       " 'new de facto standard',\n",
       " 'massive momentum',\n",
       " 'relational datastructure',\n",
       " 'more time consumption',\n",
       " 'lenet nn',\n",
       " 'nncs',\n",
       " 'detailed campaign organization',\n",
       " 'blstm layer',\n",
       " 'optimization researcher',\n",
       " 'fine facial region extraction process',\n",
       " 'hysteresis nonlinearity',\n",
       " 'population base training',\n",
       " 'partial occlusion distortion',\n",
       " 'conditional random forest',\n",
       " 'propose text recognition architecture',\n",
       " 'region base and pixel base method',\n",
       " 'common center',\n",
       " 'many biomedical area',\n",
       " 'casia iris thousand',\n",
       " 'sincere concern',\n",
       " 'undesirable downtime',\n",
       " 'i datum compression',\n",
       " 'representative connect neuron',\n",
       " 'unique image',\n",
       " 'educational datum mining technique',\n",
       " 'only age',\n",
       " 'part fractals',\n",
       " 'expression extraction',\n",
       " 'facial contour landmark',\n",
       " 'strong independence',\n",
       " 'cyclist violation prediction model',\n",
       " 'functional pattern',\n",
       " 'cpu gpu architecture',\n",
       " 'suboptimal regression model',\n",
       " 'real world malware datum distribution',\n",
       " 'rentable infrastructure',\n",
       " 'spectroscopic and ion mobility investigation',\n",
       " 'mechanical force',\n",
       " 'different vegetation class',\n",
       " 'favorite part',\n",
       " 'essential milestone',\n",
       " 'adaptive relay',\n",
       " 'digital computers store data',\n",
       " 'general fuzzy min max neural network',\n",
       " 'equal influence',\n",
       " 'approachdata',\n",
       " 'topic specific and more specifically company specific sentiment analysis',\n",
       " 'translation scale and rotation independent feature',\n",
       " 'alternative algorithm',\n",
       " 'different detection mechanism',\n",
       " 'vision hou',\n",
       " 'datum parallel computing framework',\n",
       " 'government contract',\n",
       " 'viadodecaneso',\n",
       " 'just over a half',\n",
       " 'hand evaluation',\n",
       " 'epithelium',\n",
       " 'hence the future availability',\n",
       " 'bilingual education',\n",
       " 'mp svms',\n",
       " 'nn structure',\n",
       " 'other hybrid method',\n",
       " 'automate workplace',\n",
       " 'university degree',\n",
       " 'french space agency',\n",
       " 'trajectory attribute',\n",
       " 'finite temporal interval',\n",
       " 'more than rate',\n",
       " 'image retrieval problem',\n",
       " 'link failure history',\n",
       " 'fundamental objective',\n",
       " 'common availability',\n",
       " 'volcan de fuego',\n",
       " 'so call permutation problem',\n",
       " 'normal high grade squamous intraepithelial lesion',\n",
       " 'sandbox environment',\n",
       " 'photomask',\n",
       " 'reservoir computing framework',\n",
       " 'deep reservoir',\n",
       " 'such multi tiere architecture',\n",
       " 'design process model',\n",
       " 'startup company',\n",
       " 'ergonomic evaluation',\n",
       " 'statistical parity difference',\n",
       " 'good activity recognition accuracy',\n",
       " 'artificial neural network vision module',\n",
       " 'c base language',\n",
       " 'rich sensing capability',\n",
       " 'challenging pedestrian database',\n",
       " 'construct',\n",
       " 'psa',\n",
       " 'parallel distribute model',\n",
       " 'human and automatic speech processing',\n",
       " 'feature extraction algorithm',\n",
       " 'efficient context',\n",
       " 'blurred and shift response',\n",
       " 'overall energy consumption',\n",
       " 'world large',\n",
       " 'mlp neuralnetwork',\n",
       " 'csaga',\n",
       " 'constituent agent',\n",
       " 'glassdoor',\n",
       " 'scalable kernel',\n",
       " 'deadly condition',\n",
       " 'dictionary match',\n",
       " 'processof',\n",
       " 'additive type model',\n",
       " 'recursive least square rls algorithm',\n",
       " 'pathogeny',\n",
       " 'affine uncertain continuous time nonlinear system',\n",
       " 'lbf energy function',\n",
       " 'hierarchical salary',\n",
       " 'neighbor target',\n",
       " 'dynamic vagueness',\n",
       " 'automatic performance prediction',\n",
       " 'ensemble size',\n",
       " 'trace base simulation',\n",
       " 'decision ability',\n",
       " 'multistage classification scheme',\n",
       " 'cognitive system',\n",
       " 'last mean',\n",
       " 'static var',\n",
       " 'interactive frame rate',\n",
       " 'bh design',\n",
       " 'modify naive baye classifier',\n",
       " 'single training phase',\n",
       " 'surveillance epidemiology and end result seer database',\n",
       " 'detailed questionnaire',\n",
       " 'visual motion predictor',\n",
       " 'compute tomography technology',\n",
       " 'crop monitoring',\n",
       " 'swagger documentation page',\n",
       " 'various material',\n",
       " 'lesion segmentation',\n",
       " 'svm rfe base feature selection method technique',\n",
       " 'bound and non bound iteration',\n",
       " 'abp event',\n",
       " 'vital function',\n",
       " 'more disentangle latent representation',\n",
       " 'base admissible wavelet packet tree',\n",
       " 'simple reliable and easily applicable deep learning technique',\n",
       " 'well know radiological feature',\n",
       " 'distinct possibility',\n",
       " 'crossleyz',\n",
       " 'do yourself kit',\n",
       " 'manual updation process',\n",
       " 'isokinetic',\n",
       " 'scree test',\n",
       " 'tropical forest cover',\n",
       " 'locally competitive algorithm',\n",
       " 'vegetation map',\n",
       " 'necessary software stack',\n",
       " 'amazons',\n",
       " 'vector machine fitting method',\n",
       " 'query classification',\n",
       " 'network utilization',\n",
       " 'various physiological feature',\n",
       " 'photometric light curve',\n",
       " 'both the speech',\n",
       " 'road map vectorization',\n",
       " 'key regulatory conundrum',\n",
       " 'just communication',\n",
       " 'computer base learning environment',\n",
       " 'texture feature extraction method',\n",
       " 'nuclear astrophysics',\n",
       " 'natural language generation system',\n",
       " 'model base tracking system',\n",
       " 'complex traffic behavior',\n",
       " 'discrete time multi layered perceptron',\n",
       " 'movie genre',\n",
       " 'comparison attribute processor',\n",
       " 'gas sensor',\n",
       " 'highway driving',\n",
       " 'prompt identification',\n",
       " 'weizmann dataset',\n",
       " 'wrapper base technique',\n",
       " 'application specific criterion',\n",
       " 'passenger',\n",
       " 'mlpse environment',\n",
       " 'tangut character annotation',\n",
       " 'ai planning problem',\n",
       " 'indophigs',\n",
       " 'abstract structure',\n",
       " 'app relate metadata',\n",
       " 'discrimination rate',\n",
       " 'training and training performance',\n",
       " 'far more high quality paper',\n",
       " 'instead of the actual process sensitivity function',\n",
       " 'facial expression detection',\n",
       " 'proper preprocessing step',\n",
       " 'bansal',\n",
       " 'character code',\n",
       " 'related model',\n",
       " 'code base',\n",
       " 'space cd',\n",
       " 'recoding process',\n",
       " 'normal scene',\n",
       " 'advanced software development',\n",
       " 'reducible decomposition',\n",
       " 'selling price',\n",
       " 'network complexity',\n",
       " 'daily operation',\n",
       " 'additional resource allocation',\n",
       " 'unsupervised cluster algorithm',\n",
       " 'product manager',\n",
       " 'interactive map',\n",
       " 'valley search method',\n",
       " 'limited balanced wbcs dataset classification',\n",
       " 'proper use',\n",
       " 'simple function',\n",
       " 'structural language',\n",
       " 'well mental model',\n",
       " 'significant and challenging task',\n",
       " 'the training method',\n",
       " 'application performance',\n",
       " 'acceptable error rate',\n",
       " 'rich optimal bank',\n",
       " 'computer aid gie diagnostic system',\n",
       " 'finite time lyapunov stability',\n",
       " 'section iv',\n",
       " 'binary bof classifier',\n",
       " 'other physical instrument',\n",
       " 'more sophisticated one',\n",
       " 'or her game lifetime',\n",
       " 'source computer vision library',\n",
       " 'integrate fold cross validation and randomization test',\n",
       " 'relaxation search strategy',\n",
       " 'same vector',\n",
       " 'stenting',\n",
       " 'such attempt',\n",
       " 'language dependent dirichlet process gaussian mixture model',\n",
       " 'positive feedback loop',\n",
       " 'late xgboost approach',\n",
       " 'big datum concept',\n",
       " 'cardinal number',\n",
       " 'other datagram',\n",
       " 'print devanagari characters',\n",
       " 'joystick',\n",
       " 'effective approach',\n",
       " 'remarkable prediction accuracy',\n",
       " 'sfam artificial neural network technique',\n",
       " 'other image descriptor',\n",
       " 'non explicit feature base approach',\n",
       " 'food recognition',\n",
       " 'iceberg lattices',\n",
       " 'macaque lateral geniculate nucleus',\n",
       " 'area overlap and migration pattern',\n",
       " 'small hyper cube',\n",
       " 'employee presence',\n",
       " 'individual contributor',\n",
       " 'event database',\n",
       " 'both temporal and textual information',\n",
       " 'neural base recognition',\n",
       " 'radio coverage area',\n",
       " 'neural state computation',\n",
       " 'csr activity',\n",
       " 'recall capacity',\n",
       " 'biological organism',\n",
       " 'proactive intervention',\n",
       " 'user facial image',\n",
       " 'flat detector ct perfusion',\n",
       " 'redundant weight',\n",
       " 'tweet behavior',\n",
       " 'arima',\n",
       " 'most popular task',\n",
       " 'computer science and artificial intelligence university',\n",
       " 'suitable pende duration',\n",
       " 'theoretical and practical issue',\n",
       " 'compact hide node',\n",
       " 'pass algorithm gmplan',\n",
       " 'international community',\n",
       " 'skin region',\n",
       " 'time dependent hebbian rule',\n",
       " 'classifier generation',\n",
       " 'character numeral image',\n",
       " 'linguistic label',\n",
       " 'llaima volcano',\n",
       " 'pitch synchronous analysis',\n",
       " 'simple statistical test',\n",
       " 'non asymptotic analysis',\n",
       " 'feedforward neural network algorithm',\n",
       " 'class classifiers',\n",
       " 'object side dimension',\n",
       " 'lymphoma cancer dataset',\n",
       " 'delay line model',\n",
       " 'the empirical approach',\n",
       " 'deep ecg',\n",
       " 'propose segmentation',\n",
       " 'using platform specific performance counters',\n",
       " 'stateless function',\n",
       " 'implant electrode',\n",
       " 'problematic notion',\n",
       " 'ias',\n",
       " 'bea area',\n",
       " 'vehicle mount point',\n",
       " 'various limitation',\n",
       " 'telecommunication software',\n",
       " 'highly variable object',\n",
       " 'possible controller singularity problem',\n",
       " 'far conduct fusion',\n",
       " 'ir experiment',\n",
       " 'reaction diffusion mechanism',\n",
       " 'language independent module',\n",
       " 'bionic humanoid system',\n",
       " 'active and interactive learning mechanism',\n",
       " 'effective cause',\n",
       " 'nonlinear learning capability',\n",
       " 'baghera',\n",
       " 'wsvm',\n",
       " 'high precision sensor',\n",
       " 'coordinate measure machine',\n",
       " 'propose channel weighting',\n",
       " 'modern solver technology',\n",
       " 'dateness',\n",
       " 'non trivial application',\n",
       " 'general classification method',\n",
       " 'multimodal joint representation',\n",
       " 'model embed feature selection',\n",
       " 'most successful approach',\n",
       " 'fuzzy memoization',\n",
       " 'rapid evolution',\n",
       " 'particular',\n",
       " 'ir',\n",
       " 'main material',\n",
       " 'unlimited information',\n",
       " 'heart electrical conduction system',\n",
       " 'emotion lexicon',\n",
       " 'specific spoof attack',\n",
       " 'agile sensor proceed',\n",
       " 'cross validation area',\n",
       " 'distribute self repair capability',\n",
       " 'late discovery',\n",
       " 'abstract latent fingerprint',\n",
       " 'music industry',\n",
       " 'individual image sequence',\n",
       " 'embed base evd distance',\n",
       " 'demand response period',\n",
       " 'music lyric',\n",
       " 'propose representation learning framework',\n",
       " 'sale process',\n",
       " 'first collection',\n",
       " 'certain universality',\n",
       " 'intensity estimation',\n",
       " 'find specify ancestor algorithm',\n",
       " 'qt correction',\n",
       " 'full parameter space',\n",
       " 'neuroprosthesis',\n",
       " 'share sketch algorithm',\n",
       " 'external datum set',\n",
       " 'clp framework',\n",
       " 'successive image sequence',\n",
       " 'over an hour',\n",
       " 'stochastic neural net',\n",
       " 'application installment',\n",
       " 'burman matrices',\n",
       " 'spatiotemporal pattern',\n",
       " 'hybrid feature method',\n",
       " 'component placement',\n",
       " 'maximum flow',\n",
       " 'well structure dataset',\n",
       " 'try and true technique',\n",
       " 'attr system',\n",
       " 'high level automatic visual recognition',\n",
       " 'frequency domain commonality',\n",
       " 'few or no work',\n",
       " 'histological grade classiﬁcation',\n",
       " 'batch way',\n",
       " 'molecular study',\n",
       " 'physiological and physical sensor response signal',\n",
       " 'schulz and sommerville datum',\n",
       " 'many researcher community',\n",
       " 'eye condition',\n",
       " 'nonsmooth problem',\n",
       " 'slow dynamic',\n",
       " 'more advanced problem',\n",
       " 'noise power spectrum',\n",
       " 'several module',\n",
       " 'wavelet domain independent mixture model',\n",
       " 'satisfie jerk restraint',\n",
       " 'non tax revenue case study',\n",
       " 'february month',\n",
       " 'the long tail',\n",
       " 'cascade network',\n",
       " 'digital intangible cultural heritage development',\n",
       " 'network communication and road layout',\n",
       " 'dimension complex',\n",
       " 'new fog computing base e healthcare framework',\n",
       " 'dimensionality reduction first layer',\n",
       " 'signing process',\n",
       " 'weld seam',\n",
       " 'very small computational compexity',\n",
       " 'rtl convolutional neural network accelerator design',\n",
       " 'preface planning',\n",
       " 'significant uncertainty',\n",
       " 'pitch detection',\n",
       " 'polypropylene melt index',\n",
       " 'second category',\n",
       " 'domain adaptation',\n",
       " 'complex statistical experiment',\n",
       " 'mojo',\n",
       " 'convex relaxation',\n",
       " 'adequate alternative text',\n",
       " 'mvnos',\n",
       " 'single large associative memory',\n",
       " 'undecimated wavelet transform',\n",
       " 'simple design',\n",
       " 'linear inequality',\n",
       " 'other speaker',\n",
       " 'back propagation training algorithm',\n",
       " 'inflate gaussian process',\n",
       " 'gst',\n",
       " 'current clustering base segmentation method',\n",
       " 'spatial preposition',\n",
       " 'auc',\n",
       " 'user nose',\n",
       " 'functional brain mapping',\n",
       " 'apply task solution code',\n",
       " 'catecholamine',\n",
       " 'ndo error',\n",
       " 'chow rule',\n",
       " 'non contrast image',\n",
       " 'label score',\n",
       " 'similarity index',\n",
       " 'stiff inclusion',\n",
       " 'new learning model',\n",
       " 'negative hc cone feedback pathway',\n",
       " 'riguzzi',\n",
       " 'usable information',\n",
       " 'analytic algorithm',\n",
       " 'hundred of million',\n",
       " 'interdependent deep model',\n",
       " 'motion planing problem',\n",
       " 'competitive approach',\n",
       " 'subsequent viewpoint',\n",
       " 'traditional anomaly base detection method',\n",
       " 'model power',\n",
       " 'rather different problem',\n",
       " 'icse',\n",
       " 'such configuration knowledge',\n",
       " 'fully connected and recurrent neural network architecture',\n",
       " 'opponent strategy',\n",
       " 'even first order logic',\n",
       " 'date sample',\n",
       " 'well equip it centre',\n",
       " 'same network',\n",
       " 'similar code structure',\n",
       " 'smart datum collection process',\n",
       " 'fall rate',\n",
       " 'good gist feature extraction parameter',\n",
       " 'shot segmentation',\n",
       " 'ndo',\n",
       " 'many fact',\n",
       " 'drone hit',\n",
       " 'many function evaluation',\n",
       " 'industrial world',\n",
       " 'pn',\n",
       " 'identify sequence',\n",
       " 'most popular classificasion',\n",
       " 'large oscillation',\n",
       " 'morphological characteristic rr interval and beat to beat correlation feature',\n",
       " 'business location selection',\n",
       " 'infrared focal plane array',\n",
       " 'a review',\n",
       " 'arithmetic word',\n",
       " 'sprint',\n",
       " 'glcm parameter',\n",
       " 'thrun',\n",
       " 'bilingual transformation matrix',\n",
       " 'physical interconnect',\n",
       " 'approximate reasoning scheme',\n",
       " 'internal database',\n",
       " 'pytorch platform',\n",
       " 'forest backscatter variability',\n",
       " 'nnpim',\n",
       " 'integrated processing',\n",
       " 'kolmogorov complexity theory',\n",
       " 'logistic unit',\n",
       " 'input distribution',\n",
       " 'software library',\n",
       " 'mmds',\n",
       " 'unary term',\n",
       " 'third objective',\n",
       " 'layer narx network',\n",
       " 'indispensable dimension',\n",
       " 'ii discourse drive construction',\n",
       " 'backbone feature network',\n",
       " 'low memory requirement',\n",
       " 'namely the precise setting',\n",
       " 'summer session',\n",
       " 'low population density region',\n",
       " 'memory switch',\n",
       " 'more biological dynamic',\n",
       " 'natural algorithm',\n",
       " 'phase congruency concept',\n",
       " 'user choice',\n",
       " 'how different image search intent',\n",
       " 'expressive and context aware recommender system',\n",
       " 'space environment',\n",
       " 'znn',\n",
       " 'clusterix simulation',\n",
       " 'same or even well correct classification result',\n",
       " 'synonymy',\n",
       " 'consistently high accuracy',\n",
       " 'nist database',\n",
       " 'order n tree',\n",
       " 'advanced manufacturing systems',\n",
       " 'pixel calibration',\n",
       " 'computing and drawing maxmin height covering triangulation',\n",
       " 'early blight',\n",
       " 'automatic pain estimation',\n",
       " 'autonomous decrease',\n",
       " 'recently develop machine learn technique',\n",
       " 'well than classification accuracy',\n",
       " 'current method',\n",
       " 'slice wise character',\n",
       " 'aces',\n",
       " 'load datum',\n",
       " 'human sort experiment',\n",
       " 'diagnosis inaccuracy',\n",
       " 'temperature field',\n",
       " 'improve adaboost algorithm',\n",
       " 'separate speaker code',\n",
       " 'unnecessary element',\n",
       " 'energy management system',\n",
       " 'giscientist',\n",
       " 'perceptrons',\n",
       " 'reconfigurable software architecture',\n",
       " 'tradeoff study',\n",
       " 'category independent object detection task',\n",
       " 'many consumer need',\n",
       " 'modulation recognition system',\n",
       " 'cosine similarity algorithm',\n",
       " 'also other picture reclamation',\n",
       " 'specific problem',\n",
       " 'rejection method',\n",
       " 'serotonin',\n",
       " 'specialized embed technique',\n",
       " 'solid boronizing',\n",
       " 'exact mutual influence',\n",
       " 'generic block',\n",
       " 'healthy and secure network operation environment',\n",
       " 'newly publish scientific article',\n",
       " 'leading indicator',\n",
       " 'nave bayes nb classifier',\n",
       " 'forward kinematic base layer',\n",
       " 'big global challenge',\n",
       " 'cauchy distribution',\n",
       " 'quotient trace formulation',\n",
       " 'driver safety',\n",
       " 'domain adaptation experiment',\n",
       " 'gpu computation',\n",
       " 'excellent environment',\n",
       " 'dictionary learning framework',\n",
       " 'the implement filter',\n",
       " 'more than contact',\n",
       " 'thorough characterization',\n",
       " 'uncertain and ever change ground truth',\n",
       " 'anesthetics',\n",
       " 'operating flow regime',\n",
       " 'more complete edge contour',\n",
       " 'grid shape model',\n",
       " 'fox et al',\n",
       " 'speaker independent isolate word speech recognition system',\n",
       " 'historical record',\n",
       " 'namely regression model',\n",
       " 'irreversible disability',\n",
       " 'existence condition',\n",
       " 'different client',\n",
       " 'actual scene',\n",
       " 'multi region neural network',\n",
       " 'other rival optimizer',\n",
       " 'synchronous asynchronous and frequency offset condition',\n",
       " 'psychology research',\n",
       " 'specific domain knowledge',\n",
       " 'optical measurement equipment',\n",
       " 'and a channel optical sensor',\n",
       " 'current output',\n",
       " 'smart city ict solution',\n",
       " 'acoustic scene classification',\n",
       " 'continuous action',\n",
       " 'very aim',\n",
       " 'functional independent measurement',\n",
       " 'original ransac algorithm',\n",
       " 'manual insertion',\n",
       " 'multivariate analysis',\n",
       " 'gabor wavelet filter',\n",
       " 'near regular texture',\n",
       " 'feedforward ann',\n",
       " 'feature characteristic',\n",
       " 'hamming space',\n",
       " 'management and security analysis',\n",
       " 'rudimentary concept',\n",
       " 'user access',\n",
       " 'traditional medoid algorithm',\n",
       " 'network embedding',\n",
       " 'text meaning',\n",
       " 'exam timetabling problem',\n",
       " 'total laryngectomy',\n",
       " 'accurate location information',\n",
       " 'traditional discriminative',\n",
       " 'automatic device control',\n",
       " 'centriod',\n",
       " 'fiss',\n",
       " 'link coefficient',\n",
       " 'learning analytic paradigm',\n",
       " 'full attribute set and select attribute set',\n",
       " 'heavy cost',\n",
       " 'different unsupervised learning algorithm',\n",
       " 'multi relational datum mining',\n",
       " 'key performance indicator',\n",
       " 'ttg',\n",
       " 'common component',\n",
       " 'multichannel speech enhancement technique',\n",
       " 'multiclass classification scenario',\n",
       " 'i ambiguity',\n",
       " 'previous research effort',\n",
       " 'scalable datum drive approach',\n",
       " 'tensor product b spline',\n",
       " 'tree vector',\n",
       " 'feature engineering and signal monitoring',\n",
       " 'broad coverage',\n",
       " 'c e',\n",
       " 'ep discriminability',\n",
       " 'chest ct scan',\n",
       " 'fourth florida ai research symposium',\n",
       " 'qrs time series',\n",
       " 'bit adaptive activation',\n",
       " 'such datum sparsity',\n",
       " 'designer experience',\n",
       " 'generative shape modeling',\n",
       " 'preconditioner',\n",
       " 'hence there have recently be increase effort',\n",
       " 'automatic web service composition',\n",
       " 'poor datum basis',\n",
       " 'vital tool',\n",
       " 'top level performance',\n",
       " 'student digital competence',\n",
       " 'strong power',\n",
       " 'inter disciplinary field',\n",
       " 'english speech',\n",
       " 'an objectivistic epistemology',\n",
       " 'conf scale space',\n",
       " 'wellknown measure',\n",
       " 'control network',\n",
       " 'vlsi or rf mmic',\n",
       " 'subarea',\n",
       " 'unascertained svr measure',\n",
       " 'tv optical flow algorithm',\n",
       " 'enable mean',\n",
       " 'pyramid layer',\n",
       " 'term metaplasticity',\n",
       " 'current brain computer interface bci study',\n",
       " 'binary segmentation',\n",
       " 'sign network',\n",
       " 'networked manufacturing',\n",
       " 'traditional dimensionality reduction method',\n",
       " 'influence signal',\n",
       " 'inertia navigation system',\n",
       " 'optical distance',\n",
       " 'novel scalable and efficient technique',\n",
       " 'difficult prolblem',\n",
       " 'so call waveform base method',\n",
       " 'pitch relate cue',\n",
       " 'smart home environment',\n",
       " 'top label',\n",
       " 'multi mode matrix multiplication module',\n",
       " 'convenient graphical user interface',\n",
       " 'conditional execution approach',\n",
       " 'practical convergence',\n",
       " 'volumetric object',\n",
       " 'new sparse',\n",
       " 'static algorithm sasepa',\n",
       " 'critical generalization aspect',\n",
       " 'potential quality problem',\n",
       " 'expect reduction',\n",
       " 'complex password combination',\n",
       " 'different adaptation technique',\n",
       " 'f micro',\n",
       " 'minimal rectangular subset',\n",
       " 'such achievement',\n",
       " 'advisor',\n",
       " 'quantitatively local image descriptor',\n",
       " 'intrinsic and extrinsic evaluation',\n",
       " 'association rule learn algorithm',\n",
       " 'information processing method',\n",
       " 'excellent convergence property',\n",
       " 'how computing and network resource',\n",
       " 'multi rate network',\n",
       " 'ontology extension procedure',\n",
       " 'ong',\n",
       " 'real brain neuron',\n",
       " 'remote datum processing site',\n",
       " 'soccer game',\n",
       " 'low quality picture',\n",
       " 'complex scheme',\n",
       " 'physical task',\n",
       " 'similar and dissimilar patch',\n",
       " 'adaptive node and polynomial shape function refinement',\n",
       " 'browser microarchitectural footprint',\n",
       " 'address event output',\n",
       " 'evolved micro',\n",
       " 'wind perturbation',\n",
       " 'geodesic distance',\n",
       " 'popular datum mining technique',\n",
       " 'inherent weakness',\n",
       " 'parallel greedy metaheuristic algorithm',\n",
       " 'fuzzy cluster analysis model',\n",
       " 'fetal fmri',\n",
       " 'correction strategy',\n",
       " 'rectangle blanket problem',\n",
       " 'grow datum dimensionality',\n",
       " 'joint feature space',\n",
       " 'pair significance test',\n",
       " 'interactive image recognition',\n",
       " 'database normalization debt',\n",
       " 'current solution',\n",
       " 'non overlapping segment region',\n",
       " 'taiwan cancer registry',\n",
       " 'swarm base multi agent system',\n",
       " 'meaningful segmentation',\n",
       " 'fraudulent datum',\n",
       " 'mosaic performance',\n",
       " 'error integral term',\n",
       " 'hide layer architecture',\n",
       " 'novel ssl model',\n",
       " 'almost any kind',\n",
       " 'and training datum',\n",
       " 'accurate pattern',\n",
       " 'extensive performance evaluation',\n",
       " 'multiple kaplan meier curve',\n",
       " 'driving safety',\n",
       " 'very useful fault diagnosis method',\n",
       " 'fully programmable solution',\n",
       " 'manhole cover object detection',\n",
       " 'multi agent learning model',\n",
       " 'task base description',\n",
       " 'enough computational power',\n",
       " 'abstract spiking neural networks',\n",
       " 'probe feature',\n",
       " 'propose feature extraction process',\n",
       " 'hcv',\n",
       " 'pattern matching method',\n",
       " 'high spectral purity',\n",
       " 'predefine color object',\n",
       " 'jdn',\n",
       " 'reverse cad engineering',\n",
       " 'most common specie',\n",
       " 'additional learning and relearn optoelectronic pnn',\n",
       " 'multi neural network',\n",
       " 'computer vision mapping image',\n",
       " 'propose associative classifier',\n",
       " 'rsnets',\n",
       " 'namely alzheimer disease ad',\n",
       " 'probe attack class',\n",
       " 'miss event',\n",
       " 'disease effect',\n",
       " 'request permission',\n",
       " 'active feed roll length',\n",
       " 'safety point',\n",
       " 'weight laplace beltrami operator',\n",
       " 'non convex set',\n",
       " 'subject independent decoding',\n",
       " 'fuzzy and rule based system technique',\n",
       " 'predictive uncertainty estimate',\n",
       " 'traditional difficulty adjustment',\n",
       " 'rich bridge',\n",
       " 'simulate scattering',\n",
       " 'fashion landmark detection',\n",
       " 'software ontology',\n",
       " 'entire meta hierarchy',\n",
       " 'chemical feature',\n",
       " 'promise strategy',\n",
       " 'infrared small target detection',\n",
       " 'follow web site',\n",
       " 'property management',\n",
       " 'optimal gene set',\n",
       " 'differential absorption spectroscopy',\n",
       " 'sam ple',\n",
       " 'mixed information',\n",
       " 'miccai liver segmentation challenge',\n",
       " 'noc system',\n",
       " 'similar ligand',\n",
       " 'leaky integrator',\n",
       " 'most challenging work',\n",
       " 'step change',\n",
       " 'linear and non linear transformation',\n",
       " 'morphing',\n",
       " 'nda',\n",
       " 'spike timing dependent plasticity',\n",
       " 'colour texture image',\n",
       " 'increasingly large volume',\n",
       " 'adversarial situation',\n",
       " 'configurational energy barrier',\n",
       " 'intermolecular hydrophobic interaction',\n",
       " 'important module',\n",
       " 'training technique',\n",
       " 'noisy image processing',\n",
       " 'coordinate conversion',\n",
       " 'chinese cloze test',\n",
       " 'destination queue tracking target',\n",
       " 'misc',\n",
       " 'novel gene gene interaction pattern',\n",
       " 'multi layer perceptron type',\n",
       " 'resemble over fit training method',\n",
       " 'content and structure posfilter',\n",
       " 'several research issue',\n",
       " 'fluid composition',\n",
       " 'xilinx zynq platform',\n",
       " 'production host',\n",
       " 'minimum perceptible color',\n",
       " 'learn site correlation',\n",
       " 'an objective function',\n",
       " 'paper machine control system',\n",
       " 'face feature extraction',\n",
       " 'develop device',\n",
       " 'relate parameter',\n",
       " 'salamander',\n",
       " 'feedforward type',\n",
       " 'centimetre level accuracy',\n",
       " 'client server base system',\n",
       " 'multiple data partition',\n",
       " 'signal strength',\n",
       " 'voting',\n",
       " 'instantaneous edge detection and motion tracking result',\n",
       " 'algorithm ideal',\n",
       " 'googlenet model',\n",
       " 'same linear subspace',\n",
       " 'human silhouette blob',\n",
       " 'augmented relational algebra',\n",
       " 'other userid',\n",
       " 'tunisian user status',\n",
       " 'model design',\n",
       " 'hyperemia',\n",
       " 'tehnique',\n",
       " 'intelligent sorting system',\n",
       " 'multi attribute graph model',\n",
       " 'transpose memory requirement',\n",
       " 'secant',\n",
       " 'combined loss function leverage',\n",
       " 'information extraction discovery task',\n",
       " 'membership group',\n",
       " 'multimodal environmental datum',\n",
       " 'serious game technology',\n",
       " 'the visitor opinion',\n",
       " 'recurrent q learn method',\n",
       " 'work efficient',\n",
       " 'robotic dance pose',\n",
       " 'bpr standard',\n",
       " 'customer marketing period',\n",
       " 'dynamical uncertainty',\n",
       " 'individual waveform',\n",
       " 'noise contamination',\n",
       " 'complicated spatial pattern optimization problem',\n",
       " 'complex representation',\n",
       " 'ebrowser',\n",
       " 'tractable manner',\n",
       " 'icdar robust reading datum',\n",
       " 'aeronautic',\n",
       " 'more appropriate measure',\n",
       " 'new manufacturing environment',\n",
       " 'vital target segment',\n",
       " 'wooden material',\n",
       " 'classification domain',\n",
       " 'their topological feature',\n",
       " 'iot system',\n",
       " 'bit single precision floatingpoint number',\n",
       " 'detect static object',\n",
       " 'snowflake',\n",
       " 'texture measurement',\n",
       " 'reflective optic spectrographic imaging system',\n",
       " 'card sort task',\n",
       " 'consumer credit datum',\n",
       " 'symbolic reasoning',\n",
       " 'static activity',\n",
       " 'semi supervised learning base computational model',\n",
       " 'geospatial data base traffic forecasting problem',\n",
       " 'pretrained wfst',\n",
       " 'sgrnas',\n",
       " 'nonlinear muscle unit',\n",
       " 'mortality',\n",
       " 'novel neural network pairwise interaction field',\n",
       " 'complementary nature',\n",
       " 'synthetic source domain',\n",
       " 'hospital resource management',\n",
       " 'fundamental difference',\n",
       " 'several statistical test',\n",
       " 'multiple random artificial neural network ann model',\n",
       " 'dispute',\n",
       " 'accurate and reliable informative datum',\n",
       " 'use case precondition',\n",
       " 'transmit string x',\n",
       " 'nature neurosci',\n",
       " 'lbp',\n",
       " 'many reader',\n",
       " 'good detection performance',\n",
       " 'virtual community',\n",
       " 'non invasive method',\n",
       " 'global post processing module',\n",
       " 'multiagent systems famas workshop series',\n",
       " 'base physichemical',\n",
       " 'health pattern',\n",
       " 'histogram base image segmentation',\n",
       " 'data augmentation method',\n",
       " 'babool',\n",
       " 'medical balanced training datum',\n",
       " 'relatively high variation',\n",
       " 'information fusion process',\n",
       " 'very crucial role',\n",
       " 'following sense',\n",
       " 'persian sa recognition',\n",
       " 'orthogonal and compactly support function',\n",
       " 'human operate system',\n",
       " 'mvno profit',\n",
       " 'well know statistical model',\n",
       " 'knowledge dissemination',\n",
       " 'longitudinal model',\n",
       " 'individual effort',\n",
       " 'adaboost ensemble classifier',\n",
       " 'fully connect network',\n",
       " 'security assessment',\n",
       " 'iso compliance',\n",
       " 'expert interpretation',\n",
       " 'slack utilization',\n",
       " 'pedcc loss',\n",
       " 'ml base framework',\n",
       " 'different snr and operating condition',\n",
       " 'few effort',\n",
       " 'semantic syntactic and lexical information',\n",
       " 'machine learning relevance function',\n",
       " 'unseen configuration',\n",
       " 'next model',\n",
       " 'jaffe database',\n",
       " 'path integration subsystem',\n",
       " 'continuous time hopfield network',\n",
       " 'various training point',\n",
       " 'stochastic ot',\n",
       " 'minimum run time computational overhead',\n",
       " 'user generate narrative element',\n",
       " 'closed loop control algorithm',\n",
       " 'microscopical image',\n",
       " 'new edge base memory system',\n",
       " 'result state trajectory',\n",
       " 'session border controller',\n",
       " 'interbeat rr interval analysis',\n",
       " 'south pacific region',\n",
       " 'spatial spectral temporal subspace',\n",
       " 'reduce mixture set',\n",
       " 'good and bad partition',\n",
       " ...}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_memes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\getlimits.py:516\u001b[0m, in \u001b[0;36miinfo.__init__\u001b[1;34m(self, int_type)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m numeric\u001b[39m.\u001b[39;49mdtype(int_type)\n\u001b[0;32m    517\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\notebooks\\pk\\meme_score.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/notebooks/pk/meme_score.ipynb#ch0000049?line=0'>1</a>\u001b[0m c_enc \u001b[39m=\u001b[39m MultiLabelBinarizer(sparse_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/notebooks/pk/meme_score.ipynb#ch0000049?line=1'>2</a>\u001b[0m cited_memes_enc \u001b[39m=\u001b[39m c_enc\u001b[39m.\u001b[39;49mfit_transform(a)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:794\u001b[0m, in \u001b[0;36mMultiLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    792\u001b[0m class_mapping \u001b[39m=\u001b[39m defaultdict(\u001b[39mint\u001b[39m)\n\u001b[0;32m    793\u001b[0m class_mapping\u001b[39m.\u001b[39mdefault_factory \u001b[39m=\u001b[39m class_mapping\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m\n\u001b[1;32m--> 794\u001b[0m yt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(y, class_mapping)\n\u001b[0;32m    796\u001b[0m \u001b[39m# sort classes and reorder columns\u001b[39;00m\n\u001b[0;32m    797\u001b[0m tmp \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(class_mapping, key\u001b[39m=\u001b[39mclass_mapping\u001b[39m.\u001b[39mget)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:880\u001b[0m, in \u001b[0;36mMultiLabelBinarizer._transform\u001b[1;34m(self, y, class_mapping)\u001b[0m\n\u001b[0;32m    875\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    876\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39munknown class(es) \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m will be ignored\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39msorted\u001b[39m(unknown, key\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m))\n\u001b[0;32m    877\u001b[0m     )\n\u001b[0;32m    878\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(indices), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n\u001b[1;32m--> 880\u001b[0m \u001b[39mreturn\u001b[39;00m sp\u001b[39m.\u001b[39;49mcsr_matrix(\n\u001b[0;32m    881\u001b[0m     (data, indices, indptr), shape\u001b[39m=\u001b[39;49m(\u001b[39mlen\u001b[39;49m(indptr) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, \u001b[39mlen\u001b[39;49m(class_mapping))\n\u001b[0;32m    882\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_compressed.py:65\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     maxval \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(shape)\n\u001b[1;32m---> 65\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype((indices, indptr),\n\u001b[0;32m     66\u001b[0m                             maxval\u001b[39m=\u001b[39;49mmaxval,\n\u001b[0;32m     67\u001b[0m                             check_contents\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indices, copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m     70\u001b[0m                         dtype\u001b[39m=\u001b[39midx_dtype)\n\u001b[0;32m     71\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(indptr, copy\u001b[39m=\u001b[39mcopy, dtype\u001b[39m=\u001b[39midx_dtype)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\_sputils.py:153\u001b[0m, in \u001b[0;36mget_index_dtype\u001b[1;34m(arrays, maxval, check_contents)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_index_dtype\u001b[39m(arrays\u001b[39m=\u001b[39m(), maxval\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_contents\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    132\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    Based on input (integer) arrays `a`, determine a suitable index data\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    type that can hold the data in the arrays.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \n\u001b[0;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     int32min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49miinfo(np\u001b[39m.\u001b[39;49mint32)\u001b[39m.\u001b[39mmin\n\u001b[0;32m    154\u001b[0m     int32max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax\n\u001b[0;32m    156\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mintc\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\getlimits.py:518\u001b[0m, in \u001b[0;36miinfo.__init__\u001b[1;34m(self, int_type)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m numeric\u001b[39m.\u001b[39mdtype(int_type)\n\u001b[0;32m    517\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m=\u001b[39m numeric\u001b[39m.\u001b[39;49mdtype(\u001b[39mtype\u001b[39;49m(int_type))\n\u001b[0;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind\n\u001b[0;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize \u001b[39m*\u001b[39m \u001b[39m8\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "c_enc = MultiLabelBinarizer(sparse_output=True)\n",
    "cited_memes_enc = c_enc.fit_transform(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parquet ilości noun chunków "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_memes_enc_cleaned = cited_memes_enc[:,memes_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3883767 [00:11<2498:41:11,  2.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ppaul\\Documents\\AI-strategies-papers-regulations-monitoring\\data\\s2orc\\meme_score.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=10'>11</a>\u001b[0m \u001b[39m#does it cite meme carrers?\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=11'>12</a>\u001b[0m c_spark \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39moutbound_citations_clear\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(\u001b[39many\u001b[39m(df[c][\u001b[39m'\u001b[39m\u001b[39mpaper_id\u001b[39m\u001b[39m'\u001b[39m]),regex\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=12'>13</a>\u001b[0m c_stick \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mdf[\u001b[39m'\u001b[39;49m\u001b[39moutbound_citations_clear\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(\u001b[39many\u001b[39;49m(df[c][\u001b[39m'\u001b[39;49m\u001b[39mpaper_id\u001b[39;49m\u001b[39m'\u001b[39;49m]),regex\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=15'>16</a>\u001b[0m p_spark1\u001b[39m.\u001b[39mappend((c_spark\u001b[39m&\u001b[39mc)\u001b[39m.\u001b[39msum())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ppaul/Documents/AI-strategies-papers-regulations-monitoring/data/s2orc/meme_score.ipynb#ch0000012?line=16'>17</a>\u001b[0m p_spark2\u001b[39m.\u001b[39mappend(c_spark\u001b[39m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:125\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 125\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:1222\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[0;32m   1215\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1216\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1217\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1218\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1219\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1220\u001b[0m     )\n\u001b[1;32m-> 1222\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_contains(pat, case, flags, na, regex)\n\u001b[0;32m   1223\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result, fill_value\u001b[39m=\u001b[39mna, returns_string\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:131\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m    129\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n\u001b[0;32m    130\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: upper_pat \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mupper()\n\u001b[1;32m--> 131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_map(f, na, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:71\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[1;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[0;32m     69\u001b[0m map_convert \u001b[39m=\u001b[39m convert \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(mask)\n\u001b[0;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer_mask(arr, f, mask\u001b[39m.\u001b[39;49mview(np\u001b[39m.\u001b[39;49muint8), map_convert)\n\u001b[0;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m     73\u001b[0m     \u001b[39m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[39m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     p_err \u001b[39m=\u001b[39m (\n\u001b[0;32m     76\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m((takes)|(missing)) (?(2)from \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ to )?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     77\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?(3)required )positional arguments?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     78\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2822\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ppaul\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\strings\\object_array.py:127\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39mif\u001b[39;00m case:\n\u001b[1;32m--> 127\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: pat \u001b[39min\u001b[39;00m x\n\u001b[0;32m    128\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.2 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/ppaul/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#instead: two oneHotEncodings. First: which memes appear in paper. Second: which  memes appear in cited papers.\n",
    "#p_spark 1: sum in papers axis of all ones of ohe1&ohe2.\n",
    "#meme axis=0, papers axis=1\n",
    "\n",
    "cited_memes_enc_cleaned.sum(axis=1)\n",
    "(1-cited_memes_enc_cleaned).sum(axis=1)\n",
    "cited_memes_enc_cleaned.multiply(memes_enc_cleaned).sum(axis=1)\n",
    "(1-cited_memes_enc_cleaned).multiply(memes_enc_cleaned).sum(axis=1)\n",
    "\n",
    "p_spark1 = []\n",
    "p_spark2 = []\n",
    "p_stick1 = []\n",
    "p_stick2 = []\n",
    "for key in tqdm(memes):\n",
    "    #does it have meme? in OneHot: memes_enc\n",
    "    c = df['noun_chunks_cleaned'].str.contains(key,regex=False)\n",
    "    #does it cite meme carrers? in OneHot: all memes in citated\n",
    "    c_spark = df['outbound_citations_clear'].str.contains(any(df[c]['paper_id']),regex=False)\n",
    "    c_stick = ~c_spark\n",
    "    \n",
    "\n",
    "    p_spark1.append((c_spark&c).sum())\n",
    "    p_spark2.append(c_spark.sum())\n",
    "    p_stick1.append((c_stick&c).sum())\n",
    "    p_stick2.append(c_stick.sum())\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48536d2addd9b85fce61b04465bb4b1e3e0a9d63a5655648dae3d18ba979ab51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
