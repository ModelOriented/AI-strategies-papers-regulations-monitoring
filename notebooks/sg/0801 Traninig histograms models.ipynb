{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../..\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from mars.models_training import data_loading\n",
    "from mars.models_training.notebook_helpers import evaluate\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from mars.models_training import document_level_similarity_search\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X, y = data_loading.load_document_level_issues_dataset(data_loading.DocumenLevelDataset.ethics_ai_ethics, \"laser\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_labels = pd.read_csv('data/labels_hagendorffEthicsAIEthics2020.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_max = list(map(max, X_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate(X_max, y_test)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def bucketize(scores, bins):\n",
    "    return np.stack([np.histogram(x, range=(-1, 1), bins=bins)[0] for x in scores])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import RFE,RFECV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "buckets_num = 250\n",
    "\n",
    "model = document_level_similarity_search.model\n",
    "model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = document_level_similarity_search.model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_train)[:, 1]\n",
    "evaluate(y_pred, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2 = document_level_similarity_search.model_with_normalization\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred = model2.predict_proba(X_train)[:, 1]\n",
    "evaluate(y_pred, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "buckets_num = 250\n",
    "\n",
    "model3 =  document_level_similarity_search.model_with_normalization_rfe\n",
    "model3.set_params(bucketize__kw_args = {'bins': buckets_num})\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred = model3.predict_proba(X_train)[:, 1]\n",
    "evaluate(y_pred, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "param_grid = {\n",
    "    \"rfe__n_features_to_select\": list(range(10,101,5)),\n",
    "    \"bucketize__kw_args\":[{\"bins\":int(n)} for n in np.linspace(50,400,num=40)]\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "cv = RandomizedSearchCV(model3, param_grid, scoring=\"roc_auc\",n_jobs=-1, verbose=1, n_iter=150)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_model = cv.best_estimator_\n",
    "cv.best_score_, cv.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = best_model.predict_proba(X_train)[:, 1]\n",
    "evaluate(y_pred, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = best_model.predict_proba(X_test)[:, 1]\n",
    "evaluate(y_pred, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(best_model, open(\"models/ethics_ai_ethics_laser_model.pkl\", \"wb\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('models/ethics_ai_ethics_laser_model.pkl', 'rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.1 64-bit ('.venv': poetry)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "interpreter": {
   "hash": "3d72576ac13b89fb09600bb6b4285e0f9ef003d397285e7a1334d2309113cab6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
