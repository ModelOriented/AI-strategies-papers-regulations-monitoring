{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import textacy\n",
    "import os\n",
    "from thefuzz import process\n",
    "os.chdir('../..')\n",
    "en_md = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FETCH_URL_TEMPLATE = \"https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:{}&from=EN\"\n",
    "def fetch_eurlex(celex: str):\n",
    "    celex = celex.replace(\"/\", \"%2F\")\n",
    "    url = FETCH_URL_TEMPLATE.format(celex)\n",
    "    r = requests.get(\n",
    "        url\n",
    "    )\n",
    "    if r.status_code == 200:\n",
    "        return r.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(fetch_eurlex(\"52021PC0206\"))\n",
    "text = soup.getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= text.split(\"\\n\")\n",
    "\n",
    "a = [w for w in t if w!='']\n",
    "\n",
    "lines = pd.Series(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       REGULATION OF THE EUROPEAN PARLIAMENT AND OF T...\n",
       "188     REGULATION OF THE EUROPEAN PARLIAMENT AND OF T...\n",
       "1892       See Proposal for a REGULATION OF THE EUROPE...\n",
       "2219    (a)Proposal for a REGULATION OF THE EUROPEAN P...\n",
       "2221    (a)Amended proposal for a REGULATION OF THE EU...\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines.str.contains(\"TITLE I\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TITLE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/stanislaw/repos/AI-strategies-papers-regulations-monitoring/notebooks/sg/23.06 Eur lex geting.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stanislaw/repos/AI-strategies-papers-regulations-monitoring/notebooks/sg/23.06%20Eur%20lex%20geting.ipynb#ch0000033?line=0'>1</a>\u001b[0m l2[\u001b[39m'\u001b[39;49m\u001b[39mTITLE\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m~/repos/AI-strategies-papers-regulations-monitoring/.venv/lib/python3.8/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/AI-strategies-papers-regulations-monitoring/.venv/lib/python3.8/site-packages/pandas/core/series.py:1069\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1066\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1068\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1070\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/repos/AI-strategies-papers-regulations-monitoring/.venv/lib/python3.8/site-packages/pandas/core/indexes/range.py:389\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    390\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_loc(key, method\u001b[39m=\u001b[39mmethod, tolerance\u001b[39m=\u001b[39mtolerance)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TITLE'"
     ]
    }
   ],
   "source": [
    "l2['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = lines[346:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = l2[l2.str.contains(r\"^\\(\\d+\\)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4 = l3[l3.str.len()>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5 = l4.str.replace(r\"\\(\\d+\\)\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = l5.apply(phrasemachine.get_phrases)\n",
    "# p.apply(lambda x: x['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‘post-market monitoring’ means all activities carried out by providers of AI systems to proactively collect and review experience gained from the use of AI systems they place on the market or put into service for the purpose of identifying any need to immediately apply any necessary corrective or preventive actions;"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text  = l5.loc[405]\n",
    "\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[all activities,\n",
       " providers,\n",
       " AI systems,\n",
       " the use,\n",
       " AI systems,\n",
       " they,\n",
       " the market,\n",
       " service,\n",
       " the purpose,\n",
       " any need,\n",
       " any necessary corrective or preventive actions]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_lg(text).noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[post-market monitoring,\n",
       " all activities,\n",
       " providers,\n",
       " AI systems,\n",
       " experience,\n",
       " the use,\n",
       " AI systems,\n",
       " they,\n",
       " the market,\n",
       " service,\n",
       " the purpose,\n",
       " any need,\n",
       " any necessary corrective or preventive actions]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_md(text).noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[post-market monitoring,\n",
       " all activities,\n",
       " providers,\n",
       " AI systems,\n",
       " experience,\n",
       " the use,\n",
       " AI systems,\n",
       " they,\n",
       " the market,\n",
       " service,\n",
       " the purpose,\n",
       " any need,\n",
       " any necessary corrective or preventive actions]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(en_sm(text).noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_chunks(doc):\n",
    "    try:\n",
    "        return [\n",
    "            chunk.text\n",
    "            for chunk in textacy.extract.basics.noun_chunks(doc)\n",
    "            if not len(chunk) == 1 or chunk[0].pos_ in {\"PROPN\", \"NOUN\"}\n",
    "        ]\n",
    "    except AttributeError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = l5.apply(en_md).apply(extract_noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = phrases.apply(lambda a: [x.strip(\"‘\") for x in a])\n",
    "pcount = phrases.explode().value_counts()\n",
    "pcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = list(pcount.index)\n",
    "phrases = [a.lower() for a in phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_memes = pd.read_parquet('data/s2orc/chunk_meme_mappings/reduced_300_big_cleaned_phrase-bert_eps_0.2_min_clust_size_3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = chunk_memes[chunk_memes['chunk'].isin(phrases)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv('chunks_from_ai_act_phrasebert.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = phrases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ai system', 100, 2630395)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extractOne(phrase,chunk_memes['chunk'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3887d37ca77ee49ef2f2537ca92bbe7921610d49c9740853abeb2b31ec16d1a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
